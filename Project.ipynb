{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "01_import dataset\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "#https://drive.google.com/drive/folders/18qV82fNY3IIWu3BRoGqm_LNgJzE8Akbr?usp=drive_link\n",
        "#base_dir = \"/Users/Andypon/10_交大研究所/1141_01_機器學習與金融科技/data\"\n",
        "base_dir= '/Users/andyw.p.chen/Documents/Project/datasets'\n",
        "#base_dir=  \"c:\\Users\\user\\Downloads\\datasets\"\n",
        "\n",
        "def load_json_to_df(filename: str) -> pd.DataFrame:\n",
        "    file_path = os.path.join(base_dir, filename)\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # 如果是 { \"target\": {id: value, ...} }\n",
        "    if isinstance(data, dict) and len(data) == 1 and isinstance(next(iter(data.values())), dict):\n",
        "        key, inner = next(iter(data.items()))\n",
        "        return pd.DataFrame(list(inner.items()), columns=[\"id\", key])\n",
        "\n",
        "    # dict of scalar\n",
        "    if isinstance(data, dict):\n",
        "        return pd.DataFrame([{\"code\": k, \"desc\": v} for k, v in data.items()])\n",
        "\n",
        "    # list of dict\n",
        "    elif isinstance(data, list):\n",
        "        return pd.DataFrame(data)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported JSON structure in {filename}: {type(data)}\")\n",
        "\n",
        "\n",
        "def load_csv_to_df(filename: str) -> pd.DataFrame:\n",
        "    \"\"\"讀取 CSV 並轉為 DataFrame。\"\"\"\n",
        "    return pd.read_csv(os.path.join(base_dir, filename))\n",
        "\n",
        "# JSON 資料\n",
        "##mcc_codes_df = load_json_to_df(\"mcc_codes.json\")\n",
        "train_fraud_labels_df = load_json_to_df(\"train_fraud_labels.json\")\n",
        "\n",
        "# CSV 資料\n",
        "cards_df = load_csv_to_df(\"cards_data.csv\")\n",
        "transactions_df = load_csv_to_df(\"transactions_data.csv\")\n",
        "users_df = load_csv_to_df(\"users_data.csv\")\n",
        "\n",
        "# 簡單檢查\n",
        "#print(mcc_codes_df.head())\n",
        "#print(train_fraud_labels_df.head())\n",
        "#print(cards_df.head())\n",
        "#print(transactions_df.head())\n",
        "#print(users_df.apthead())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "02_rename variable in each data set\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_fraud_labels_df = train_fraud_labels_df.rename(columns={'id': 'transactions_id'})\n",
        "train_fraud_labels_df = train_fraud_labels_df.rename(columns={'target': 'is_fraud'})\n",
        "\n",
        "cards_df = cards_df.rename(columns={'id':'card_id'})\n",
        "\n",
        "users_df = users_df.rename(columns={'id':'client_id'})\n",
        "\n",
        "transactions_df = transactions_df.rename(columns={'mcc': 'mcc_code'})\n",
        "transactions_df = transactions_df.rename(columns={'id': 'transaction_id'})\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "03_變數型態統一及缺失值處理\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_missing_flags(df: pd.DataFrame, cols: list) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    在 DataFrame 中對指定欄位建立 missing flag 欄位\n",
        "    flag=1 表示缺失值，flag=0 表示非缺失值\n",
        "    \n",
        "    參數\n",
        "    ----\n",
        "    df : pd.DataFrame\n",
        "        輸入的資料框\n",
        "    cols : list\n",
        "        要檢查的欄位名稱清單\n",
        "    \n",
        "    回傳\n",
        "    ----\n",
        "    pd.DataFrame : 新的資料框 (含新增的 flag 欄位)\n",
        "    \"\"\"\n",
        "    for col in cols:\n",
        "        df[f\"{col}_missing_flag\"] = df[col].isna().astype(int)\n",
        "    return df\n",
        "\n",
        "transactions_df = add_missing_flags(transactions_df, [\"merchant_state\", \"zip\", \"errors\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "##train_fraud_labels_df##\n",
        "train_fraud_labels_df[\"is_fraud\"]=train_fraud_labels_df[\"is_fraud\"].astype(\"category\") \n",
        "train_fraud_labels_df[\"transactions_id\"]=train_fraud_labels_df[\"transactions_id\"].astype(int) #合併資料需要\n",
        "\n",
        "##cards_df##\n",
        "cards_df[\"card_brand\"]=cards_df[\"card_brand\"].astype(\"category\") \n",
        "cards_df[\"card_type\"]=cards_df[\"card_type\"].astype(\"category\")\n",
        "#####不要load這行 cards_df[\"expires\"]=pd.to_datetime(cards_df[\"expires\"], format=\"%m/%Y\")\n",
        "cards_df[\"expires\"] = pd.to_datetime(cards_df[\"expires\"], format=\"%m/%Y\").dt.to_period(\"M\")\n",
        "cards_df[\"has_chip\"]=cards_df[\"has_chip\"].astype(\"category\")\n",
        "\n",
        "cards_df['credit_limit'] = cards_df['credit_limit'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
        "#####不要load這行 cards_df[\"acct_open_date\"]=pd.to_datetime(cards_df[\"acct_open_date\"], format=\"%m/%Y\")\n",
        "cards_df[\"acct_open_date\"] = pd.to_datetime(cards_df[\"acct_open_date\"], format=\"%m/%Y\").dt.to_period(\"M\")\n",
        "#####不要load這行 cards_df[\"year_pin_last_changed\"]=pd.to_datetime(cards_df[\"year_pin_last_changed\"], format=\"%Y\")\n",
        "cards_df[\"year_pin_last_changed\"] = pd.to_datetime(cards_df[\"year_pin_last_changed\"], format=\"%Y\").dt.to_period(\"Y\")\n",
        "cards_df[\"card_on_dark_web\"]=cards_df[\"card_on_dark_web\"].astype(\"category\") \n",
        "\n",
        "##users_df##\n",
        "users_df[\"birth_year\"] = pd.to_datetime(users_df[\"birth_year\"], format=\"%Y\").dt.to_period(\"Y\")\n",
        "users_df[\"birth_month\"] = pd.to_datetime(users_df[\"birth_month\"], format=\"%m\").dt.to_period(\"M\")\n",
        "users_df[\"gender\"]=users_df[\"gender\"].astype(\"category\") \n",
        "users_df['per_capita_income'] = users_df['per_capita_income'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
        "users_df['yearly_income'] = users_df['yearly_income'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
        "users_df['total_debt'] = users_df['total_debt'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
        "\n",
        "##transactions_df##\n",
        "transactions_df[\"date\"] = pd.to_datetime(transactions_df[\"date\"])\n",
        "#浮點數轉整數原因確定？\n",
        "transactions_df['amount'] = transactions_df['amount'].replace(r'[\\$,]', '', regex=True).astype(float).astype(int)\n",
        "##負數取log調成1\n",
        "#transactions_df['amount'] = transactions_df['amount'].replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "\n",
        "transactions_df[\"use_chip\"]=transactions_df[\"use_chip\"].astype(\"category\") \n",
        "\n",
        "transactions_df.loc[\n",
        "    transactions_df['merchant_city'].str.lower() == 'online',\n",
        "    'merchant_state'\n",
        "] = 'online'\n",
        "\n",
        "transactions_df.loc[\n",
        "    transactions_df['merchant_city'].str.lower() == 'online',\n",
        "    'zip'\n",
        "] = -1\n",
        "## 我沒有全部改，這樣完之後仍有89006筆Missing，剩下都是在國外\n",
        "transactions_df['zip'] = transactions_df['zip'].fillna(-999)\n",
        "transactions_df[\"zip\"]=transactions_df[\"zip\"].astype(\"int64\")\n",
        "\n",
        "transactions_df['errors'] = transactions_df['errors'].astype('category')\n",
        "transactions_df['errors'] = transactions_df['errors'].cat.add_categories('No_error').fillna('No_error')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#cars one hot encoding\n",
        "##統一類別變數轉dummy variable(要注意共線性問題，應刪掉其中之一)\n",
        "\n",
        "#card_type 原始種類：Debit_57%, Credit_33%, Debit(Prepaid)_9%\n",
        "#card_brand 原始種類：MasterCard_52%, Visa_38%, Amex_7%, Discovery_3%\n",
        "#has_chip 原始種類：Yes_89%, No_11%\n",
        "#card_on_dark_web 原始種類：No_0%\n",
        "cols_to_encode = ['card_type', 'card_brand', 'has_chip']\n",
        "cards_df[cols_to_encode] = cards_df[cols_to_encode].astype('category')\n",
        "dummies_cards = pd.get_dummies(\n",
        "    cards_df[cols_to_encode], \n",
        "    prefix=cols_to_encode, \n",
        "    dtype='uint8'\n",
        "    )\n",
        "cards_df = pd.concat([cards_df, dummies_cards], axis=1)\n",
        "\n",
        "#use_chip 原始種類：Swiped_52%, Chipe_36%, Online_12%\n",
        "dummies_use = pd.get_dummies(transactions_df['use_chip'], prefix='use_chip', dtype='uint8')\n",
        "transactions_df = pd.concat([transactions_df, dummies_use], axis=1)\n",
        "\n",
        "#gender 原始種類：Female_51%, Male_49%\n",
        "dummies_gender = pd.get_dummies(users_df['gender'], prefix='gender', dtype='uint8')\n",
        "users_df = pd.concat([users_df, dummies_gender], axis=1)\n",
        "\n",
        "\n",
        "cards_df.drop(columns=[\"has_chip_NO\",\"has_chip\"], inplace=True)\n",
        "transactions_df.drop(columns=[\"use_chip\"], inplace=True)\n",
        "users_df.drop(columns=[\"gender_Female\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##不用執行～～(本來試圖建立對照表將Missing的zip補上)\n",
        "\n",
        "##檢查89006筆Missing的zip\n",
        "c_missing_zip = transactions_df[transactions_df[\"zip\"].isna()]\n",
        "c_mexico_zip = transactions_df[transactions_df[\"merchant_state\"]==\"Mexico\"]\n",
        "#c_mcc_mv_zip = c_missing_zip[\n",
        "#    (c_missing_zip[\"mcc_code\"] > 5400) & (c_missing_zip[\"mcc_code\"] < 5700)\n",
        "#]\n",
        "\n",
        "\n",
        "\n",
        "# 先建立 mapping table：一組 state+city 可能對應多個 zip\n",
        "mapping_df = (\n",
        "    transactions_df\n",
        "    .dropna(subset=[\"zip\"])                                   # 只要 zip 有值的 row\n",
        "    .drop_duplicates(subset=[\"merchant_state\", \"merchant_city\", \"zip\"]) \n",
        "    [[\"merchant_state\", \"merchant_city\", \"zip\"]]              # 只留下需要的欄位\n",
        ")\n",
        "\n",
        "print(mapping_df.head())\n",
        "\n",
        "\n",
        "# 假設 df 已經存在\n",
        "# 建立新的欄位 F，B 與 C 合併\n",
        "c_missing_zip[\"fullname\"] = c_missing_zip[\"merchant_city\"].astype(str) + c_missing_zip[\"merchant_state\"].astype(str)\n",
        "# 建立新的 DataFrame，只取 A, D, F\n",
        "df_small = c_missing_zip[[\"transaction_id\", \"fullname\",\"zip\"]]\n",
        "\n",
        "mapping_df[\"mfullname\"] = mapping_df[\"merchant_city\"].astype(str) + mapping_df[\"merchant_state\"].astype(str)\n",
        "\n",
        "# 先建立一個 lookup 字典\n",
        "lookup_dict = dict(zip(mapping_df[\"mfullname\"], mapping_df[\"zip\"]))\n",
        "\n",
        "# 用 map 當作 vlookup\n",
        "df_small[\"zip\"] = df_small[\"zip\"].fillna(df_small[\"fullname\"].map(lookup_dict))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "05_data資料整合\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#transactions_df.loc[transactions_df[\"transaction_id\"] == 10649266] #transaction_id vs id\n",
        "\n",
        "#原始資料筆數：13305915\n",
        "### transactions_df+train_fraud_labels_df      left 會有4390952 missing values\n",
        "merged = pd.merge(transactions_df, train_fraud_labels_df, left_on=\"transaction_id\", right_on=\"transactions_id\", how=\"outer\")\n",
        "### transactions_df train_fraud_labels_df(8914963) + users_df 對過去不會有missing values\n",
        "merged = pd.merge(merged,users_df , left_on=\"client_id\", right_on=\"client_id\", how=\"left\")\n",
        "### transactions_df train_fraud_labels_df users_df + cards_df 對過去不會有missing values\n",
        "merged = pd.merge(merged,cards_df , left_on=\"card_id\", right_on=\"card_id\", how=\"left\")\n",
        "\n",
        "#刪掉重複的columns\n",
        "merged.drop(columns=[\"transactions_id\"], inplace=True)\n",
        "merged.drop(columns=[\"client_id_y\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "del transactions_df, users_df, cards_df, train_fraud_labels_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged[\"is_fraud\"] = merged[\"is_fraud\"].astype(str)\n",
        "merged.loc[merged['is_fraud'].str.lower() == 'no','is_fraud'] = '0'\n",
        "merged.loc[merged['is_fraud'].str.lower() == 'yes','is_fraud'] = '1'\n",
        "merged[\"is_fraud\"] = pd.to_numeric(merged[\"is_fraud\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "merged = add_missing_flags(merged, [\"is_fraud\"])\n",
        "\n",
        "#merged.to_csv(\"merged.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "del cols_to_encode, dummies_cards, dummies_use, dummies_gender"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06_EDA_Exploratory-Data-Analysis\n",
        "=="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-1_資料型態\n",
        "=="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "merged資料：8914963x37"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-2_資料統計指標\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-3_類別型資料frequency barchart\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cat_cols = merged.select_dtypes(include=[\"category\"]).columns\n",
        "\n",
        "n_rows, n_cols = 4, 2\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 50))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(cat_cols):\n",
        "    ax = axes[i]\n",
        "    sns.countplot(data=merged, x=col, order=merged[col].value_counts().index, ax=ax)\n",
        "    ax.set_title(f\"Bar chart of {col}\")\n",
        "    ax.set_xlabel(col)\n",
        "    ax.set_ylabel(\"Count\")\n",
        "    if col == \"errors\":\n",
        "        ax.tick_params(axis='x', rotation=90)  # X軸標籤旋轉\n",
        "    else:\n",
        "        ax.tick_params(axis='x', rotation=0)  # X軸標籤旋轉\n",
        "    \n",
        "    # 在長條圖上加數字\n",
        "    for p in ax.patches:\n",
        "        height = p.get_height()\n",
        "        ax.text(x=p.get_x() + p.get_width()/2,\n",
        "                y=height + 0.05,\n",
        "                s=int(height),\n",
        "                ha='center')\n",
        "\n",
        "# 移除多餘空白子圖\n",
        "for j in range(i+1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-4_數值型資料histogram\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 設定 subplot 格式\n",
        "n_cols = 4   # 每列放4張圖\n",
        "n_rows = 6   # 每行放6列 (共 4x6=24)\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20,15))  # 調整大小\n",
        "axes = axes.flatten()  # 攤平成一維方便迭代\n",
        "num_cols = merged.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "for i, col in enumerate(num_cols):\n",
        "    sns.histplot(data=merged, x=col, bins=30, kde=True, ax=axes[i])\n",
        "    axes[i].set_title(col)\n",
        "\n",
        "# 把多餘的 subplot 關掉（避免空白框）\n",
        "for j in range(i+1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-5_類別型資料box plot\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 抓出數值型欄位\n",
        "num_cols = merged.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# 建立 3x8 subplot\n",
        "fig, axes = plt.subplots(8, 3, figsize=(30, 50))  # 依照需求調整 figsize\n",
        "axes = axes.flatten()  # 攤平成一維 array，方便迴圈\n",
        "\n",
        "# 逐一畫圖\n",
        "for i, col in enumerate(num_cols):\n",
        "    sns.boxplot(y=merged[col], ax=axes[i])  # 每個 subplot 畫一個 boxplot\n",
        "    axes[i].set_title(col, fontsize=10)\n",
        "\n",
        "# 如果欄位數小於 3x8，隱藏多餘的子圖\n",
        "for j in range(len(num_cols), len(axes)):\n",
        "    axes[j].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-7_數值型資料pair wise scatterplot(畫不出來？)\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cols = merged.select_dtypes(include=['int64', 'float64']).columns\n",
        "sns.pairplot(merged[num_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-8_針對詐騙標籤轉成dummy variable\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_to_encode = ['is_fraud']\n",
        "merged[cols_to_encode] = merged[cols_to_encode].astype('category')\n",
        "dummies_cards = pd.get_dummies(\n",
        "    merged[cols_to_encode], \n",
        "    prefix=cols_to_encode, \n",
        "    dtype='uint8'\n",
        "    )\n",
        "merged = pd.concat([merged, dummies_cards], axis=1)\n",
        "merged.drop(columns=[\"is_fraud_No\",\"is_fraud\"], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged[\"is_fraud_Yes\"]=merged[\"is_fraud_Yes\"].astype(\"int64\")\n",
        "target = 'is_fraud_Yes'  # 假設這是目標\n",
        "num_cols = merged.select_dtypes(include=['int64','float64']).columns.drop(target)\n",
        "\n",
        "for col in num_cols:\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.scatter(merged[col], merged[target], alpha=0.3)  # alpha降低透明度，避免太擠\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel(target)\n",
        "    plt.title(f\"{target} vs {col}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-9_其他觀察 詐騙與否跟時間的關係\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 確保 date 是 datetime 格式\n",
        "merged[\"date\"] = pd.to_datetime(merged[\"date\"])\n",
        "\n",
        "# 按天統計詐騙事件數\n",
        "fraud_per_day = merged.groupby(merged[\"date\"].dt.date)[\"is_fraud_Yes\"].sum()\n",
        "\n",
        "# 畫折線圖\n",
        "plt.figure(figsize=(12,5))\n",
        "fraud_per_day.plot(kind=\"line\", marker=\"o\")\n",
        "plt.title(\"Daily Fraud Counts 日期 vs 詐騙次數\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Number of Frauds\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 按小時\n",
        "merged[\"hour\"] = merged[\"date\"].dt.hour\n",
        "hourly_fraud = merged.groupby(\"hour\")[\"is_fraud_Yes\"].sum()\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "hourly_fraud.plot(kind=\"bar\")\n",
        "plt.title(\"Fraud Counts by Hour of Day\")\n",
        "plt.xlabel(\"Hour\")\n",
        "plt.ylabel(\"Number of Frauds\")\n",
        "plt.show()\n",
        "\n",
        "# 按星期幾\n",
        "merged[\"weekday\"] = merged[\"date\"].dt.day_name()\n",
        "weekday_fraud = merged.groupby(\"weekday\")[\"is_fraud_Yes\"].sum().reindex(\n",
        "    [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "weekday_fraud.plot(kind=\"bar\")\n",
        "plt.title(\"Fraud Counts by Weekday\")\n",
        "plt.ylabel(\"Number of Frauds\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 想確認原始交易分布與詐騙無關\n",
        "# 取出小時\n",
        "merged[\"hour\"] = merged[\"date\"].dt.hour\n",
        "\n",
        "# 按小時計算交易數\n",
        "transactions_per_hour = merged[\"hour\"].value_counts().sort_index()\n",
        "\n",
        "# 畫長條圖\n",
        "plt.figure(figsize=(12,5))\n",
        "transactions_per_hour.plot(kind=\"bar\")\n",
        "plt.title(\"Transaction Distribution by Hour of Day\")\n",
        "plt.xlabel(\"Hour of Day\")\n",
        "plt.ylabel(\"Number of Transactions\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-10_correlation and heatmap\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_df = merged.select_dtypes(include=['int64', 'float64'])\n",
        "corr = numeric_df.corr()\n",
        "print(corr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0)\n",
        "plt.title(\"Correlation Heatmap of Numeric Variables\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 原始資料 correlation ---\n",
        "corr_raw = numeric_df.corr()\n",
        "\n",
        "# --- 標準化後 correlation ---\n",
        "scaler = StandardScaler()\n",
        "num_scaled = scaler.fit_transform(numeric_df)   # 轉換成 Numpy array\n",
        "num_df_scaled = pd.DataFrame(num_scaled, columns=numeric_df.columns)\n",
        "corr_scaled = num_df_scaled.corr()\n",
        "\n",
        "# --- 繪圖 (上下對照) ---\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 14))\n",
        "\n",
        "sns.heatmap(corr_raw, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, ax=axes[0])\n",
        "axes[0].set_title(\"Correlation Heatmap (Raw Data)\")\n",
        "\n",
        "sns.heatmap(corr_scaled, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, ax=axes[1])\n",
        "axes[1].set_title(\"Correlation Heatmap (Standardized Data)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "07_categoracal 轉 dummy分析\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "WVTi5S6XrUyN",
        "outputId": "7c85d826-19f0-4213-a5de-613565d7244e"
      },
      "outputs": [],
      "source": [
        "info_df = pd.DataFrame({\n",
        "    \"column\": merged.columns,\n",
        "    \"dtype\": merged.dtypes.astype(str)\n",
        "})\n",
        "info_df.to_csv(\"info.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "08_Benchmark model\n",
        "==\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cols = merged.select_dtypes(include=['int64', 'float64','uint8']).columns\n",
        "df=merged[num_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_cleaned = df.dropna()\n",
        "del df\n",
        "\n",
        "df_cleaned.drop(columns=[\"is_fraud_missing_flag\",\"card_type_Debit (Prepaid)\", \"card_brand_Discover\", \"use_chip_Online Transaction\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df_cleaned, test_size=0.2, random_state=888)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is_fraud\n",
            "0    7121379\n",
            "1      10591\n",
            "Name: count, dtype: Int64\n",
            "is_fraud\n",
            "0    1780252\n",
            "1       2741\n",
            "Name: count, dtype: Int64\n"
          ]
        }
      ],
      "source": [
        "del df_cleaned, merged\n",
        "trainp = train_df['is_fraud'].value_counts(normalize=False)\n",
        "print(trainp)\n",
        "testp = test_df['is_fraud'].value_counts(normalize=False)\n",
        "print(testp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/andyw.p.chen/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  return 1 - self.ssr/self.centered_tss\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       features  VIF Factor\n",
            "24                  card_number   22.245532\n",
            "18            per_capita_income   12.898282\n",
            "19                yearly_income   12.619509\n",
            "30              card_brand_Amex    4.408913\n",
            "9              zip_missing_flag    2.108261\n",
            "8   merchant_state_missing_flag    1.989951\n",
            "6                           zip    1.922594\n",
            "11    use_chip_Chip Transaction    1.800531\n",
            "12   use_chip_Swipe Transaction    1.791158\n",
            "17                    longitude    1.746897\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "def calculate_vif(df):\n",
        "    # 1. 保留數值欄位\n",
        "    df_num = df.select_dtypes(include=[np.number]).copy()\n",
        "\n",
        "    # 2. 強制轉成 float64，避免 Int64 / uint8 / object 問題\n",
        "    df_num = df_num.astype(np.float64)\n",
        "\n",
        "    # 3. 檢查 inf / NaN\n",
        "    if not np.isfinite(df_num.values).all():\n",
        "        raise ValueError(\"Data contains NaN or infinite values, cannot compute VIF.\")\n",
        "\n",
        "    # 4. 加上截距\n",
        "    X = sm.add_constant(df_num)\n",
        "\n",
        "    # 5. 計算 VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"features\"] = X.columns\n",
        "    vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) \n",
        "                         for i in range(X.shape[1])]\n",
        "\n",
        "    return vif\n",
        "\n",
        "# 使用範例\n",
        "vif_result = calculate_vif(train_df)\n",
        "print(vif_result.sort_values(by=\"VIF Factor\", ascending=False).head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4070 / 7131970\n"
          ]
        }
      ],
      "source": [
        "##第一次處理共線性\n",
        "train_df.drop(columns=[\"per_capita_income\"], inplace=True)\n",
        "##觀察card_number的異常處\n",
        "print(train_df[\"card_number\"].nunique(), \"/\", len(train_df))\n",
        "##第一次處理card_number\n",
        "train_df.drop(columns=[\"card_number\"], inplace=True)\n",
        "#再重跑一次VIF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       features   VIF Factor\n",
            "0                         const  3100.543997\n",
            "12   use_chip_Swipe Transaction   569.424426\n",
            "11    use_chip_Chip Transaction   524.571982\n",
            "8   merchant_state_missing_flag   251.088030\n",
            "9              zip_missing_flag    17.641667\n",
            "29        card_brand_Mastercard    11.382571\n",
            "30              card_brand_Visa    10.554099\n",
            "27              card_type_Debit     4.931201\n",
            "26             card_type_Credit     4.562805\n",
            "6                           zip     3.879815\n"
          ]
        }
      ],
      "source": [
        "vif_result = calculate_vif(train_df)\n",
        "print(vif_result.sort_values(by=\"VIF Factor\", ascending=False).head(10))\n",
        "##發現missing_flag的共線性問題，決定保留one hot encoding高vif值的變數"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.drop(columns=[\"zip_missing_flag\",\"merchant_state_missing_flag\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      features  VIF Factor\n",
            "0                        const  848.160979\n",
            "27       card_brand_Mastercard   11.382517\n",
            "28             card_brand_Visa   10.554078\n",
            "10  use_chip_Swipe Transaction    5.244474\n",
            "9    use_chip_Chip Transaction    5.144790\n",
            "25             card_type_Debit    4.931106\n",
            "24            card_type_Credit    4.562503\n",
            "6                          zip    3.645768\n",
            "26             card_brand_Amex    3.328279\n",
            "15                   longitude    2.709211\n"
          ]
        }
      ],
      "source": [
        "vif_result = calculate_vif(train_df)\n",
        "print(vif_result.sort_values(by=\"VIF Factor\", ascending=False).head(10))\n",
        "##移除missing_flag共線性問題，再次確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      variable   coefficient  p_value\n",
            "0    use_chip_Chip Transaction -5.792166e-01   0.0000\n",
            "1              card_type_Debit -2.431305e-01   0.0000\n",
            "2             card_type_Credit  1.187650e-01   0.0000\n",
            "3                       amount  2.634523e-03   0.0000\n",
            "4                  merchant_id  5.815498e-06   0.0000\n",
            "5                          zip -1.023342e-04   0.0000\n",
            "6                     mcc_code -5.383161e-04   0.0000\n",
            "7          errors_missing_flag -1.034501e+00   0.0000\n",
            "8                   total_debt -1.507820e-06   0.0000\n",
            "9   use_chip_Swipe Transaction -2.282721e+00   0.0000\n",
            "10                 current_age  6.811940e-03   0.0000\n",
            "11                credit_limit -1.325726e-05   0.0000\n",
            "12                    latitude -8.201997e-03   0.0000\n",
            "13            num_credit_cards  1.108020e-01   0.0000\n",
            "14               yearly_income -4.518766e-06   0.0000\n",
            "15                has_chip_YES  1.266255e-01   0.0002\n",
            "16                credit_score  4.469540e-04   0.0027\n",
            "17                   longitude -1.721663e-03   0.0035\n",
            "18                     card_id -1.531231e-05   0.0081\n",
            "19             card_brand_Visa -4.786636e-02   0.0180\n",
            "20             card_brand_Amex  8.191560e-02   0.0324\n",
            "21                 gender_Male -3.298179e-02   0.0902\n",
            "22              transaction_id  2.666966e-09   0.1970\n",
            "23       card_brand_Mastercard -2.159213e-02   0.2679\n",
            "24              retirement_age  2.897547e-03   0.2859\n",
            "25                         cvv  3.560710e-05   0.2907\n",
            "26                 client_id_x -1.477671e-05   0.3766\n",
            "27            num_cards_issued -7.095726e-03   0.7070\n"
          ]
        }
      ],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# assume train_df is your dataframe and \"is_fraud\" is the dependent variable\n",
        "y = train_df[\"is_fraud\"]\n",
        "\n",
        "# exclude the dependent variable itself\n",
        "independent_vars = train_df.columns.drop(\"is_fraud\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for var in independent_vars:\n",
        "    X = sm.add_constant(train_df[var])  # add intercept\n",
        "    model = sm.Logit(y, X)\n",
        "    try:\n",
        "        result = model.fit(disp=False)\n",
        "        coef = result.params[var]\n",
        "        pval = np.around(result.pvalues[var], 4)\n",
        "        results.append({\"variable\": var, \"coefficient\": coef, \"p_value\": pval})\n",
        "    except Exception as e:\n",
        "        results.append({\"variable\": var, \"coefficient\": None, \"p_value\": None})\n",
        "        print(f\"Skipped {var} due to error: {e}\")\n",
        "\n",
        "# convert to dataframe\n",
        "summary_df = pd.DataFrame(results)\n",
        "\n",
        "# optional: sort by p_value\n",
        "summary_df = summary_df.sort_values(\"p_value\", ascending=True).reset_index(drop=True)\n",
        "\n",
        "print(summary_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table: Logistic Regression Stepwise Estimation — Adding amount\n",
            "\n",
            "Overall Model Fit: Goodness-of-Fit Measures\n",
            "\n",
            "                       Measure      Value Change_from_Base Change_pvalue\n",
            "-2 Log Likelihood (−2LL) value 156596.132         -2514.48           0.0\n",
            "              Cox and Snell R2      0.000                               \n",
            "                 Nagelkerke R2      0.016                               \n",
            "          Pseudo R2 (McFadden)      0.016                               \n",
            "            Hosmer-Lemeshow χ2   3046.494                            0.0\n",
            "\n",
            "\n",
            "Variables in the Equation\n",
            "\n",
            "Independent Variable       B  Std. Error       Wald  df  Sig.  Exp(B)\n",
            "              amount  0.0026      0.0000   4155.605   1   0.0  1.0026\n",
            "            Constant -6.6693      0.0104 408490.171   1   0.0  0.0013\n",
            "\n",
            "\n",
            "Variables Not in the Equation (candidates and LRT vs base)\n",
            "\n",
            "      Independent Variable  Score Statistic (LRT)  Significance\n",
            "                       zip              25168.126        0.0000\n",
            "                  mcc_code               1850.618        0.0000\n",
            "use_chip_Swipe Transaction               8580.841        0.0000\n",
            " use_chip_Chip Transaction                707.825        0.0000\n",
            "       errors_missing_flag                348.748        0.0000\n",
            "          num_credit_cards                330.237        0.0000\n",
            "               merchant_id                241.641        0.0000\n",
            "              credit_limit                223.331        0.0000\n",
            "           card_type_Debit                151.787        0.0000\n",
            "               current_age                125.967        0.0000\n",
            "             yearly_income                105.587        0.0000\n",
            "                total_debt                 59.954        0.0000\n",
            "          card_type_Credit                 32.764        0.0000\n",
            "                  latitude                 18.643        0.0000\n",
            "              has_chip_YES                 14.268        0.0002\n",
            "              credit_score                  9.045        0.0026\n",
            "                 longitude                  8.450        0.0037\n",
            "                   card_id                  6.996        0.0082\n",
            "           card_brand_Visa                  5.618        0.0178\n",
            "           card_brand_Amex                  4.471        0.0345\n",
            "               gender_Male                  2.872        0.0901\n",
            "            transaction_id                  1.665        0.1970\n",
            "     card_brand_Mastercard                  1.227        0.2680\n",
            "            retirement_age                  1.140        0.2857\n",
            "                       cvv                  1.116        0.2907\n",
            "               client_id_x                  0.782        0.3767\n",
            "          num_cards_issued                  0.141        0.7070\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/yb/xnfk9z6x34527z3924bcjqcr0000gn/T/ipykernel_1455/99504724.py:17: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  grouped = df.groupby(\"group\")\n"
          ]
        }
      ],
      "source": [
        "#(寫錯了不要使用)放入第一個變數會怎樣\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import chi2\n",
        "from sklearn.utils import check_array\n",
        "\n",
        "def hosmer_lemeshow_test(y_true, y_prob, g=10):\n",
        "    \"\"\"\n",
        "    Hosmer-Lemeshow test (group into g quantiles by predicted prob).\n",
        "    Returns (chi2, pvalue, table_df)\n",
        "    \"\"\"\n",
        "    # create dataframe\n",
        "    df = pd.DataFrame({\"y\": np.asarray(y_true), \"yhat\": np.asarray(y_prob)})\n",
        "    # create g groups by quantile of predicted prob\n",
        "    df[\"group\"] = pd.qcut(df[\"yhat\"], q=g, duplicates=\"drop\")\n",
        "    grouped = df.groupby(\"group\")\n",
        "    \n",
        "    obs = grouped[\"y\"].sum()\n",
        "    n = grouped.size()\n",
        "    exp = grouped[\"yhat\"].sum()\n",
        "    \n",
        "    # HL chi2: sum ( (O - E)^2 / (E*(1 - E/n)) )  -- alternative formulation:\n",
        "    # Common simple formula: sum((O - E)^2 / (E*(1 - E/n_i))) is unstable;\n",
        "    # We'll use classical: sum((O - E)^2 / (E*(1 - E/n_i))) where E is expected count in group\n",
        "    # But many use: sum((O - E)^2 / (E*(1 - E/n_i))) ; here we fallback to standard HL:\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        term = (obs - exp) ** 2 / (exp * (1 - exp / n))\n",
        "        term = term.replace([np.inf, -np.inf], 0).fillna(0)\n",
        "    chi2_stat = term.sum()\n",
        "    df_hl = max(1, len(n) - 2)\n",
        "    pvalue = chi2.sf(chi2_stat, df_hl)\n",
        "    \n",
        "    table = pd.DataFrame({\n",
        "        \"group\": n.index.astype(str),\n",
        "        \"n_obs\": n.values,\n",
        "        \"y_obs\": obs.values,\n",
        "        \"y_exp\": exp.values\n",
        "    })\n",
        "    return chi2_stat, pvalue, table\n",
        "\n",
        "def table_for_first_step(train_df, target_col=\"is_fraud\", g_hl=10, max_vars_display=None):\n",
        "    \"\"\"\n",
        "    Automatically pick the best single variable to add (by LRT vs base) and\n",
        "    produce three tables in the style of the textbook for the first step:\n",
        "      - Overall Model Fit (with change from base)\n",
        "      - Variables in the Equation (the added variable)\n",
        "      - Variables Not in the Equation (LRT for other candidates)\n",
        "    Returns: dict with dataframes: goodness_df, in_eq_df, not_in_eq_df\n",
        "    \"\"\"\n",
        "    train_df = train_df.reset_index(drop=True)\n",
        "    y = train_df[target_col].astype(int).reset_index(drop=True)\n",
        "    candidates = list(train_df.columns.drop(target_col))\n",
        "    n = len(train_df)\n",
        "    \n",
        "    # Base model (intercept only)\n",
        "    X_base = sm.add_constant(pd.DataFrame({\"intercept\": np.ones(n)}))\n",
        "    base_model = sm.Logit(y, X_base).fit(disp=False)\n",
        "    ll_base = base_model.llf\n",
        "    minus2ll_base = -2 * ll_base\n",
        "    \n",
        "    # For each candidate, fit model with that single variable and compute LRT\n",
        "    lrt_list = []\n",
        "    for var in candidates:\n",
        "        try:\n",
        "            Xv = sm.add_constant(train_df[[var]])\n",
        "            mv = sm.Logit(y, Xv).fit(disp=False)\n",
        "            ll_v = mv.llf\n",
        "            lr_stat = -2 * (ll_base - ll_v)   # change in -2LL\n",
        "            pval = chi2.sf(lr_stat, df=1)\n",
        "            lrt_list.append({\"variable\": var, \"lr_stat\": lr_stat, \"p_value\": pval, \"ll_v\": ll_v})\n",
        "        except Exception as e:\n",
        "            lrt_list.append({\"variable\": var, \"lr_stat\": None, \"p_value\": None, \"ll_v\": None})\n",
        "            # continue even on errors\n",
        "    \n",
        "    lrt_df = pd.DataFrame(lrt_list).sort_values(\"p_value\", na_position=\"last\").reset_index(drop=True)\n",
        "    \n",
        "    # pick best variable (smallest p-value, and lr_stat not null)\n",
        "    best_row = lrt_df.dropna(subset=[\"p_value\"]).sort_values(\"p_value\").iloc[0]  ###原本只有1個\n",
        "    best_var = best_row[\"variable\"]                                              ###原本只有1個\n",
        "    ###k = 2  # 想放幾個變數就改這裡\n",
        "    ###top_k_vars = lrt_df.dropna(subset=[\"p_value\"]).sort_values(\"p_value\").head(k)[\"variable\"].tolist()\n",
        "    \n",
        "    # Fit model with the chosen variable\n",
        "    X_best = sm.add_constant(train_df[[best_var]])  ###原本只有1個\n",
        "    ###X_best = sm.add_constant(train_df[top_k_vars])\n",
        "    ###best_var = \", \".join(top_k_vars)\n",
        "\n",
        "    best_model = sm.Logit(y, X_best).fit(disp=False)\n",
        "    ll_best = best_model.llf\n",
        "    minus2ll_best = -2 * ll_best\n",
        "    change_from_base = minus2ll_best - minus2ll_base  # how -2LL changed (positive if decreased in LL)\n",
        "    # significance of change (LRT)\n",
        "    lr_stat_best = -2 * (ll_base - ll_best)\n",
        "    p_change = chi2.sf(lr_stat_best, df=1)\n",
        "    \n",
        "    # R-squared variants\n",
        "    ll_null = ll_base\n",
        "    ll_model = ll_best\n",
        "    # McFadden\n",
        "    pseudo_r2 = 1 - (ll_model / ll_null)\n",
        "    # Cox & Snell\n",
        "    try:\n",
        "        r_cs = 1 - np.exp((2.0 / n) * (ll_null - ll_model))\n",
        "    except:\n",
        "        r_cs = np.nan\n",
        "    # Nagelkerke (adjusted Cox & Snell)\n",
        "    try:\n",
        "        r_max = 1 - np.exp((2.0 / n) * ll_null)\n",
        "        nagelkerke = r_cs / r_max if r_max != 0 else np.nan\n",
        "    except:\n",
        "        nagelkerke = np.nan\n",
        "    \n",
        "    # Hosmer-Lemeshow\n",
        "    preds = best_model.predict(X_best)\n",
        "    hl_chi2, hl_p, hl_table = hosmer_lemeshow_test(y, preds, g=g_hl)\n",
        "    \n",
        "    # Build Goodness-of-Fit DataFrame (layout like textbook)\n",
        "    goodness_rows = [\n",
        "        {\"Measure\": \"-2 Log Likelihood (−2LL) value\", \"Value\": round(minus2ll_best, 3),\n",
        "         \"Change_from_Base\": round(change_from_base, 3), \"Change_pvalue\": round(p_change, 4)},\n",
        "        {\"Measure\": \"Cox and Snell R2\", \"Value\": round(r_cs, 3), \"Change_from_Base\": \"\", \"Change_pvalue\": \"\"},\n",
        "        {\"Measure\": \"Nagelkerke R2\", \"Value\": round(nagelkerke, 3), \"Change_from_Base\": \"\", \"Change_pvalue\": \"\"},\n",
        "        {\"Measure\": \"Pseudo R2 (McFadden)\", \"Value\": round(pseudo_r2, 3), \"Change_from_Base\": \"\", \"Change_pvalue\": \"\"},\n",
        "        {\"Measure\": \"Hosmer-Lemeshow χ2\", \"Value\": round(hl_chi2, 3), \"Change_from_Base\": \"\", \"Change_pvalue\": round(hl_p, 4)}\n",
        "    ]\n",
        "    goodness_df = pd.DataFrame(goodness_rows)\n",
        "    \n",
        "    # Variables in the Equation (the chosen variable)\n",
        "    params = best_model.params\n",
        "    bse = best_model.bse\n",
        "    z = params / bse\n",
        "    wald = (z**2)\n",
        "    pvals = best_model.pvalues\n",
        "    expb = np.exp(params)\n",
        "    in_eq = []\n",
        "    # list chosen var then constant\n",
        "    for var in [best_var, \"const\"]:\n",
        "        if var in params.index:\n",
        "            in_eq.append({\n",
        "                \"Independent Variable\": var if var != \"const\" else \"Constant\",\n",
        "                \"B\": round(params[var], 4),\n",
        "                \"Std. Error\": round(bse[var], 4),\n",
        "                \"Wald\": round(wald[var], 3),\n",
        "                \"df\": 1,\n",
        "                \"Sig.\": round(pvals[var], 4),\n",
        "                \"Exp(B)\": round(expb[var], 4)\n",
        "            })\n",
        "    in_eq_df = pd.DataFrame(in_eq)\n",
        "    \n",
        "    # Variables Not in the Equation: show LRT for all other candidates (vs base model)\n",
        "    not_in = []\n",
        "    for _, row in lrt_df.iterrows():\n",
        "        var = row[\"variable\"]\n",
        "        if var == best_var:\n",
        "            continue\n",
        "        not_in.append({\n",
        "            \"Independent Variable\": var,\n",
        "            \"Score Statistic (LRT)\": None if pd.isna(row[\"lr_stat\"]) else round(row[\"lr_stat\"], 3),\n",
        "            \"Significance\": None if pd.isna(row[\"p_value\"]) else round(row[\"p_value\"], 4)\n",
        "        })\n",
        "    not_in_eq_df = pd.DataFrame(not_in)\n",
        "    \n",
        "    # Optionally truncate long lists\n",
        "    if max_vars_display is not None:\n",
        "        not_in_eq_df = not_in_eq_df.head(max_vars_display)\n",
        "    \n",
        "    # Print summary in textbook style\n",
        "    print(\"Table: Logistic Regression Stepwise Estimation — Adding\", best_var)\n",
        "    print(\"\\nOverall Model Fit: Goodness-of-Fit Measures\\n\")\n",
        "    print(goodness_df.to_string(index=False))\n",
        "    print(\"\\n\\nVariables in the Equation\\n\")\n",
        "    print(in_eq_df.to_string(index=False))\n",
        "    print(\"\\n\\nVariables Not in the Equation (candidates and LRT vs base)\\n\")\n",
        "    print(not_in_eq_df.to_string(index=False))\n",
        "    \n",
        "    return {\n",
        "        \"best_var\": best_var,\n",
        "        \"goodness_df\": goodness_df,\n",
        "        \"in_eq_df\": in_eq_df,\n",
        "        \"not_in_eq_df\": not_in_eq_df,\n",
        "        \"hl_table\": hl_table,\n",
        "        \"best_model\": best_model\n",
        "    }\n",
        "\n",
        "# ===== Example usage =====\n",
        "results = table_for_first_step(train_df, target_col=\"is_fraud\")\n",
        "good_df, in_df, notin_df = results[\"goodness_df\"], results[\"in_eq_df\"], results[\"not_in_eq_df\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#(寫錯了不要使用)\n",
        "from scipy.stats import chi2\n",
        "def table_for_first_step(train_df, target_col=\"is_fraud\", g_hl=10, max_vars_display=None, k=1):\n",
        "    \"\"\"\n",
        "    Automatically pick the best k variables (default=1) to add (by LRT vs base)\n",
        "    and produce tables like textbook.\n",
        "    \"\"\"\n",
        "    train_df = train_df.reset_index(drop=True)\n",
        "    y = train_df[target_col].astype(int).reset_index(drop=True)\n",
        "    candidates = list(train_df.columns.drop(target_col))\n",
        "    n = len(train_df)\n",
        "    \n",
        "    # Base model\n",
        "    X_base = sm.add_constant(pd.DataFrame({\"intercept\": np.ones(n)}))\n",
        "    base_model = sm.Logit(y, X_base).fit(disp=False)\n",
        "    ll_base = base_model.llf\n",
        "    minus2ll_base = -2 * ll_base\n",
        "\n",
        "    # Fit single-variable models for all candidates\n",
        "    lrt_list = []\n",
        "    for var in candidates:\n",
        "        try:\n",
        "            Xv = sm.add_constant(train_df[[var]])\n",
        "            mv = sm.Logit(y, Xv).fit(disp=False)\n",
        "            ll_v = mv.llf\n",
        "            lr_stat = -2 * (ll_base - ll_v)\n",
        "            pval = chi2.sf(lr_stat, df=1)\n",
        "            lrt_list.append({\"variable\": var, \"lr_stat\": lr_stat, \"p_value\": pval, \"ll_v\": ll_v})\n",
        "        except Exception:\n",
        "            lrt_list.append({\"variable\": var, \"lr_stat\": None, \"p_value\": None, \"ll_v\": None})\n",
        "    \n",
        "    lrt_df = pd.DataFrame(lrt_list).sort_values(\"p_value\", na_position=\"last\").reset_index(drop=True)\n",
        "\n",
        "    # ✅ pick top k variables\n",
        "    top_k_vars = lrt_df.dropna(subset=[\"p_value\"]).sort_values(\"p_value\").head(k)[\"variable\"].tolist()\n",
        "    best_var_display = \", \".join(top_k_vars)\n",
        "\n",
        "    # Fit model with chosen variables\n",
        "    X_best = sm.add_constant(train_df[top_k_vars])\n",
        "    best_model = sm.Logit(y, X_best).fit(disp=False)\n",
        "    ll_best = best_model.llf\n",
        "    minus2ll_best = -2 * ll_best\n",
        "\n",
        "    # Model fit improvements\n",
        "    change_from_base = minus2ll_best - minus2ll_base\n",
        "    df_lr = len(best_model.params) - len(base_model.params)\n",
        "    lr_stat_best = -2 * (ll_base - ll_best)\n",
        "    p_change = chi2.sf(lr_stat_best, df=df_lr)\n",
        "\n",
        "    # R2 variants\n",
        "    ll_null = ll_base\n",
        "    ll_model = ll_best\n",
        "    pseudo_r2 = 1 - (ll_model / ll_null)\n",
        "    r_cs = 1 - np.exp((2.0 / n) * (ll_null - ll_model))\n",
        "    r_max = 1 - np.exp((2.0 / n) * ll_null)\n",
        "    nagelkerke = r_cs / r_max if r_max != 0 else np.nan\n",
        "\n",
        "    # Hosmer-Lemeshow\n",
        "    preds = best_model.predict(X_best)\n",
        "    hl_chi2, hl_p, hl_table = hosmer_lemeshow_test(y, preds, g=g_hl)\n",
        "\n",
        "    # ✅ Table 1: Goodness of Fit\n",
        "    goodness_rows = [\n",
        "        {\"Measure\": \"-2 Log Likelihood (−2LL) value\", \"Value\": round(minus2ll_best, 3),\n",
        "         \"Change_from_Base\": round(change_from_base, 3), \"Change_pvalue\": round(p_change, 4)},\n",
        "        {\"Measure\": \"Cox and Snell R2\", \"Value\": round(r_cs, 3), \"Change_from_Base\": \"\", \"Change_pvalue\": \"\"},\n",
        "        {\"Measure\": \"Nagelkerke R2\", \"Value\": round(nagelkerke, 3), \"Change_from_Base\": \"\", \"Change_pvalue\": \"\"},\n",
        "        {\"Measure\": \"Pseudo R2 (McFadden)\", \"Value\": round(pseudo_r2, 3), \"Change_from_Base\": \"\", \"Change_pvalue\": \"\"},\n",
        "        {\"Measure\": \"Hosmer-Lemeshow χ2\", \"Value\": round(hl_chi2, 3), \"Change_from_Base\": \"\", \"Change_pvalue\": round(hl_p, 4)}\n",
        "    ]\n",
        "    goodness_df = pd.DataFrame(goodness_rows)\n",
        "\n",
        "    # ✅ Table 2: Variables in the Equation\n",
        "    params = best_model.params\n",
        "    bse = best_model.bse\n",
        "    z = params / bse\n",
        "    wald = (z ** 2)\n",
        "    pvals = best_model.pvalues\n",
        "    expb = np.exp(params)\n",
        "    in_eq = []\n",
        "    for var in top_k_vars + [\"const\"]:\n",
        "        if var in params.index:\n",
        "            in_eq.append({\n",
        "                \"Independent Variable\": var if var != \"const\" else \"Constant\",\n",
        "                \"B\": round(params[var], 4),\n",
        "                \"Std. Error\": round(bse[var], 4),\n",
        "                \"Wald\": round(wald[var], 3),\n",
        "                \"df\": 1,\n",
        "                \"Sig.\": round(pvals[var], 4),\n",
        "                \"Exp(B)\": round(expb[var], 4)\n",
        "            })\n",
        "    in_eq_df = pd.DataFrame(in_eq)\n",
        "\n",
        "    # ✅ Table 3: Variables Not in the Equation\n",
        "    not_in = []\n",
        "    for _, row in lrt_df.iterrows():\n",
        "        var = row[\"variable\"]\n",
        "        if var in top_k_vars:\n",
        "            continue\n",
        "        not_in.append({\n",
        "            \"Independent Variable\": var,\n",
        "            \"Score Statistic (LRT)\": None if pd.isna(row[\"lr_stat\"]) else round(row[\"lr_stat\"], 3),\n",
        "            \"Significance\": None if pd.isna(row[\"p_value\"]) else round(row[\"p_value\"], 4)\n",
        "        })\n",
        "    not_in_eq_df = pd.DataFrame(not_in)\n",
        "\n",
        "    if max_vars_display is not None:\n",
        "        not_in_eq_df = not_in_eq_df.head(max_vars_display)\n",
        "\n",
        "    # print results\n",
        "    print(f\"Table: Logistic Regression Stepwise Estimation — Adding {best_var_display}\")\n",
        "    print(\"\\nOverall Model Fit: Goodness-of-Fit Measures\\n\")\n",
        "    print(goodness_df.to_string(index=False))\n",
        "    print(\"\\n\\nVariables in the Equation\\n\")\n",
        "    print(in_eq_df.to_string(index=False))\n",
        "    print(\"\\n\\nVariables Not in the Equation (candidates and LRT vs base)\\n\")\n",
        "    print(not_in_eq_df.to_string(index=False))\n",
        "\n",
        "    return {\n",
        "        \"best_vars\": top_k_vars,\n",
        "        \"goodness_df\": goodness_df,\n",
        "        \"in_eq_df\": in_eq_df,\n",
        "        \"not_in_eq_df\": not_in_eq_df,\n",
        "        \"hl_table\": hl_table,\n",
        "        \"best_model\": best_model\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Matrix — Training Sample\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                   16                 10575   10591        0.2\n",
            "  Normal (0)                   54               7121325 7121379      100.0\n",
            "       Total                   70               7131900 7131970       99.9\n",
            "\n",
            "Classification Matrix — Holdout (Test) Sample\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                    4                  2737    2741        0.1\n",
            "  Normal (0)                   15               1780237 1780252      100.0\n",
            "       Total                   19               1782974 1782993       99.8\n"
          ]
        }
      ],
      "source": [
        "#(寫錯了先不要用)\n",
        "#在 train 與 test 上做預測並分類，並產出分類矩陣\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def classification_table(model, df, target_col=\"is_fraud\", cutoff=0.5):\n",
        "    \"\"\"\n",
        "    建立分類矩陣 (confusion matrix) 與正確率統計\n",
        "    \"\"\"\n",
        "    y_true = df[target_col].astype(int)\n",
        "    X = sm.add_constant(df[model.params.index.drop(\"const\")])\n",
        "    y_pred_prob = model.predict(X)\n",
        "    y_pred = (y_pred_prob >= cutoff).astype(int)\n",
        "    \n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
        "    TP, FN, FP, TN = cm.ravel()  # 注意順序是 [ [TP, FN], [FP, TN] ]\n",
        "    \n",
        "    fraud_total = TP + FN\n",
        "    normal_total = FP + TN\n",
        "    \n",
        "    fraud_correct = TP / fraud_total if fraud_total > 0 else 0\n",
        "    normal_correct = TN / normal_total if normal_total > 0 else 0\n",
        "    overall_correct = (TP + TN) / (fraud_total + normal_total)\n",
        "    \n",
        "    table = pd.DataFrame({\n",
        "        \"Actual Group\": [\"Fraud (1)\", \"Normal (0)\", \"Total\"],\n",
        "        \"Predicted Fraud (1)\": [TP, FP, TP+FP],\n",
        "        \"Predicted Normal (0)\": [FN, TN, FN+TN],\n",
        "        \"Total\": [fraud_total, normal_total, fraud_total + normal_total],\n",
        "        \"% Correct\": [round(fraud_correct*100, 1), round(normal_correct*100, 1), round(overall_correct*100, 1)]\n",
        "    })\n",
        "    \n",
        "    return table\n",
        "\n",
        "# 產出訓練集和測試集的分類矩陣\n",
        "best_model = results[\"best_model\"]\n",
        "\n",
        "train_table = classification_table(best_model, train_df, target_col=\"is_fraud\")\n",
        "test_table = classification_table(best_model, test_df, target_col=\"is_fraud\")\n",
        "\n",
        "print(\"Classification Matrix — Training Sample\")\n",
        "print(train_table.to_string(index=False))\n",
        "\n",
        "print(\"\\nClassification Matrix — Holdout (Test) Sample\")\n",
        "print(test_table.to_string(index=False))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0: Base model estimated. -2LL = 159110.612\n",
            "Step 1: Added amount, p = 0.0000, -2LL = 156596.132\n",
            "Step 2: Added zip, p = 0.0000, -2LL = 132160.472\n",
            "Step 3: Added longitude, p = 0.0000, -2LL = 130365.785\n",
            "Step 4: Added merchant_id, p = 0.0000, -2LL = 129422.859\n",
            "Step 5: Added use_chip_Swipe Transaction, p = 0.0000, -2LL = 128369.766\n",
            "Step 6: Added credit_limit, p = 0.0000, -2LL = 127721.557\n",
            "Step 7: Added num_credit_cards, p = 0.0000, -2LL = 127399.629\n",
            "Step 8: Added errors_missing_flag, p = 0.0000, -2LL = 127194.361\n",
            "Step 9: Added use_chip_Chip Transaction, p = 0.0000, -2LL = 126969.403\n",
            "Step 10: Added transaction_id, p = 0.0000, -2LL = 126659.120\n",
            "Step 11: Added yearly_income, p = 0.0000, -2LL = 126479.431\n",
            "Step 12: Added latitude, p = 0.0000, -2LL = 126331.866\n",
            "Step 13: Added client_id_x, p = 0.0000, -2LL = 126287.731\n",
            "Step 14: Added has_chip_YES, p = 0.0000, -2LL = 126259.387\n",
            "Step 15: Added credit_score, p = 0.0000, -2LL = 126231.397\n",
            "Step 16: Added retirement_age, p = 0.0001, -2LL = 126215.109\n",
            "Step 17: Added card_type_Credit, p = 0.0000, -2LL = 126196.468\n",
            "Step 18: Added card_type_Debit, p = 0.0000, -2LL = 126161.194\n",
            "Step 19: Added mcc_code, p = 0.0029, -2LL = 126152.192\n",
            "Step 20: Added card_brand_Visa, p = 0.0138, -2LL = 126146.098\n",
            "Step 21: Added card_brand_Mastercard, p = 0.0255, -2LL = 126141.149\n",
            "Step 22: Added card_brand_Amex, p = 0.0000, -2LL = 126119.895\n",
            "Step 23: Added card_id, p = 0.0250, -2LL = 126114.885\n",
            "\n",
            "✅ No more variables meet the entry threshold. Stepwise selection finished.\n",
            "\n",
            "Final model summary:\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:               is_fraud   No. Observations:              7131970\n",
            "Model:                          Logit   Df Residuals:                  7131945\n",
            "Method:                           MLE   Df Model:                           24\n",
            "Date:                Mon, 06 Oct 2025   Pseudo R-squ.:                  0.2074\n",
            "Time:                        20:05:54   Log-Likelihood:                -63057.\n",
            "converged:                       True   LL-Null:                       -79555.\n",
            "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
            "==============================================================================================\n",
            "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "----------------------------------------------------------------------------------------------\n",
            "const                         -5.3101      0.254    -20.889      0.000      -5.808      -4.812\n",
            "amount                         0.0026   4.97e-05     52.698      0.000       0.003       0.003\n",
            "zip                        -9.421e-05   1.37e-06    -68.580      0.000   -9.69e-05   -9.15e-05\n",
            "longitude                     -0.0208      0.001    -35.590      0.000      -0.022      -0.020\n",
            "merchant_id                 1.066e-05   3.72e-07     28.683      0.000    9.93e-06    1.14e-05\n",
            "use_chip_Swipe Transaction    -0.7149      0.040    -17.660      0.000      -0.794      -0.636\n",
            "credit_limit                 -1.5e-05   1.31e-06    -11.413      0.000   -1.76e-05   -1.24e-05\n",
            "num_credit_cards               0.0933      0.006     14.741      0.000       0.081       0.106\n",
            "errors_missing_flag           -0.7900      0.048    -16.317      0.000      -0.885      -0.695\n",
            "use_chip_Chip Transaction      0.8156      0.034     23.947      0.000       0.749       0.882\n",
            "transaction_id             -4.274e-08    2.4e-09    -17.790      0.000   -4.74e-08    -3.8e-08\n",
            "yearly_income              -7.414e-06   5.83e-07    -12.711      0.000   -8.56e-06   -6.27e-06\n",
            "latitude                      -0.0233      0.002    -11.936      0.000      -0.027      -0.020\n",
            "client_id_x                   -0.0001    1.7e-05     -6.582      0.000      -0.000   -7.87e-05\n",
            "has_chip_YES                  -0.1911      0.035     -5.409      0.000      -0.260      -0.122\n",
            "credit_score                   0.0007      0.000      4.433      0.000       0.000       0.001\n",
            "retirement_age                 0.0133      0.003      4.553      0.000       0.008       0.019\n",
            "card_type_Credit              -0.3022      0.041     -7.423      0.000      -0.382      -0.222\n",
            "card_type_Debit               -0.2335      0.041     -5.739      0.000      -0.313      -0.154\n",
            "mcc_code                   -3.558e-05   1.16e-05     -3.073      0.002   -5.83e-05   -1.29e-05\n",
            "card_brand_Visa               -0.3294      0.056     -5.844      0.000      -0.440      -0.219\n",
            "card_brand_Mastercard         -0.2932      0.057     -5.142      0.000      -0.405      -0.181\n",
            "card_brand_Amex               -0.3027      0.064     -4.742      0.000      -0.428      -0.178\n",
            "card_id                    -1.296e-05   5.85e-06     -2.218      0.027   -2.44e-05   -1.51e-06\n",
            "cvv                         3.144e-05   3.39e-05      0.928      0.354    -3.5e-05    9.79e-05\n",
            "==============================================================================================\n",
            "\n",
            "Possibly complete quasi-separation: A fraction 0.49 of observations can be\n",
            "perfectly predicted. This might indicate that there is complete\n",
            "quasi-separation. In this case some parameters will not be identified.\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Step",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Variable Entered",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "-2 Log Likelihood",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "956e14ed-8550-4c2d-817f-39c5975b5e54",
              "rows": [
                [
                  "0",
                  "0",
                  null,
                  "159110.61205098676"
                ],
                [
                  "1",
                  "1",
                  "amount",
                  "156596.1318859173"
                ],
                [
                  "2",
                  "2",
                  "zip",
                  "132160.47242328618"
                ],
                [
                  "3",
                  "3",
                  "longitude",
                  "130365.78537629134"
                ],
                [
                  "4",
                  "4",
                  "merchant_id",
                  "129422.85897686762"
                ],
                [
                  "5",
                  "5",
                  "use_chip_Swipe Transaction",
                  "128369.76553755146"
                ],
                [
                  "6",
                  "6",
                  "credit_limit",
                  "127721.5573537219"
                ],
                [
                  "7",
                  "7",
                  "num_credit_cards",
                  "127399.6289361857"
                ],
                [
                  "8",
                  "8",
                  "errors_missing_flag",
                  "127194.36144428997"
                ],
                [
                  "9",
                  "9",
                  "use_chip_Chip Transaction",
                  "126969.403353223"
                ],
                [
                  "10",
                  "10",
                  "transaction_id",
                  "126659.12047431353"
                ],
                [
                  "11",
                  "11",
                  "yearly_income",
                  "126479.43146008762"
                ],
                [
                  "12",
                  "12",
                  "latitude",
                  "126331.86559310334"
                ],
                [
                  "13",
                  "13",
                  "client_id_x",
                  "126287.73082180246"
                ],
                [
                  "14",
                  "14",
                  "has_chip_YES",
                  "126259.38712661443"
                ],
                [
                  "15",
                  "15",
                  "credit_score",
                  "126231.39740436297"
                ],
                [
                  "16",
                  "16",
                  "retirement_age",
                  "126215.10906426272"
                ],
                [
                  "17",
                  "17",
                  "card_type_Credit",
                  "126196.46814774227"
                ],
                [
                  "18",
                  "18",
                  "card_type_Debit",
                  "126161.1941248596"
                ],
                [
                  "19",
                  "19",
                  "mcc_code",
                  "126152.1919911101"
                ],
                [
                  "20",
                  "20",
                  "card_brand_Visa",
                  "126146.09812282966"
                ],
                [
                  "21",
                  "21",
                  "card_brand_Mastercard",
                  "126141.1489606208"
                ],
                [
                  "22",
                  "22",
                  "card_brand_Amex",
                  "126119.89492591114"
                ],
                [
                  "23",
                  "23",
                  "card_id",
                  "126114.88498004613"
                ]
              ],
              "shape": {
                "columns": 3,
                "rows": 24
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Step</th>\n",
              "      <th>Variable Entered</th>\n",
              "      <th>-2 Log Likelihood</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>159110.612051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>amount</td>\n",
              "      <td>156596.131886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>zip</td>\n",
              "      <td>132160.472423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>longitude</td>\n",
              "      <td>130365.785376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>merchant_id</td>\n",
              "      <td>129422.858977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>use_chip_Swipe Transaction</td>\n",
              "      <td>128369.765538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>credit_limit</td>\n",
              "      <td>127721.557354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>num_credit_cards</td>\n",
              "      <td>127399.628936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>errors_missing_flag</td>\n",
              "      <td>127194.361444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>use_chip_Chip Transaction</td>\n",
              "      <td>126969.403353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>transaction_id</td>\n",
              "      <td>126659.120474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>yearly_income</td>\n",
              "      <td>126479.431460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>latitude</td>\n",
              "      <td>126331.865593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>client_id_x</td>\n",
              "      <td>126287.730822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>has_chip_YES</td>\n",
              "      <td>126259.387127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>credit_score</td>\n",
              "      <td>126231.397404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>retirement_age</td>\n",
              "      <td>126215.109064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>card_type_Credit</td>\n",
              "      <td>126196.468148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>card_type_Debit</td>\n",
              "      <td>126161.194125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>mcc_code</td>\n",
              "      <td>126152.191991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>card_brand_Visa</td>\n",
              "      <td>126146.098123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>card_brand_Mastercard</td>\n",
              "      <td>126141.148961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>card_brand_Amex</td>\n",
              "      <td>126119.894926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>card_id</td>\n",
              "      <td>126114.884980</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Step            Variable Entered  -2 Log Likelihood\n",
              "0      0                        None      159110.612051\n",
              "1      1                      amount      156596.131886\n",
              "2      2                         zip      132160.472423\n",
              "3      3                   longitude      130365.785376\n",
              "4      4                 merchant_id      129422.858977\n",
              "5      5  use_chip_Swipe Transaction      128369.765538\n",
              "6      6                credit_limit      127721.557354\n",
              "7      7            num_credit_cards      127399.628936\n",
              "8      8         errors_missing_flag      127194.361444\n",
              "9      9   use_chip_Chip Transaction      126969.403353\n",
              "10    10              transaction_id      126659.120474\n",
              "11    11               yearly_income      126479.431460\n",
              "12    12                    latitude      126331.865593\n",
              "13    13                 client_id_x      126287.730822\n",
              "14    14                has_chip_YES      126259.387127\n",
              "15    15                credit_score      126231.397404\n",
              "16    16              retirement_age      126215.109064\n",
              "17    17            card_type_Credit      126196.468148\n",
              "18    18             card_type_Debit      126161.194125\n",
              "19    19                    mcc_code      126152.191991\n",
              "20    20             card_brand_Visa      126146.098123\n",
              "21    21       card_brand_Mastercard      126141.148961\n",
              "22    22             card_brand_Amex      126119.894926\n",
              "23    23                     card_id      126114.884980"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Stepwise Selection all variables\n",
        "\n",
        "def stepwise_logit(train_df, target_col=\"is_fraud\", entry_threshold=0.05):\n",
        "    # ✅ 確保索引對齊\n",
        "    train_df = train_df.reset_index(drop=True)\n",
        "    y = train_df[target_col].reset_index(drop=True)\n",
        "    \n",
        "    candidate_vars = list(train_df.columns.drop(target_col))\n",
        "    included_vars = []\n",
        "    step_results = []\n",
        "    \n",
        "    # Base model (only intercept)\n",
        "    X_base = sm.add_constant(pd.DataFrame({\"intercept\": [1]*len(train_df)}))\n",
        "    base_model = sm.Logit(y, X_base).fit(disp=False)\n",
        "    base_ll = -2 * base_model.llf\n",
        "    step_results.append({\"Step\": 0, \"Variable Entered\": None, \"-2 Log Likelihood\": base_ll})\n",
        "    \n",
        "    print(f\"Step 0: Base model estimated. -2LL = {base_ll:.3f}\")\n",
        "    \n",
        "    step = 1\n",
        "    while True:\n",
        "        best_pval = 1\n",
        "        best_var = None\n",
        "        best_model = None\n",
        "        \n",
        "        for var in candidate_vars:\n",
        "            try:\n",
        "                X_temp = sm.add_constant(train_df[included_vars + [var]])\n",
        "                model_temp = sm.Logit(y, X_temp).fit(disp=False)\n",
        "                pval = model_temp.pvalues[var]\n",
        "                \n",
        "                if pval < best_pval:\n",
        "                    best_pval = pval\n",
        "                    best_var = var\n",
        "                    best_model = model_temp\n",
        "                    \n",
        "            except Exception:\n",
        "                continue\n",
        "        \n",
        "        if best_var is None or best_pval > entry_threshold:\n",
        "            print(\"\\n✅ No more variables meet the entry threshold. Stepwise selection finished.\")\n",
        "            break\n",
        "        \n",
        "        included_vars.append(best_var)\n",
        "        candidate_vars.remove(best_var)\n",
        "        \n",
        "        ll = -2 * best_model.llf\n",
        "        step_results.append({\"Step\": step, \"Variable Entered\": best_var, \"-2 Log Likelihood\": ll})\n",
        "        \n",
        "        print(f\"Step {step}: Added {best_var}, p = {best_pval:.4f}, -2LL = {ll:.3f}\")\n",
        "        step += 1\n",
        "    \n",
        "    print(\"\\nFinal model summary:\")\n",
        "    print(best_model.summary())\n",
        "    \n",
        "    step_df = pd.DataFrame(step_results)\n",
        "    return step_df, best_model\n",
        "\n",
        "# 🚀 執行\n",
        "step_df, final_model = stepwise_logit(train_df, target_col=\"is_fraud\")\n",
        "step_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def stepwise_logit_with_k_tables(train_df, test_df, dep_var=\"is_fraud\", k=314657018,\n",
        "                                 threshold_in=0.05, threshold_out=0.10):\n",
        "    \"\"\"\n",
        "    Stepwise logistic regression (forward + backward) with flexible k control,\n",
        "    and 3 formatted output tables like table_for_first_step().\n",
        "    \"\"\"\n",
        "\n",
        "    y_train = train_df[dep_var]\n",
        "    X_train = train_df.drop(columns=[dep_var])\n",
        "    y_test = test_df[dep_var]\n",
        "    X_test = test_df.drop(columns=[dep_var])\n",
        "\n",
        "    included = []\n",
        "    step = 0\n",
        "    full_mode = (k == 314657018)\n",
        "    base_model = None\n",
        "\n",
        "    while True:\n",
        "        step += 1\n",
        "        changed = False\n",
        "\n",
        "        # ---------- Forward Step ----------\n",
        "        excluded = list(set(X_train.columns) - set(included))\n",
        "        new_pvals = pd.Series(index=excluded, dtype=float)\n",
        "        for new_var in excluded:\n",
        "            try:\n",
        "                model = sm.Logit(y_train, sm.add_constant(X_train[included + [new_var]])).fit(disp=False)\n",
        "                new_pvals[new_var] = model.pvalues[new_var]\n",
        "            except Exception:\n",
        "                new_pvals[new_var] = np.nan\n",
        "\n",
        "        if new_pvals.empty:\n",
        "            break\n",
        "\n",
        "        best_pval = new_pvals.min()\n",
        "        if best_pval < threshold_in:\n",
        "            best_var = new_pvals.idxmin()\n",
        "            included.append(best_var)\n",
        "            changed = True\n",
        "\n",
        "        # ---------- Backward Step ----------\n",
        "        if included:\n",
        "            model = sm.Logit(y_train, sm.add_constant(X_train[included])).fit(disp=False)\n",
        "            pvalues = model.pvalues.iloc[1:]\n",
        "            worst_pval = pvalues.max()\n",
        "            if worst_pval > threshold_out:\n",
        "                worst_var = pvalues.idxmax()\n",
        "                included.remove(worst_var)\n",
        "                changed = True\n",
        "\n",
        "        # ---------- 結束條件 ----------\n",
        "        if not changed:\n",
        "            break\n",
        "        if not full_mode and len(included) >= k:\n",
        "            break\n",
        "\n",
        "    # ========= Final Model =========\n",
        "    final_model = sm.Logit(y_train, sm.add_constant(X_train[included])).fit(disp=False)\n",
        "    ll_full = final_model.llf\n",
        "    ll_null = sm.Logit(y_train, sm.add_constant(np.ones(len(y_train)))).fit(disp=False).llf\n",
        "\n",
        "    # 1️⃣ Overall Model Fit\n",
        "    ll_diff = -2 * (ll_null - ll_full)\n",
        "    df_diff = len(final_model.params) - 1\n",
        "    p_value = stats.chi2.sf(ll_diff, df_diff)\n",
        "\n",
        "    overall_fit = pd.DataFrame({\n",
        "        \"Measure\": [\n",
        "            \"-2 Log Likelihood (−2LL) value\",\n",
        "            \"Cox and Snell R2\",\n",
        "            \"Nagelkerke R2\",\n",
        "            \"Pseudo R2 (McFadden)\",\n",
        "            \"Hosmer-Lemeshow χ2\"\n",
        "        ],\n",
        "        \"Value\": [\n",
        "            round(-2 * ll_full, 3),\n",
        "            round(1 - np.exp((2 / len(y_train)) * (ll_null - ll_full)), 3),\n",
        "            round((1 - np.exp((2 / len(y_train)) * (ll_null - ll_full))) / (1 - np.exp(2 * ll_null / len(y_train))), 3),\n",
        "            round(1 - (ll_full / ll_null), 3),\n",
        "            round(ll_diff, 3)\n",
        "        ],\n",
        "        \"Change_from_Base\": [\n",
        "            round(-2 * (ll_null - ll_full), 3),\n",
        "            \"\", \"\", \"\", \"\"\n",
        "        ],\n",
        "        \"Change_pvalue\": [\n",
        "            round(p_value, 4),\n",
        "            \"\", \"\", \"\", \"\"\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    # 2️⃣ Variables in the Equation\n",
        "    coef_df = pd.DataFrame({\n",
        "        \"Independent Variable\": final_model.params.index,\n",
        "        \"B\": final_model.params.values,\n",
        "        \"Std. Error\": final_model.bse.values,\n",
        "        \"Wald\": (final_model.params / final_model.bse) ** 2,\n",
        "        \"df\": 1,\n",
        "        \"Sig.\": final_model.pvalues.values,\n",
        "        \"Exp(B)\": np.exp(final_model.params.values)\n",
        "    })\n",
        "    coef_df = coef_df.reset_index(drop=True)\n",
        "\n",
        "    # 3️⃣ Variables Not in the Equation\n",
        "    excluded_vars = [v for v in X_train.columns if v not in included]\n",
        "    not_in_eq = []\n",
        "    for var in excluded_vars:\n",
        "        try:\n",
        "            temp_model = sm.Logit(y_train, sm.add_constant(X_train[included + [var]])).fit(disp=False)\n",
        "            lr_stat = -2 * (final_model.llf - temp_model.llf)\n",
        "            p_val = stats.chi2.sf(lr_stat, 1)\n",
        "            not_in_eq.append({\"Independent Variable\": var,\n",
        "                              \"Score Statistic (LRT)\": round(lr_stat, 3),\n",
        "                              \"Significance\": round(p_val, 4)})\n",
        "        except Exception:\n",
        "            not_in_eq.append({\"Independent Variable\": var,\n",
        "                              \"Score Statistic (LRT)\": None,\n",
        "                              \"Significance\": None})\n",
        "\n",
        "    not_in_eq_df = pd.DataFrame(not_in_eq)\n",
        "\n",
        "    # 額外：Train / Test Accuracy\n",
        "    train_pred = (final_model.predict(sm.add_constant(X_train[included])) > 0.5).astype(int)\n",
        "    test_pred = (final_model.predict(sm.add_constant(X_test[included])) > 0.5).astype(int)\n",
        "    train_acc = (train_pred == y_train).mean()\n",
        "    test_acc = (test_pred == y_test).mean()\n",
        "\n",
        "    print(f\"\\n✅ Stepwise completed with {len(included)} variables: {included}\")\n",
        "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    return overall_fit, coef_df, not_in_eq_df, final_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Stepwise completed with 1 variables: ['amount']\n",
            "Train Accuracy: 0.9985, Test Accuracy: 0.9985\n",
            "=== Overall Model Fit ===\n",
            "                          Measure       Value Change_from_Base Change_pvalue\n",
            "0  -2 Log Likelihood (−2LL) value  156596.132          2514.48           0.0\n",
            "1                Cox and Snell R2       0.000                               \n",
            "2                   Nagelkerke R2       0.016                               \n",
            "3            Pseudo R2 (McFadden)       0.016                               \n",
            "4              Hosmer-Lemeshow χ2    2514.480                               \n",
            "\n",
            "=== Variables in the Equation ===\n",
            "  Independent Variable         B  Std. Error           Wald  df  Sig.  \\\n",
            "0                const -6.669261    0.010435  408490.171355   1   0.0   \n",
            "1               amount  0.002635    0.000041    4155.604769   1   0.0   \n",
            "\n",
            "     Exp(B)  \n",
            "0  0.001269  \n",
            "1  1.002638  \n",
            "\n",
            "=== Variables Not in the Equation ===\n",
            "          Independent Variable  Score Statistic (LRT)  Significance\n",
            "0               transaction_id                  2.224        0.1359\n",
            "1                  client_id_x                  0.810        0.3680\n",
            "2                      card_id                  7.316        0.0068\n",
            "3                  merchant_id                269.892        0.0000\n",
            "4                          zip              24435.659        0.0000\n",
            "5                     mcc_code               1213.597        0.0000\n",
            "6          errors_missing_flag                338.804        0.0000\n",
            "7    use_chip_Chip Transaction                665.857        0.0000\n",
            "8   use_chip_Swipe Transaction               8443.861        0.0000\n",
            "9                  current_age                126.100        0.0000\n",
            "10              retirement_age                  1.915        0.1664\n",
            "11                    latitude                 21.875        0.0000\n",
            "12                   longitude                 11.576        0.0007\n",
            "13               yearly_income                321.943        0.0000\n",
            "14                  total_debt                123.778        0.0000\n",
            "15                credit_score                 14.251        0.0002\n",
            "16            num_credit_cards                337.445        0.0000\n",
            "17                 gender_Male                  1.713        0.1906\n",
            "18                         cvv                  0.770        0.3801\n",
            "19            num_cards_issued                  0.034        0.8539\n",
            "20                credit_limit                397.394        0.0000\n",
            "21            card_type_Credit                  3.281        0.0701\n",
            "22             card_type_Debit                 98.707        0.0000\n",
            "23             card_brand_Amex                  0.704        0.4015\n",
            "24       card_brand_Mastercard                  0.076        0.7825\n",
            "25             card_brand_Visa                  8.015        0.0046\n",
            "26                has_chip_YES                 14.057        0.0002\n",
            "\n",
            "================================================\n",
            "\n",
            "=== Accuracy in Training and Testing dataset ===\n",
            "\n",
            "=== Classification Matrix — Training Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                   20                 10571   10591        0.2\n",
            "  Normal (0)                   49               7121330 7121379      100.0\n",
            "       Total                   69               7131901 7131970       99.9\n",
            "\n",
            "=== Classification Matrix — Holdout (Test) Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                    7                  2734    2741        0.3\n",
            "  Normal (0)                   14               1780238 1780252      100.0\n",
            "       Total                   21               1782972 1782993       99.8\n"
          ]
        }
      ],
      "source": [
        "overall_fit, coef_df, not_in_eq_df, model_0 = stepwise_logit_with_k_tables(\n",
        "    train_df, test_df, dep_var=\"is_fraud\", k=0\n",
        ")\n",
        "\n",
        "\n",
        "print(\"=== Overall Model Fit ===\")\n",
        "print(overall_fit)\n",
        "\n",
        "print(\"\\n=== Variables in the Equation ===\")\n",
        "print(coef_df)\n",
        "\n",
        "print(\"\\n=== Variables Not in the Equation ===\")\n",
        "print(not_in_eq_df)\n",
        "\n",
        "print(\"\\n================================================\")\n",
        "print(\"\\n=== Accuracy in Training and Testing dataset ===\")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def classification_table(model, df, target_col=\"is_fraud\", cutoff=0.5):\n",
        "    y_true = df[target_col].astype(int)\n",
        "    X = sm.add_constant(df[model.params.index.drop(\"const\")])\n",
        "    y_pred_prob = model.predict(X)\n",
        "    y_pred = (y_pred_prob >= cutoff).astype(int)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
        "    TP, FN, FP, TN = cm.ravel()\n",
        "\n",
        "    fraud_total = TP + FN\n",
        "    normal_total = FP + TN\n",
        "\n",
        "    fraud_correct = TP / fraud_total if fraud_total > 0 else 0\n",
        "    normal_correct = TN / normal_total if normal_total > 0 else 0\n",
        "    overall_correct = (TP + TN) / (fraud_total + normal_total)\n",
        "\n",
        "    table = pd.DataFrame({\n",
        "        \"Actual Group\": [\"Fraud (1)\", \"Normal (0)\", \"Total\"],\n",
        "        \"Predicted Fraud (1)\": [TP, FP, TP + FP],\n",
        "        \"Predicted Normal (0)\": [FN, TN, FN + TN],\n",
        "        \"Total\": [fraud_total, normal_total, fraud_total + normal_total],\n",
        "        \"% Correct\": [\n",
        "            round(fraud_correct * 100, 1),\n",
        "            round(normal_correct * 100, 1),\n",
        "            round(overall_correct * 100, 1),\n",
        "        ],\n",
        "    })\n",
        "    return table\n",
        "\n",
        "# Step 3. 產出訓練集和測試集的結果表\n",
        "train_table = classification_table(model_0, train_df, target_col=\"is_fraud\")\n",
        "test_table = classification_table(model_0, test_df, target_col=\"is_fraud\")\n",
        "\n",
        "print(\"\\n=== Classification Matrix — Training Sample ===\")\n",
        "print(train_table.to_string(index=False))\n",
        "print(\"\\n=== Classification Matrix — Holdout (Test) Sample ===\")\n",
        "print(test_table.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Stepwise completed with 2 variables: ['amount', 'zip']\n",
            "Train Accuracy: 0.9985, Test Accuracy: 0.9985\n",
            "=== Overall Model Fit ===\n",
            "                          Measure       Value Change_from_Base Change_pvalue\n",
            "0  -2 Log Likelihood (−2LL) value  132160.472         26950.14           0.0\n",
            "1                Cox and Snell R2       0.004                               \n",
            "2                   Nagelkerke R2       0.171                               \n",
            "3            Pseudo R2 (McFadden)       0.169                               \n",
            "4              Hosmer-Lemeshow χ2   26950.140                               \n",
            "\n",
            "=== Variables in the Equation ===\n",
            "  Independent Variable         B  Std. Error           Wald  df  Sig.  \\\n",
            "0                const -5.042287    0.011809  182312.965555   1   0.0   \n",
            "1               amount  0.002291    0.000045    2574.184666   1   0.0   \n",
            "2                  zip -0.000101    0.000001    7453.420607   1   0.0   \n",
            "\n",
            "     Exp(B)  \n",
            "0  0.006459  \n",
            "1  1.002293  \n",
            "2  0.999899  \n",
            "\n",
            "=== Variables Not in the Equation ===\n",
            "          Independent Variable  Score Statistic (LRT)  Significance\n",
            "0               transaction_id                  1.149        0.2838\n",
            "1                  client_id_x                 43.012        0.0000\n",
            "2                      card_id                  5.104        0.0239\n",
            "3                  merchant_id                741.511        0.0000\n",
            "4                     mcc_code                  0.388        0.5336\n",
            "5          errors_missing_flag                237.637        0.0000\n",
            "6    use_chip_Chip Transaction                385.363        0.0000\n",
            "7   use_chip_Swipe Transaction               1460.427        0.0000\n",
            "8                  current_age                157.508        0.0000\n",
            "9               retirement_age                 30.813        0.0000\n",
            "10                    latitude                504.700        0.0000\n",
            "11                   longitude               1794.687        0.0000\n",
            "12               yearly_income               1190.288        0.0000\n",
            "13                  total_debt                344.124        0.0000\n",
            "14                credit_score                 95.914        0.0000\n",
            "15            num_credit_cards                452.970        0.0000\n",
            "16                 gender_Male                  3.306        0.0690\n",
            "17                         cvv                  7.397        0.0065\n",
            "18            num_cards_issued                  4.242        0.0394\n",
            "19                credit_limit                987.600        0.0000\n",
            "20            card_type_Credit                 15.493        0.0001\n",
            "21             card_type_Debit                131.113        0.0000\n",
            "22             card_brand_Amex                  0.092        0.7621\n",
            "23       card_brand_Mastercard                  0.286        0.5925\n",
            "24             card_brand_Visa                  7.784        0.0053\n",
            "25                has_chip_YES                  0.049        0.8254\n",
            "\n",
            "================================================\n",
            "\n",
            "=== Accuracy in Training and Testing dataset ===\n",
            "\n",
            "=== Classification Matrix — Training Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                   20                 10571   10591        0.2\n",
            "  Normal (0)                   49               7121330 7121379      100.0\n",
            "       Total                   69               7131901 7131970       99.9\n",
            "\n",
            "=== Classification Matrix — Holdout (Test) Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                    7                  2734    2741        0.3\n",
            "  Normal (0)                   14               1780238 1780252      100.0\n",
            "       Total                   21               1782972 1782993       99.8\n"
          ]
        }
      ],
      "source": [
        "overall_fit, coef_df, not_in_eq_df, model_2 = stepwise_logit_with_k_tables(\n",
        "    train_df, test_df, dep_var=\"is_fraud\", k=2\n",
        ")\n",
        "\n",
        "\n",
        "print(\"=== Overall Model Fit ===\")\n",
        "print(overall_fit)\n",
        "\n",
        "print(\"\\n=== Variables in the Equation ===\")\n",
        "print(coef_df)\n",
        "\n",
        "print(\"\\n=== Variables Not in the Equation ===\")\n",
        "print(not_in_eq_df)\n",
        "\n",
        "print(\"\\n================================================\")\n",
        "print(\"\\n=== Accuracy in Training and Testing dataset ===\")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def classification_table(model, df, target_col=\"is_fraud\", cutoff=0.5):\n",
        "    y_true = df[target_col].astype(int)\n",
        "    X = sm.add_constant(df[model.params.index.drop(\"const\")])\n",
        "    y_pred_prob = model.predict(X)\n",
        "    y_pred = (y_pred_prob >= cutoff).astype(int)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
        "    TP, FN, FP, TN = cm.ravel()\n",
        "\n",
        "    fraud_total = TP + FN\n",
        "    normal_total = FP + TN\n",
        "\n",
        "    fraud_correct = TP / fraud_total if fraud_total > 0 else 0\n",
        "    normal_correct = TN / normal_total if normal_total > 0 else 0\n",
        "    overall_correct = (TP + TN) / (fraud_total + normal_total)\n",
        "\n",
        "    table = pd.DataFrame({\n",
        "        \"Actual Group\": [\"Fraud (1)\", \"Normal (0)\", \"Total\"],\n",
        "        \"Predicted Fraud (1)\": [TP, FP, TP + FP],\n",
        "        \"Predicted Normal (0)\": [FN, TN, FN + TN],\n",
        "        \"Total\": [fraud_total, normal_total, fraud_total + normal_total],\n",
        "        \"% Correct\": [\n",
        "            round(fraud_correct * 100, 1),\n",
        "            round(normal_correct * 100, 1),\n",
        "            round(overall_correct * 100, 1),\n",
        "        ],\n",
        "    })\n",
        "    return table\n",
        "\n",
        "# Step 3. 產出訓練集和測試集的結果表\n",
        "train_table = classification_table(model_2, train_df, target_col=\"is_fraud\")\n",
        "test_table = classification_table(model_2, test_df, target_col=\"is_fraud\")\n",
        "\n",
        "print(\"\\n=== Classification Matrix — Training Sample ===\")\n",
        "print(train_table.to_string(index=False))\n",
        "print(\"\\n=== Classification Matrix — Holdout (Test) Sample ===\")\n",
        "print(test_table.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Stepwise completed with 3 variables: ['amount', 'zip', 'longitude']\n",
            "Train Accuracy: 0.9985, Test Accuracy: 0.9985\n",
            "=== Overall Model Fit ===\n",
            "                          Measure       Value Change_from_Base Change_pvalue\n",
            "0  -2 Log Likelihood (−2LL) value  130365.785        28744.827           0.0\n",
            "1                Cox and Snell R2       0.004                               \n",
            "2                   Nagelkerke R2       0.182                               \n",
            "3            Pseudo R2 (McFadden)       0.181                               \n",
            "4              Hosmer-Lemeshow χ2   28744.827                               \n",
            "\n",
            "=== Variables in the Equation ===\n",
            "  Independent Variable         B  Std. Error          Wald  df  Sig.    Exp(B)\n",
            "0                const -7.173969    0.050525  20160.905638   1   0.0  0.000766\n",
            "1               amount  0.002290    0.000045   2569.711326   1   0.0  1.002293\n",
            "2                  zip -0.000090    0.000001   6942.907659   1   0.0  0.999911\n",
            "3            longitude -0.023565    0.000522   2040.979358   1   0.0  0.976711\n",
            "\n",
            "=== Variables Not in the Equation ===\n",
            "          Independent Variable  Score Statistic (LRT)  Significance\n",
            "0               transaction_id                  1.366        0.2425\n",
            "1                  client_id_x                 84.225        0.0000\n",
            "2                      card_id                 18.269        0.0000\n",
            "3                  merchant_id                942.926        0.0000\n",
            "4                     mcc_code                 15.292        0.0001\n",
            "5          errors_missing_flag                224.322        0.0000\n",
            "6    use_chip_Chip Transaction                786.069        0.0000\n",
            "7   use_chip_Swipe Transaction                975.627        0.0000\n",
            "8                  current_age                 42.508        0.0000\n",
            "9               retirement_age                 22.077        0.0000\n",
            "10                    latitude                110.494        0.0000\n",
            "11               yearly_income                791.044        0.0000\n",
            "12                  total_debt                190.573        0.0000\n",
            "13                credit_score                 76.326        0.0000\n",
            "14            num_credit_cards                271.419        0.0000\n",
            "15                 gender_Male                  0.107        0.7433\n",
            "16                         cvv                  4.247        0.0393\n",
            "17            num_cards_issued                  2.148        0.1427\n",
            "18                credit_limit                817.642        0.0000\n",
            "19            card_type_Credit                  9.912        0.0016\n",
            "20             card_type_Debit                109.428        0.0000\n",
            "21             card_brand_Amex                  0.038        0.8458\n",
            "22       card_brand_Mastercard                  0.022        0.8831\n",
            "23             card_brand_Visa                  7.596        0.0059\n",
            "24                has_chip_YES                  2.757        0.0968\n",
            "\n",
            "================================================\n",
            "\n",
            "=== Accuracy in Training and Testing dataset ===\n",
            "\n",
            "=== Classification Matrix — Training Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                   14                 10577   10591        0.1\n",
            "  Normal (0)                   54               7121325 7121379      100.0\n",
            "       Total                   68               7131902 7131970       99.9\n",
            "\n",
            "=== Classification Matrix — Holdout (Test) Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                    4                  2737    2741        0.1\n",
            "  Normal (0)                   14               1780238 1780252      100.0\n",
            "       Total                   18               1782975 1782993       99.8\n"
          ]
        }
      ],
      "source": [
        "overall_fit, coef_df, not_in_eq_df, model_3 = stepwise_logit_with_k_tables(\n",
        "    train_df, test_df, dep_var=\"is_fraud\", k=3\n",
        ")\n",
        "\n",
        "\n",
        "print(\"=== Overall Model Fit ===\")\n",
        "print(overall_fit)\n",
        "\n",
        "print(\"\\n=== Variables in the Equation ===\")\n",
        "print(coef_df)\n",
        "\n",
        "print(\"\\n=== Variables Not in the Equation ===\")\n",
        "print(not_in_eq_df)\n",
        "\n",
        "print(\"\\n================================================\")\n",
        "print(\"\\n=== Accuracy in Training and Testing dataset ===\")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def classification_table(model, df, target_col=\"is_fraud\", cutoff=0.5):\n",
        "    y_true = df[target_col].astype(int)\n",
        "    X = sm.add_constant(df[model.params.index.drop(\"const\")])\n",
        "    y_pred_prob = model.predict(X)\n",
        "    y_pred = (y_pred_prob >= cutoff).astype(int)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
        "    TP, FN, FP, TN = cm.ravel()\n",
        "\n",
        "    fraud_total = TP + FN\n",
        "    normal_total = FP + TN\n",
        "\n",
        "    fraud_correct = TP / fraud_total if fraud_total > 0 else 0\n",
        "    normal_correct = TN / normal_total if normal_total > 0 else 0\n",
        "    overall_correct = (TP + TN) / (fraud_total + normal_total)\n",
        "\n",
        "    table = pd.DataFrame({\n",
        "        \"Actual Group\": [\"Fraud (1)\", \"Normal (0)\", \"Total\"],\n",
        "        \"Predicted Fraud (1)\": [TP, FP, TP + FP],\n",
        "        \"Predicted Normal (0)\": [FN, TN, FN + TN],\n",
        "        \"Total\": [fraud_total, normal_total, fraud_total + normal_total],\n",
        "        \"% Correct\": [\n",
        "            round(fraud_correct * 100, 1),\n",
        "            round(normal_correct * 100, 1),\n",
        "            round(overall_correct * 100, 1),\n",
        "        ],\n",
        "    })\n",
        "    return table\n",
        "\n",
        "# Step 3. 產出訓練集和測試集的結果表\n",
        "train_table = classification_table(model_3, train_df, target_col=\"is_fraud\")\n",
        "test_table = classification_table(model_3, test_df, target_col=\"is_fraud\")\n",
        "\n",
        "print(\"\\n=== Classification Matrix — Training Sample ===\")\n",
        "print(train_table.to_string(index=False))\n",
        "print(\"\\n=== Classification Matrix — Holdout (Test) Sample ===\")\n",
        "print(test_table.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Stepwise completed with 4 variables: ['amount', 'zip', 'longitude', 'merchant_id']\n",
            "Train Accuracy: 0.9985, Test Accuracy: 0.9985\n",
            "=== Overall Model Fit ===\n",
            "                          Measure       Value Change_from_Base Change_pvalue\n",
            "0  -2 Log Likelihood (−2LL) value  129422.859        29687.753           0.0\n",
            "1                Cox and Snell R2       0.004                               \n",
            "2                   Nagelkerke R2       0.188                               \n",
            "3            Pseudo R2 (McFadden)       0.187                               \n",
            "4              Hosmer-Lemeshow χ2   29687.753                               \n",
            "\n",
            "=== Variables in the Equation ===\n",
            "  Independent Variable         B    Std. Error          Wald  df  \\\n",
            "0                const -7.811634  5.447445e-02  20563.548341   1   \n",
            "1               amount  0.002258  4.587596e-05   2423.164577   1   \n",
            "2                  zip -0.000091  1.088713e-06   7041.973083   1   \n",
            "3            longitude -0.024936  5.202238e-04   2297.553695   1   \n",
            "4          merchant_id  0.000011  3.543440e-07    959.021651   1   \n",
            "\n",
            "            Sig.    Exp(B)  \n",
            "0   0.000000e+00  0.000405  \n",
            "1   0.000000e+00  1.002261  \n",
            "2   0.000000e+00  0.999909  \n",
            "3   0.000000e+00  0.975373  \n",
            "4  1.451004e-210  1.000011  \n",
            "\n",
            "=== Variables Not in the Equation ===\n",
            "          Independent Variable  Score Statistic (LRT)  Significance\n",
            "0               transaction_id                  0.866        0.3522\n",
            "1                  client_id_x                 68.583        0.0000\n",
            "2                      card_id                 11.664        0.0006\n",
            "3                     mcc_code                 13.195        0.0003\n",
            "4          errors_missing_flag                217.195        0.0000\n",
            "5    use_chip_Chip Transaction                712.651        0.0000\n",
            "6   use_chip_Swipe Transaction               1053.093        0.0000\n",
            "7                  current_age                 61.879        0.0000\n",
            "8               retirement_age                 27.315        0.0000\n",
            "9                     latitude                166.212        0.0000\n",
            "10               yearly_income                739.286        0.0000\n",
            "11                  total_debt                213.273        0.0000\n",
            "12                credit_score                 79.717        0.0000\n",
            "13            num_credit_cards                229.339        0.0000\n",
            "14                 gender_Male                  0.000        0.9972\n",
            "15                         cvv                  1.242        0.2651\n",
            "16            num_cards_issued                  0.607        0.4358\n",
            "17                credit_limit                725.316        0.0000\n",
            "18            card_type_Credit                  3.059        0.0803\n",
            "19             card_type_Debit                 86.571        0.0000\n",
            "20             card_brand_Amex                  0.102        0.7498\n",
            "21       card_brand_Mastercard                  0.357        0.5505\n",
            "22             card_brand_Visa                  8.674        0.0032\n",
            "23                has_chip_YES                  1.845        0.1743\n",
            "\n",
            "================================================\n",
            "\n",
            "=== Accuracy in Training and Testing dataset ===\n",
            "\n",
            "=== Classification Matrix — Training Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                   20                 10571   10591        0.2\n",
            "  Normal (0)                   49               7121330 7121379      100.0\n",
            "       Total                   69               7131901 7131970       99.9\n",
            "\n",
            "=== Classification Matrix — Holdout (Test) Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                    7                  2734    2741        0.3\n",
            "  Normal (0)                   14               1780238 1780252      100.0\n",
            "       Total                   21               1782972 1782993       99.8\n"
          ]
        }
      ],
      "source": [
        "overall_fit, coef_df, not_in_eq_df, model_4 = stepwise_logit_with_k_tables(\n",
        "    train_df, test_df, dep_var=\"is_fraud\", k=4\n",
        ")\n",
        "\n",
        "\n",
        "print(\"=== Overall Model Fit ===\")\n",
        "print(overall_fit)\n",
        "\n",
        "print(\"\\n=== Variables in the Equation ===\")\n",
        "print(coef_df)\n",
        "\n",
        "print(\"\\n=== Variables Not in the Equation ===\")\n",
        "print(not_in_eq_df)\n",
        "\n",
        "print(\"\\n================================================\")\n",
        "print(\"\\n=== Accuracy in Training and Testing dataset ===\")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def classification_table(model, df, target_col=\"is_fraud\", cutoff=0.5):\n",
        "    y_true = df[target_col].astype(int)\n",
        "    X = sm.add_constant(df[model.params.index.drop(\"const\")])\n",
        "    y_pred_prob = model.predict(X)\n",
        "    y_pred = (y_pred_prob >= cutoff).astype(int)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
        "    TP, FN, FP, TN = cm.ravel()\n",
        "\n",
        "    fraud_total = TP + FN\n",
        "    normal_total = FP + TN\n",
        "\n",
        "    fraud_correct = TP / fraud_total if fraud_total > 0 else 0\n",
        "    normal_correct = TN / normal_total if normal_total > 0 else 0\n",
        "    overall_correct = (TP + TN) / (fraud_total + normal_total)\n",
        "\n",
        "    table = pd.DataFrame({\n",
        "        \"Actual Group\": [\"Fraud (1)\", \"Normal (0)\", \"Total\"],\n",
        "        \"Predicted Fraud (1)\": [TP, FP, TP + FP],\n",
        "        \"Predicted Normal (0)\": [FN, TN, FN + TN],\n",
        "        \"Total\": [fraud_total, normal_total, fraud_total + normal_total],\n",
        "        \"% Correct\": [\n",
        "            round(fraud_correct * 100, 1),\n",
        "            round(normal_correct * 100, 1),\n",
        "            round(overall_correct * 100, 1),\n",
        "        ],\n",
        "    })\n",
        "    return table\n",
        "\n",
        "# Step 3. 產出訓練集和測試集的結果表\n",
        "train_table = classification_table(model_4, train_df, target_col=\"is_fraud\")\n",
        "test_table = classification_table(model_4, test_df, target_col=\"is_fraud\")\n",
        "\n",
        "print(\"\\n=== Classification Matrix — Training Sample ===\")\n",
        "print(train_table.to_string(index=False))\n",
        "print(\"\\n=== Classification Matrix — Holdout (Test) Sample ===\")\n",
        "print(test_table.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Stepwise completed with 23 variables: ['amount', 'zip', 'longitude', 'merchant_id', 'use_chip_Swipe Transaction', 'credit_limit', 'num_credit_cards', 'errors_missing_flag', 'use_chip_Chip Transaction', 'transaction_id', 'yearly_income', 'latitude', 'client_id_x', 'has_chip_YES', 'credit_score', 'retirement_age', 'card_type_Credit', 'card_type_Debit', 'mcc_code', 'card_brand_Visa', 'card_brand_Mastercard', 'card_brand_Amex', 'card_id']\n",
            "Train Accuracy: 0.9985, Test Accuracy: 0.9985\n",
            "=== Overall Model Fit ===\n",
            "                          Measure       Value Change_from_Base Change_pvalue\n",
            "0  -2 Log Likelihood (−2LL) value  126114.885        32995.727           0.0\n",
            "1                Cox and Snell R2       0.005                               \n",
            "2                   Nagelkerke R2       0.209                               \n",
            "3            Pseudo R2 (McFadden)       0.207                               \n",
            "4              Hosmer-Lemeshow χ2   32995.727                               \n",
            "\n",
            "=== Variables in the Equation ===\n",
            "          Independent Variable             B    Std. Error         Wald  df  \\\n",
            "0                        const -5.292035e+00  2.534512e-01   435.970008   1   \n",
            "1                       amount  2.619412e-03  4.970449e-05  2777.258399   1   \n",
            "2                          zip -9.419831e-05  1.373477e-06  4703.738293   1   \n",
            "3                    longitude -2.077493e-02  5.837857e-04  1266.403609   1   \n",
            "4                  merchant_id  1.067403e-05  3.716056e-07   825.072135   1   \n",
            "5   use_chip_Swipe Transaction -7.152812e-01  4.048087e-02   312.215235   1   \n",
            "6                 credit_limit -1.501740e-05  1.314672e-06   130.483201   1   \n",
            "7             num_credit_cards  9.361115e-02  6.316508e-03   219.634747   1   \n",
            "8          errors_missing_flag -7.901281e-01  4.841736e-02   266.313303   1   \n",
            "9    use_chip_Chip Transaction  8.149060e-01  3.404956e-02   572.785473   1   \n",
            "10              transaction_id -4.272704e-08  2.402336e-09   316.328158   1   \n",
            "11               yearly_income -7.409976e-06  5.832643e-07   161.399760   1   \n",
            "12                    latitude -2.335531e-02  1.954936e-03   142.727125   1   \n",
            "13                 client_id_x -1.123827e-04  1.703471e-05    43.524055   1   \n",
            "14                has_chip_YES -1.904791e-01  3.531443e-02    29.093100   1   \n",
            "15                credit_score  7.019687e-04  1.583567e-04    19.650009   1   \n",
            "16              retirement_age  1.319879e-02  2.910833e-03    20.560504   1   \n",
            "17            card_type_Credit -3.022556e-01  4.071155e-02    55.120543   1   \n",
            "18             card_type_Debit -2.331958e-01  4.067593e-02    32.867493   1   \n",
            "19                    mcc_code -3.544164e-05  1.157822e-05     9.370090   1   \n",
            "20             card_brand_Visa -3.294481e-01  5.637146e-02    34.155089   1   \n",
            "21       card_brand_Mastercard -2.931285e-01  5.702473e-02    26.423457   1   \n",
            "22             card_brand_Amex -3.024703e-01  6.384412e-02    22.445213   1   \n",
            "23                     card_id -1.309347e-05  5.842951e-06     5.021638   1   \n",
            "\n",
            "             Sig.    Exp(B)  \n",
            "0    8.157121e-97  0.005032  \n",
            "1    0.000000e+00  1.002623  \n",
            "2    0.000000e+00  0.999906  \n",
            "3   2.260800e-277  0.979439  \n",
            "4   1.909993e-181  1.000011  \n",
            "5    7.188794e-70  0.489055  \n",
            "6    3.212394e-30  0.999985  \n",
            "7    1.086563e-49  1.098133  \n",
            "8    7.218198e-60  0.453787  \n",
            "9   1.391246e-126  2.258963  \n",
            "10   9.135286e-71  1.000000  \n",
            "11   5.595331e-37  0.999993  \n",
            "12   6.743637e-33  0.976915  \n",
            "13   4.187797e-11  0.999888  \n",
            "14   6.898222e-08  0.826563  \n",
            "15   9.300289e-06  1.000702  \n",
            "16   5.777589e-06  1.013286  \n",
            "17   1.133599e-13  0.739149  \n",
            "18   9.865930e-09  0.791998  \n",
            "19   2.205546e-03  0.999965  \n",
            "20   5.088997e-09  0.719321  \n",
            "21   2.741904e-07  0.745926  \n",
            "22   2.162237e-06  0.738990  \n",
            "23   2.503248e-02  0.999987  \n",
            "\n",
            "=== Variables Not in the Equation ===\n",
            "  Independent Variable  Score Statistic (LRT)  Significance\n",
            "0          current_age                  0.474        0.4911\n",
            "1           total_debt                  0.841        0.3591\n",
            "2          gender_Male                  0.079        0.7780\n",
            "3                  cvv                  0.861        0.3535\n",
            "4     num_cards_issued                  0.707        0.4005\n",
            "\n",
            "================================================\n",
            "\n",
            "=== Accuracy in Training and Testing dataset ===\n",
            "\n",
            "=== Classification Matrix — Training Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                   20                 10571   10591        0.2\n",
            "  Normal (0)                   49               7121330 7121379      100.0\n",
            "       Total                   69               7131901 7131970       99.9\n",
            "\n",
            "=== Classification Matrix — Holdout (Test) Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                    7                  2734    2741        0.3\n",
            "  Normal (0)                   14               1780238 1780252      100.0\n",
            "       Total                   21               1782972 1782993       99.8\n"
          ]
        }
      ],
      "source": [
        "overall_fit, coef_df, not_in_eq_df, final_model = stepwise_logit_with_k_tables(\n",
        "    train_df, test_df, dep_var=\"is_fraud\", k=314657018\n",
        ")\n",
        "\n",
        "\n",
        "print(\"=== Overall Model Fit ===\")\n",
        "print(overall_fit)\n",
        "\n",
        "print(\"\\n=== Variables in the Equation ===\")\n",
        "print(coef_df)\n",
        "\n",
        "print(\"\\n=== Variables Not in the Equation ===\")\n",
        "print(not_in_eq_df)\n",
        "\n",
        "print(\"\\n================================================\")\n",
        "print(\"\\n=== Accuracy in Training and Testing dataset ===\")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def classification_table(model, df, target_col=\"is_fraud\", cutoff=0.5):\n",
        "    y_true = df[target_col].astype(int)\n",
        "    X = sm.add_constant(df[model.params.index.drop(\"const\")])\n",
        "    y_pred_prob = model.predict(X)\n",
        "    y_pred = (y_pred_prob >= cutoff).astype(int)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
        "    TP, FN, FP, TN = cm.ravel()\n",
        "\n",
        "    fraud_total = TP + FN\n",
        "    normal_total = FP + TN\n",
        "\n",
        "    fraud_correct = TP / fraud_total if fraud_total > 0 else 0\n",
        "    normal_correct = TN / normal_total if normal_total > 0 else 0\n",
        "    overall_correct = (TP + TN) / (fraud_total + normal_total)\n",
        "\n",
        "    table = pd.DataFrame({\n",
        "        \"Actual Group\": [\"Fraud (1)\", \"Normal (0)\", \"Total\"],\n",
        "        \"Predicted Fraud (1)\": [TP, FP, TP + FP],\n",
        "        \"Predicted Normal (0)\": [FN, TN, FN + TN],\n",
        "        \"Total\": [fraud_total, normal_total, fraud_total + normal_total],\n",
        "        \"% Correct\": [\n",
        "            round(fraud_correct * 100, 1),\n",
        "            round(normal_correct * 100, 1),\n",
        "            round(overall_correct * 100, 1),\n",
        "        ],\n",
        "    })\n",
        "    return table\n",
        "\n",
        "# Step 3. 產出訓練集和測試集的結果表\n",
        "train_table = classification_table(final_model, train_df, target_col=\"is_fraud\")\n",
        "test_table = classification_table(final_model, test_df, target_col=\"is_fraud\")\n",
        "\n",
        "print(\"\\n=== Classification Matrix — Training Sample ===\")\n",
        "print(train_table.to_string(index=False))\n",
        "print(\"\\n=== Classification Matrix — Holdout (Test) Sample ===\")\n",
        "print(test_table.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Cutoff      TN      FP   FN   TP  Accuracy  Sensitivity  Specificity  Youden   PPV   NPV\n",
            "   0.00       0 1780252    0 2741       0.2        100.0          0.0     0.0   0.2    NC\n",
            "   0.10 1780039     213 2713   28      99.8          1.0        100.0     1.0  11.6  99.8\n",
            "   0.20 1780186      66 2727   14      99.8          0.5        100.0     0.5  17.5  99.8\n",
            "   0.30 1780223      29 2732    9      99.8          0.3        100.0     0.3  23.7  99.8\n",
            "   0.40 1780230      22 2733    8      99.8          0.3        100.0     0.3  26.7  99.8\n",
            "   0.42 1780230      22 2733    8      99.8          0.3        100.0     0.3  26.7  99.8\n",
            "   0.44 1780233      19 2733    8      99.8          0.3        100.0     0.3  29.6  99.8\n",
            "   0.46 1780236      16 2733    8      99.8          0.3        100.0     0.3  33.3  99.8\n",
            "   0.48 1780237      15 2733    8      99.8          0.3        100.0     0.3  34.8  99.8\n",
            "   0.50 1780238      14 2734    7      99.8          0.3        100.0     0.3  33.3  99.8\n",
            "   0.52 1780238      14 2734    7      99.8          0.3        100.0     0.3  33.3  99.8\n",
            "   0.54 1780238      14 2734    7      99.8          0.3        100.0     0.3  33.3  99.8\n",
            "   0.56 1780239      13 2734    7      99.8          0.3        100.0     0.3  35.0  99.8\n",
            "   0.58 1780239      13 2734    7      99.8          0.3        100.0     0.3  35.0  99.8\n",
            "   0.60 1780239      13 2735    6      99.8          0.2        100.0     0.2  31.6  99.8\n",
            "   0.70 1780241      11 2737    4      99.8          0.1        100.0     0.1  26.7  99.8\n",
            "   0.80 1780244       8 2739    2      99.8          0.1        100.0     0.1  20.0  99.8\n",
            "   0.90 1780246       6 2739    2      99.8          0.1        100.0     0.1  25.0  99.8\n",
            "   1.00 1780252       0 2741    0      99.8          0.0        100.0     0.0    NC  99.8\n"
          ]
        }
      ],
      "source": [
        "## 一些模型檢驗診斷\n",
        "def cutoff_analysis(model, df, target_col=\"is_fraud\", cutoffs=None):\n",
        "    \"\"\"\n",
        "    產出類似 Table 8.7 的結果\n",
        "    \"\"\"\n",
        "    if cutoffs is None:\n",
        "        cutoffs = np.arange(0, 1.01, 0.02)  # 預設 0, 0.02, ..., 1\n",
        "    \n",
        "    y_true = df[target_col].astype(int)\n",
        "    X = sm.add_constant(df[model.params.index.drop(\"const\")])\n",
        "    y_prob = model.predict(X)\n",
        "\n",
        "    rows = []\n",
        "    for cutoff in cutoffs:\n",
        "        y_pred = (y_prob >= cutoff).astype(int)\n",
        "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])  # 注意順序 [0,1]\n",
        "        TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "        total = TP + TN + FP + FN\n",
        "        accuracy = (TP + TN) / total if total > 0 else np.nan\n",
        "        sensitivity = TP / (TP + FN) if (TP + FN) > 0 else np.nan\n",
        "        specificity = TN / (TN + FP) if (TN + FP) > 0 else np.nan\n",
        "        youden = sensitivity + specificity - 1 if not np.isnan(sensitivity) and not np.isnan(specificity) else np.nan\n",
        "        ppv = TP / (TP + FP) if (TP + FP) > 0 else np.nan\n",
        "        npv = TN / (TN + FN) if (TN + FN) > 0 else np.nan\n",
        "\n",
        "        rows.append({\n",
        "            \"Cutoff\": cutoff,\n",
        "            \"TN\": TN, \"FP\": FP, \"FN\": FN, \"TP\": TP,\n",
        "            \"Accuracy\": round(accuracy*100, 1),\n",
        "            \"Sensitivity\": round(sensitivity*100, 1) if not np.isnan(sensitivity) else \"NC\",\n",
        "            \"Specificity\": round(specificity*100, 1) if not np.isnan(specificity) else \"NC\",\n",
        "            \"Youden\": round(youden*100, 1) if not np.isnan(youden) else \"NC\",\n",
        "            \"PPV\": round(ppv*100, 1) if not np.isnan(ppv) else \"NC\",\n",
        "            \"NPV\": round(npv*100, 1) if not np.isnan(npv) else \"NC\",\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "cutoff_table_all = cutoff_analysis(final_model, test_df, target_col=\"is_fraud\",\n",
        "                               cutoffs=[0,0.1,0.2,0.3,0.4,0.42,0.44,0.46,0.48,0.5,0.52,0.54,0.56,0.58,0.6,0.7,0.8,0.9,1])\n",
        "\n",
        "print(cutoff_table_all.to_string(index=False))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Cutoff      TN      FP   FN   TP  Accuracy  Sensitivity  Specificity  Youden   PPV    NPV\n",
            " 0.0000       0 1780252    0 2741       0.2        100.0          0.0     0.0   0.2     NC\n",
            " 0.0005 1203478  576774  216 2525      67.6         92.1         67.6    59.7   0.4  100.0\n",
            " 0.0010 1355117  425135  240 2501      76.1         91.2         76.1    67.4   0.6  100.0\n",
            " 0.0015 1427657  352595  273 2468      80.2         90.0         80.2    70.2   0.7  100.0\n",
            " 0.0020 1470930  309322  290 2451      82.6         89.4         82.6    72.0   0.8  100.0\n",
            " 0.0025 1503977  276275  346 2395      84.5         87.4         84.5    71.9   0.9  100.0\n",
            " 0.0030 1532171  248081  390 2351      86.1         85.8         86.1    71.8   0.9  100.0\n",
            " 0.0035 1557720  222532  446 2295      87.5         83.7         87.5    71.2   1.0  100.0\n",
            " 0.0040 1580618  199634  491 2250      88.8         82.1         88.8    70.9   1.1  100.0\n",
            " 0.0045 1601462  178790  540 2201      89.9         80.3         90.0    70.3   1.2  100.0\n",
            " 0.0050 1619913  160339  627 2114      91.0         77.1         91.0    68.1   1.3  100.0\n",
            " 0.0055 1636786  143466  694 2047      91.9         74.7         91.9    66.6   1.4  100.0\n",
            " 0.0060 1651852  128400  760 1981      92.8         72.3         92.8    65.1   1.5  100.0\n",
            " 0.0065 1665011  115241  842 1899      93.5         69.3         93.5    62.8   1.6   99.9\n",
            " 0.0070 1676622  103630  924 1817      94.1         66.3         94.2    60.5   1.7   99.9\n",
            " 0.0075 1686795   93457 1012 1729      94.7         63.1         94.8    57.8   1.8   99.9\n",
            " 0.0080 1696058   84194 1100 1641      95.2         59.9         95.3    55.1   1.9   99.9\n",
            " 0.0085 1704040   76212 1173 1568      95.7         57.2         95.7    52.9   2.0   99.9\n",
            " 0.0090 1711268   68984 1247 1494      96.1         54.5         96.1    50.6   2.1   99.9\n",
            " 0.0095 1717662   62590 1320 1421      96.4         51.8         96.5    48.3   2.2   99.9\n",
            " 0.0100 1723418   56834 1388 1353      96.7         49.4         96.8    46.2   2.3   99.9\n",
            " 0.0105 1728553   51699 1467 1274      97.0         46.5         97.1    43.6   2.4   99.9\n",
            " 0.0110 1733078   47174 1532 1209      97.3         44.1         97.4    41.5   2.5   99.9\n",
            " 0.0115 1736980   43272 1587 1154      97.5         42.1         97.6    39.7   2.6   99.9\n",
            " 0.0120 1740543   39709 1638 1103      97.7         40.2         97.8    38.0   2.7   99.9\n",
            " 0.0125 1743936   36316 1693 1048      97.9         38.2         98.0    36.2   2.8   99.9\n",
            " 0.0130 1747029   33223 1747  994      98.0         36.3         98.1    34.4   2.9   99.9\n",
            " 0.0135 1749639   30613 1785  956      98.2         34.9         98.3    33.2   3.0   99.9\n",
            " 0.0140 1752047   28205 1827  914      98.3         33.3         98.4    31.8   3.1   99.9\n",
            " 0.0145 1754168   26084 1872  869      98.4         31.7         98.5    30.2   3.2   99.9\n",
            " 0.0150 1756081   24171 1910  831      98.5         30.3         98.6    29.0   3.3   99.9\n",
            " 0.0155 1757857   22395 1953  788      98.6         28.7         98.7    27.5   3.4   99.9\n",
            " 0.0160 1759386   20866 1987  754      98.7         27.5         98.8    26.3   3.5   99.9\n",
            " 0.0165 1760767   19485 2016  725      98.8         26.5         98.9    25.4   3.6   99.9\n",
            " 0.0170 1762080   18172 2049  692      98.9         25.2         99.0    24.2   3.7   99.9\n",
            " 0.0175 1763262   16990 2086  655      98.9         23.9         99.0    22.9   3.7   99.9\n",
            " 0.0180 1764295   15957 2113  628      99.0         22.9         99.1    22.0   3.8   99.9\n",
            " 0.0185 1765318   14934 2134  607      99.0         22.1         99.2    21.3   3.9   99.9\n",
            " 0.0190 1766219   14033 2170  571      99.1         20.8         99.2    20.0   3.9   99.9\n",
            " 0.0195 1767065   13187 2189  552      99.1         20.1         99.3    19.4   4.0   99.9\n",
            " 0.0200 1767885   12367 2223  518      99.2         18.9         99.3    18.2   4.0   99.9\n",
            " 0.0205 1768618   11634 2242  499      99.2         18.2         99.3    17.6   4.1   99.9\n",
            " 0.0210 1769335   10917 2267  474      99.3         17.3         99.4    16.7   4.2   99.9\n",
            " 0.0215 1770024   10228 2291  450      99.3         16.4         99.4    15.8   4.2   99.9\n",
            " 0.0220 1770635    9617 2315  426      99.3         15.5         99.5    15.0   4.2   99.9\n",
            " 0.0225 1771179    9073 2345  396      99.4         14.4         99.5    13.9   4.2   99.9\n",
            " 0.0230 1771689    8563 2357  384      99.4         14.0         99.5    13.5   4.3   99.9\n",
            " 0.0235 1772146    8106 2372  369      99.4         13.5         99.5    13.0   4.4   99.9\n",
            " 0.0240 1772618    7634 2385  356      99.4         13.0         99.6    12.6   4.5   99.9\n",
            " 0.0245 1773046    7206 2399  342      99.5         12.5         99.6    12.1   4.5   99.9\n",
            " 0.0250 1773402    6850 2415  326      99.5         11.9         99.6    11.5   4.5   99.9\n",
            " 0.0255 1773726    6526 2430  311      99.5         11.3         99.6    11.0   4.5   99.9\n",
            " 0.0260 1774036    6216 2441  300      99.5         10.9         99.7    10.6   4.6   99.9\n",
            " 0.0265 1774323    5929 2450  291      99.5         10.6         99.7    10.3   4.7   99.9\n",
            " 0.0270 1774643    5609 2461  280      99.5         10.2         99.7     9.9   4.8   99.9\n",
            " 0.0275 1774901    5351 2466  275      99.6         10.0         99.7     9.7   4.9   99.9\n",
            " 0.0280 1775157    5095 2476  265      99.6          9.7         99.7     9.4   4.9   99.9\n",
            " 0.0285 1775382    4870 2487  254      99.6          9.3         99.7     9.0   5.0   99.9\n",
            " 0.0290 1775598    4654 2498  243      99.6          8.9         99.7     8.6   5.0   99.9\n",
            " 0.0295 1775801    4451 2505  236      99.6          8.6         99.7     8.4   5.0   99.9\n",
            " 0.0300 1776004    4248 2511  230      99.6          8.4         99.8     8.2   5.1   99.9\n",
            " 0.0305 1776170    4082 2515  226      99.6          8.2         99.8     8.0   5.2   99.9\n",
            " 0.0310 1776341    3911 2523  218      99.6          8.0         99.8     7.7   5.3   99.9\n",
            " 0.0315 1776512    3740 2536  205      99.6          7.5         99.8     7.3   5.2   99.9\n",
            " 0.0320 1776652    3600 2540  201      99.7          7.3         99.8     7.1   5.3   99.9\n",
            " 0.0325 1776807    3445 2544  197      99.7          7.2         99.8     7.0   5.4   99.9\n",
            " 0.0330 1776937    3315 2557  184      99.7          6.7         99.8     6.5   5.3   99.9\n",
            " 0.0335 1777064    3188 2563  178      99.7          6.5         99.8     6.3   5.3   99.9\n",
            " 0.0340 1777188    3064 2566  175      99.7          6.4         99.8     6.2   5.4   99.9\n",
            " 0.0345 1777291    2961 2573  168      99.7          6.1         99.8     6.0   5.4   99.9\n",
            " 0.0350 1777417    2835 2581  160      99.7          5.8         99.8     5.7   5.3   99.9\n",
            " 0.0355 1777535    2717 2583  158      99.7          5.8         99.8     5.6   5.5   99.9\n",
            " 0.0360 1777634    2618 2587  154      99.7          5.6         99.9     5.5   5.6   99.9\n",
            " 0.0365 1777752    2500 2589  152      99.7          5.5         99.9     5.4   5.7   99.9\n",
            " 0.0370 1777839    2413 2593  148      99.7          5.4         99.9     5.3   5.8   99.9\n",
            " 0.0375 1777927    2325 2594  147      99.7          5.4         99.9     5.2   5.9   99.9\n",
            " 0.0380 1778023    2229 2598  143      99.7          5.2         99.9     5.1   6.0   99.9\n",
            " 0.0385 1778115    2137 2602  139      99.7          5.1         99.9     5.0   6.1   99.9\n",
            " 0.0390 1778182    2070 2608  133      99.7          4.9         99.9     4.7   6.0   99.9\n",
            " 0.0395 1778258    1994 2612  129      99.7          4.7         99.9     4.6   6.1   99.9\n",
            " 0.0400 1778319    1933 2614  127      99.7          4.6         99.9     4.5   6.2   99.9\n",
            " 0.0405 1778379    1873 2618  123      99.7          4.5         99.9     4.4   6.2   99.9\n",
            " 0.0410 1778441    1811 2620  121      99.8          4.4         99.9     4.3   6.3   99.9\n",
            " 0.0415 1778509    1743 2625  116      99.8          4.2         99.9     4.1   6.2   99.9\n",
            " 0.0420 1778572    1680 2629  112      99.8          4.1         99.9     4.0   6.2   99.9\n",
            " 0.0425 1778618    1634 2633  108      99.8          3.9         99.9     3.8   6.2   99.9\n",
            " 0.0430 1778669    1583 2636  105      99.8          3.8         99.9     3.7   6.2   99.9\n",
            " 0.0435 1778731    1521 2637  104      99.8          3.8         99.9     3.7   6.4   99.9\n",
            " 0.0440 1778776    1476 2639  102      99.8          3.7         99.9     3.6   6.5   99.9\n",
            " 0.0445 1778818    1434 2641  100      99.8          3.6         99.9     3.6   6.5   99.9\n",
            " 0.0450 1778846    1406 2643   98      99.8          3.6         99.9     3.5   6.5   99.9\n",
            " 0.0455 1778891    1361 2645   96      99.8          3.5         99.9     3.4   6.6   99.9\n",
            " 0.0460 1778931    1321 2650   91      99.8          3.3         99.9     3.2   6.4   99.9\n",
            " 0.0465 1778970    1282 2653   88      99.8          3.2         99.9     3.1   6.4   99.9\n",
            " 0.0470 1779005    1247 2656   85      99.8          3.1         99.9     3.0   6.4   99.9\n",
            " 0.0475 1779032    1220 2656   85      99.8          3.1         99.9     3.0   6.5   99.9\n",
            " 0.0480 1779070    1182 2656   85      99.8          3.1         99.9     3.0   6.7   99.9\n",
            " 0.0485 1779098    1154 2658   83      99.8          3.0         99.9     3.0   6.7   99.9\n",
            " 0.0490 1779129    1123 2658   83      99.8          3.0         99.9     3.0   6.9   99.9\n",
            " 0.0495 1779161    1091 2660   81      99.8          3.0         99.9     2.9   6.9   99.9\n",
            " 0.0500 1779183    1069 2660   81      99.8          3.0         99.9     2.9   7.0   99.9\n",
            " 0.0505 1779209    1043 2662   79      99.8          2.9         99.9     2.8   7.0   99.9\n",
            " 0.0510 1779229    1023 2664   77      99.8          2.8         99.9     2.8   7.0   99.9\n",
            " 0.0515 1779254     998 2664   77      99.8          2.8         99.9     2.8   7.2   99.9\n",
            " 0.0520 1779288     964 2664   77      99.8          2.8         99.9     2.8   7.4   99.9\n",
            " 0.0525 1779315     937 2664   77      99.8          2.8         99.9     2.8   7.6   99.9\n",
            " 0.0530 1779334     918 2665   76      99.8          2.8         99.9     2.7   7.6   99.9\n",
            " 0.0535 1779361     891 2668   73      99.8          2.7         99.9     2.6   7.6   99.9\n",
            " 0.0540 1779381     871 2670   71      99.8          2.6        100.0     2.5   7.5   99.9\n",
            " 0.0545 1779397     855 2671   70      99.8          2.6        100.0     2.5   7.6   99.9\n",
            " 0.0550 1779409     843 2674   67      99.8          2.4        100.0     2.4   7.4   99.8\n",
            " 0.0555 1779424     828 2674   67      99.8          2.4        100.0     2.4   7.5   99.8\n",
            " 0.0560 1779437     815 2674   67      99.8          2.4        100.0     2.4   7.6   99.8\n",
            " 0.0565 1779449     803 2674   67      99.8          2.4        100.0     2.4   7.7   99.8\n",
            " 0.0570 1779464     788 2675   66      99.8          2.4        100.0     2.4   7.7   99.8\n",
            " 0.0575 1779490     762 2676   65      99.8          2.4        100.0     2.3   7.9   99.8\n",
            " 0.0580 1779514     738 2678   63      99.8          2.3        100.0     2.3   7.9   99.8\n",
            " 0.0585 1779529     723 2679   62      99.8          2.3        100.0     2.2   7.9   99.8\n",
            " 0.0590 1779546     706 2681   60      99.8          2.2        100.0     2.1   7.8   99.8\n",
            " 0.0595 1779553     699 2682   59      99.8          2.2        100.0     2.1   7.8   99.8\n",
            " 0.0600 1779571     681 2684   57      99.8          2.1        100.0     2.0   7.7   99.8\n",
            " 0.0605 1779584     668 2684   57      99.8          2.1        100.0     2.0   7.9   99.8\n",
            " 0.0610 1779601     651 2684   57      99.8          2.1        100.0     2.0   8.1   99.8\n",
            " 0.0615 1779613     639 2684   57      99.8          2.1        100.0     2.0   8.2   99.8\n",
            " 0.0620 1779622     630 2684   57      99.8          2.1        100.0     2.0   8.3   99.8\n",
            " 0.0625 1779630     622 2685   56      99.8          2.0        100.0     2.0   8.3   99.8\n",
            " 0.0630 1779638     614 2685   56      99.8          2.0        100.0     2.0   8.4   99.8\n",
            " 0.0635 1779651     601 2685   56      99.8          2.0        100.0     2.0   8.5   99.8\n",
            " 0.0640 1779657     595 2686   55      99.8          2.0        100.0     2.0   8.5   99.8\n",
            " 0.0645 1779666     586 2687   54      99.8          2.0        100.0     1.9   8.4   99.8\n",
            " 0.0650 1779681     571 2689   52      99.8          1.9        100.0     1.9   8.3   99.8\n",
            " 0.0655 1779693     559 2691   50      99.8          1.8        100.0     1.8   8.2   99.8\n",
            " 0.0660 1779702     550 2691   50      99.8          1.8        100.0     1.8   8.3   99.8\n",
            " 0.0665 1779714     538 2692   49      99.8          1.8        100.0     1.8   8.3   99.8\n",
            " 0.0670 1779721     531 2693   48      99.8          1.8        100.0     1.7   8.3   99.8\n",
            " 0.0675 1779732     520 2693   48      99.8          1.8        100.0     1.7   8.5   99.8\n",
            " 0.0680 1779744     508 2694   47      99.8          1.7        100.0     1.7   8.5   99.8\n",
            " 0.0685 1779751     501 2694   47      99.8          1.7        100.0     1.7   8.6   99.8\n",
            " 0.0690 1779760     492 2694   47      99.8          1.7        100.0     1.7   8.7   99.8\n",
            " 0.0695 1779767     485 2696   45      99.8          1.6        100.0     1.6   8.5   99.8\n",
            " 0.0700 1779774     478 2696   45      99.8          1.6        100.0     1.6   8.6   99.8\n",
            " 0.0705 1779785     467 2696   45      99.8          1.6        100.0     1.6   8.8   99.8\n",
            " 0.0710 1779795     457 2698   43      99.8          1.6        100.0     1.5   8.6   99.8\n",
            " 0.0715 1779804     448 2698   43      99.8          1.6        100.0     1.5   8.8   99.8\n",
            " 0.0720 1779815     437 2698   43      99.8          1.6        100.0     1.5   9.0   99.8\n",
            " 0.0725 1779821     431 2698   43      99.8          1.6        100.0     1.5   9.1   99.8\n",
            " 0.0730 1779826     426 2698   43      99.8          1.6        100.0     1.5   9.2   99.8\n",
            " 0.0735 1779832     420 2699   42      99.8          1.5        100.0     1.5   9.1   99.8\n",
            " 0.0740 1779836     416 2699   42      99.8          1.5        100.0     1.5   9.2   99.8\n",
            " 0.0745 1779842     410 2699   42      99.8          1.5        100.0     1.5   9.3   99.8\n",
            " 0.0750 1779849     403 2701   40      99.8          1.5        100.0     1.4   9.0   99.8\n",
            " 0.0755 1779852     400 2701   40      99.8          1.5        100.0     1.4   9.1   99.8\n",
            " 0.0760 1779862     390 2702   39      99.8          1.4        100.0     1.4   9.1   99.8\n",
            " 0.0765 1779870     382 2703   38      99.8          1.4        100.0     1.4   9.0   99.8\n",
            " 0.0770 1779874     378 2704   37      99.8          1.3        100.0     1.3   8.9   99.8\n",
            " 0.0775 1779877     375 2704   37      99.8          1.3        100.0     1.3   9.0   99.8\n",
            " 0.0780 1779879     373 2704   37      99.8          1.3        100.0     1.3   9.0   99.8\n",
            " 0.0785 1779884     368 2704   37      99.8          1.3        100.0     1.3   9.1   99.8\n",
            " 0.0790 1779888     364 2704   37      99.8          1.3        100.0     1.3   9.2   99.8\n",
            " 0.0795 1779893     359 2704   37      99.8          1.3        100.0     1.3   9.3   99.8\n",
            " 0.0800 1779899     353 2704   37      99.8          1.3        100.0     1.3   9.5   99.8\n",
            " 0.0805 1779905     347 2704   37      99.8          1.3        100.0     1.3   9.6   99.8\n",
            " 0.0810 1779914     338 2704   37      99.8          1.3        100.0     1.3   9.9   99.8\n",
            " 0.0815 1779920     332 2705   36      99.8          1.3        100.0     1.3   9.8   99.8\n",
            " 0.0820 1779925     327 2705   36      99.8          1.3        100.0     1.3   9.9   99.8\n",
            " 0.0825 1779934     318 2705   36      99.8          1.3        100.0     1.3  10.2   99.8\n",
            " 0.0830 1779939     313 2705   36      99.8          1.3        100.0     1.3  10.3   99.8\n",
            " 0.0835 1779944     308 2707   34      99.8          1.2        100.0     1.2   9.9   99.8\n",
            " 0.0840 1779950     302 2707   34      99.8          1.2        100.0     1.2  10.1   99.8\n",
            " 0.0845 1779958     294 2707   34      99.8          1.2        100.0     1.2  10.4   99.8\n",
            " 0.0850 1779961     291 2707   34      99.8          1.2        100.0     1.2  10.5   99.8\n",
            " 0.0855 1779961     291 2707   34      99.8          1.2        100.0     1.2  10.5   99.8\n",
            " 0.0860 1779967     285 2707   34      99.8          1.2        100.0     1.2  10.7   99.8\n",
            " 0.0865 1779970     282 2708   33      99.8          1.2        100.0     1.2  10.5   99.8\n",
            " 0.0870 1779974     278 2708   33      99.8          1.2        100.0     1.2  10.6   99.8\n",
            " 0.0875 1779979     273 2708   33      99.8          1.2        100.0     1.2  10.8   99.8\n",
            " 0.0880 1779983     269 2709   32      99.8          1.2        100.0     1.2  10.6   99.8\n",
            " 0.0885 1779986     266 2709   32      99.8          1.2        100.0     1.2  10.7   99.8\n",
            " 0.0890 1779990     262 2709   32      99.8          1.2        100.0     1.2  10.9   99.8\n",
            " 0.0895 1779990     262 2709   32      99.8          1.2        100.0     1.2  10.9   99.8\n",
            " 0.0900 1779993     259 2710   31      99.8          1.1        100.0     1.1  10.7   99.8\n",
            " 0.0905 1779995     257 2710   31      99.8          1.1        100.0     1.1  10.8   99.8\n",
            " 0.0910 1779996     256 2711   30      99.8          1.1        100.0     1.1  10.5   99.8\n",
            " 0.0915 1779999     253 2711   30      99.8          1.1        100.0     1.1  10.6   99.8\n",
            " 0.0920 1780003     249 2711   30      99.8          1.1        100.0     1.1  10.8   99.8\n",
            " 0.0925 1780004     248 2711   30      99.8          1.1        100.0     1.1  10.8   99.8\n",
            " 0.0930 1780006     246 2711   30      99.8          1.1        100.0     1.1  10.9   99.8\n",
            " 0.0935 1780008     244 2712   29      99.8          1.1        100.0     1.0  10.6   99.8\n",
            " 0.0940 1780009     243 2712   29      99.8          1.1        100.0     1.0  10.7   99.8\n",
            " 0.0945 1780009     243 2712   29      99.8          1.1        100.0     1.0  10.7   99.8\n",
            " 0.0950 1780014     238 2712   29      99.8          1.1        100.0     1.0  10.9   99.8\n",
            " 0.0955 1780017     235 2712   29      99.8          1.1        100.0     1.0  11.0   99.8\n",
            " 0.0960 1780020     232 2712   29      99.8          1.1        100.0     1.0  11.1   99.8\n",
            " 0.0965 1780023     229 2713   28      99.8          1.0        100.0     1.0  10.9   99.8\n",
            " 0.0970 1780025     227 2713   28      99.8          1.0        100.0     1.0  11.0   99.8\n",
            " 0.0975 1780026     226 2713   28      99.8          1.0        100.0     1.0  11.0   99.8\n",
            " 0.0980 1780028     224 2713   28      99.8          1.0        100.0     1.0  11.1   99.8\n",
            " 0.0985 1780031     221 2713   28      99.8          1.0        100.0     1.0  11.2   99.8\n",
            " 0.0990 1780034     218 2713   28      99.8          1.0        100.0     1.0  11.4   99.8\n",
            " 0.0995 1780035     217 2713   28      99.8          1.0        100.0     1.0  11.4   99.8\n",
            " 0.1000 1780039     213 2713   28      99.8          1.0        100.0     1.0  11.6   99.8\n",
            " 0.1005 1780043     209 2713   28      99.8          1.0        100.0     1.0  11.8   99.8\n",
            " 0.1010 1780043     209 2714   27      99.8          1.0        100.0     1.0  11.4   99.8\n",
            " 0.1015 1780045     207 2714   27      99.8          1.0        100.0     1.0  11.5   99.8\n",
            " 0.1020 1780047     205 2715   26      99.8          0.9        100.0     0.9  11.3   99.8\n",
            " 0.1025 1780050     202 2715   26      99.8          0.9        100.0     0.9  11.4   99.8\n",
            " 0.1030 1780053     199 2715   26      99.8          0.9        100.0     0.9  11.6   99.8\n",
            " 0.1035 1780054     198 2715   26      99.8          0.9        100.0     0.9  11.6   99.8\n",
            " 0.1040 1780058     194 2715   26      99.8          0.9        100.0     0.9  11.8   99.8\n",
            " 0.1045 1780062     190 2715   26      99.8          0.9        100.0     0.9  12.0   99.8\n",
            " 0.1050 1780065     187 2715   26      99.8          0.9        100.0     0.9  12.2   99.8\n",
            " 0.1055 1780067     185 2715   26      99.8          0.9        100.0     0.9  12.3   99.8\n",
            " 0.1060 1780067     185 2715   26      99.8          0.9        100.0     0.9  12.3   99.8\n",
            " 0.1065 1780068     184 2715   26      99.8          0.9        100.0     0.9  12.4   99.8\n",
            " 0.1070 1780069     183 2715   26      99.8          0.9        100.0     0.9  12.4   99.8\n",
            " 0.1075 1780073     179 2715   26      99.8          0.9        100.0     0.9  12.7   99.8\n",
            " 0.1080 1780076     176 2715   26      99.8          0.9        100.0     0.9  12.9   99.8\n",
            " 0.1085 1780076     176 2715   26      99.8          0.9        100.0     0.9  12.9   99.8\n",
            " 0.1090 1780077     175 2715   26      99.8          0.9        100.0     0.9  12.9   99.8\n",
            " 0.1095 1780078     174 2715   26      99.8          0.9        100.0     0.9  13.0   99.8\n",
            " 0.2000 1780186      66 2727   14      99.8          0.5        100.0     0.5  17.5   99.8\n",
            " 0.3000 1780223      29 2732    9      99.8          0.3        100.0     0.3  23.7   99.8\n",
            " 0.4000 1780230      22 2733    8      99.8          0.3        100.0     0.3  26.7   99.8\n",
            " 0.5000 1780238      14 2734    7      99.8          0.3        100.0     0.3  33.3   99.8\n",
            " 0.6000 1780239      13 2735    6      99.8          0.2        100.0     0.2  31.6   99.8\n",
            " 0.7000 1780241      11 2737    4      99.8          0.1        100.0     0.1  26.7   99.8\n",
            " 0.8000 1780244       8 2739    2      99.8          0.1        100.0     0.1  20.0   99.8\n",
            " 0.9000 1780246       6 2739    2      99.8          0.1        100.0     0.1  25.0   99.8\n",
            " 1.0000 1780252       0 2741    0      99.8          0.0        100.0     0.0    NC   99.8\n"
          ]
        }
      ],
      "source": [
        "cutoffs_v1 = [round(x, 4) for x in np.arange(0, 0.11, 0.0005)]  # 0 ~ 0.2 間隔 0.02\n",
        "cutoffs_v1 += [round(x, 4) for x in np.arange(0.2, 1.01, 0.1)]  # 0.3 ~ 1 間隔 0.1\n",
        "\n",
        "cutoff_table_zoom = cutoff_analysis(final_model, test_df, target_col=\"is_fraud\", cutoffs=cutoffs_v1)\n",
        "print(cutoff_table_zoom.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC values:\n",
            "Model_1 (amount): 0.6638\n",
            "Model_2 (Zip): 0.9117\n",
            "Model_3 (longitude): 0.9032\n",
            "Model_4 (mercahnt_id): 0.9053\n",
            "Final Model (26vars): 0.9093\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "def plot_multiple_roc(models, model_names, test_df, target_col=\"is_fraud\"):\n",
        "    \"\"\"\n",
        "    models: list of fitted statsmodels.Logit models\n",
        "    model_names: list of strings\n",
        "    test_df: test dataframe\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.style.use('seaborn-v0_8-darkgrid')\n",
        "    plt.rcParams['axes.facecolor'] = '#f0f0f0'\n",
        "\n",
        "    # 隨機機率線\n",
        "    plt.plot([0, 1], [0, 1], color='gray', linestyle='-', label='Random Chance')\n",
        "\n",
        "    auc_values = {}\n",
        "\n",
        "    for model, name in zip(models, model_names):\n",
        "        # 取出模型變數\n",
        "        vars_used = model.params.index.drop(\"const\")\n",
        "        X_test = sm.add_constant(test_df[vars_used])\n",
        "\n",
        "        # 計算預測機率\n",
        "        y_true = test_df[target_col]\n",
        "        y_score = model.predict(X_test)\n",
        "\n",
        "        # ROC 曲線\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
        "        auc_val = roc_auc_score(y_true, y_score)\n",
        "        auc_values[name] = auc_val\n",
        "\n",
        "        plt.plot(fpr, tpr, label=f\"{name} (AUC={auc_val:.4f})\")\n",
        "\n",
        "    plt.title(\"Comparing Independent Variables and Final Stepwise Model with ROC Curve\", fontsize=13, fontweight='bold')\n",
        "    plt.xlabel(\"1 - Specificity\")\n",
        "    plt.ylabel(\"Sensitivity\")\n",
        "    plt.legend(loc=\"lower right\", frameon=True)\n",
        "    plt.show()\n",
        "\n",
        "    # 印出 AUC summary\n",
        "    print(\"AUC values:\")\n",
        "    for name, val in auc_values.items():\n",
        "        print(f\"{name}: {val:.4f}\")\n",
        "\n",
        "# 假設你已經有以下模型：\n",
        "# model_1 = sm.Logit(y_train, sm.add_constant(X_train[[\"X13\"]])).fit(disp=False)\n",
        "# model_2 = sm.Logit(y_train, sm.add_constant(X_train[[\"X17\"]])).fit(disp=False)\n",
        "# final_model = ...\n",
        "\n",
        "# 範例呼叫\n",
        "plot_multiple_roc(\n",
        "    models=[model_0, model_2, model_3,model_4, final_model],\n",
        "    model_names=[\"Model_1 (amount)\", \"Model_2 (Zip)\", \"Model_3 (longitude)\",\"Model_4 (mercahnt_id)\", \"Final Model (26vars)\"],\n",
        "    test_df=test_df,\n",
        "    target_col=\"is_fraud\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cutoff_table_zoom.to_csv(\"cutoff_table_zoom(test).csv\", index=False)\n",
        "\n",
        "overall_fit, coef_df, not_in_eq_df, final_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfs = [overall_fit, coef_df, not_in_eq_df, final_model]\n",
        "names = [\"overall_fit\", \"coef_df\", \"not_in_eq_df\"]\n",
        "\n",
        "for df, name in zip(dfs, names):\n",
        "    df.to_csv(f\"{name}.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "virtual",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
