{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "01_import dataset\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "#https://drive.google.com/drive/folders/18qV82fNY3IIWu3BRoGqm_LNgJzE8Akbr?usp=drive_link\n",
        "#base_dir = \"/Users/Andypon/10_交大研究所/1141_01_機器學習與金融科技/data\"\n",
        "base_dir= '/Users/andyw.p.chen/Documents/Project/datasets'\n",
        "#base_dir=  \"c:\\Users\\user\\Downloads\\datasets\"\n",
        "\n",
        "def load_json_to_df(filename: str) -> pd.DataFrame:\n",
        "    file_path = os.path.join(base_dir, filename)\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # 如果是 { \"target\": {id: value, ...} }\n",
        "    if isinstance(data, dict) and len(data) == 1 and isinstance(next(iter(data.values())), dict):\n",
        "        key, inner = next(iter(data.items()))\n",
        "        return pd.DataFrame(list(inner.items()), columns=[\"id\", key])\n",
        "\n",
        "    # dict of scalar\n",
        "    if isinstance(data, dict):\n",
        "        return pd.DataFrame([{\"code\": k, \"desc\": v} for k, v in data.items()])\n",
        "\n",
        "    # list of dict\n",
        "    elif isinstance(data, list):\n",
        "        return pd.DataFrame(data)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported JSON structure in {filename}: {type(data)}\")\n",
        "\n",
        "\n",
        "def load_csv_to_df(filename: str) -> pd.DataFrame:\n",
        "    \"\"\"讀取 CSV 並轉為 DataFrame。\"\"\"\n",
        "    return pd.read_csv(os.path.join(base_dir, filename))\n",
        "\n",
        "# JSON 資料\n",
        "##mcc_codes_df = load_json_to_df(\"mcc_codes.json\")\n",
        "train_fraud_labels_df = load_json_to_df(\"train_fraud_labels.json\")\n",
        "\n",
        "# CSV 資料\n",
        "cards_df = load_csv_to_df(\"cards_data.csv\")\n",
        "transactions_df = load_csv_to_df(\"transactions_data.csv\")\n",
        "users_df = load_csv_to_df(\"users_data.csv\")\n",
        "\n",
        "# 簡單檢查\n",
        "#print(mcc_codes_df.head())\n",
        "#print(train_fraud_labels_df.head())\n",
        "#print(cards_df.head())\n",
        "#print(transactions_df.head())\n",
        "#print(users_df.apthead())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "02_rename variable in each data set\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_fraud_labels_df = train_fraud_labels_df.rename(columns={'id': 'transactions_id'})\n",
        "train_fraud_labels_df = train_fraud_labels_df.rename(columns={'target': 'is_fraud'})\n",
        "\n",
        "cards_df = cards_df.rename(columns={'id':'card_id'})\n",
        "\n",
        "users_df = users_df.rename(columns={'id':'client_id'})\n",
        "\n",
        "transactions_df = transactions_df.rename(columns={'mcc': 'mcc_code'})\n",
        "transactions_df = transactions_df.rename(columns={'id': 'transaction_id'})\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "03_變數型態統一及缺失值處理\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_missing_flags(df: pd.DataFrame, cols: list) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    在 DataFrame 中對指定欄位建立 missing flag 欄位\n",
        "    flag=1 表示缺失值，flag=0 表示非缺失值\n",
        "    \n",
        "    參數\n",
        "    ----\n",
        "    df : pd.DataFrame\n",
        "        輸入的資料框\n",
        "    cols : list\n",
        "        要檢查的欄位名稱清單\n",
        "    \n",
        "    回傳\n",
        "    ----\n",
        "    pd.DataFrame : 新的資料框 (含新增的 flag 欄位)\n",
        "    \"\"\"\n",
        "    for col in cols:\n",
        "        df[f\"{col}_missing_flag\"] = df[col].isna().astype(int)\n",
        "    return df\n",
        "\n",
        "transactions_df = add_missing_flags(transactions_df, [\"merchant_state\", \"zip\", \"errors\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "##train_fraud_labels_df##\n",
        "train_fraud_labels_df[\"is_fraud\"]=train_fraud_labels_df[\"is_fraud\"].astype(\"category\") \n",
        "train_fraud_labels_df[\"transactions_id\"]=train_fraud_labels_df[\"transactions_id\"].astype(int) #合併資料需要\n",
        "\n",
        "##cards_df##\n",
        "cards_df[\"card_brand\"]=cards_df[\"card_brand\"].astype(\"category\") \n",
        "cards_df[\"card_type\"]=cards_df[\"card_type\"].astype(\"category\")\n",
        "#####不要load這行 cards_df[\"expires\"]=pd.to_datetime(cards_df[\"expires\"], format=\"%m/%Y\")\n",
        "cards_df[\"expires\"] = pd.to_datetime(cards_df[\"expires\"], format=\"%m/%Y\").dt.to_period(\"M\")\n",
        "cards_df[\"has_chip\"]=cards_df[\"has_chip\"].astype(\"category\")\n",
        "\n",
        "cards_df['credit_limit'] = cards_df['credit_limit'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
        "#####不要load這行 cards_df[\"acct_open_date\"]=pd.to_datetime(cards_df[\"acct_open_date\"], format=\"%m/%Y\")\n",
        "cards_df[\"acct_open_date\"] = pd.to_datetime(cards_df[\"acct_open_date\"], format=\"%m/%Y\").dt.to_period(\"M\")\n",
        "#####不要load這行 cards_df[\"year_pin_last_changed\"]=pd.to_datetime(cards_df[\"year_pin_last_changed\"], format=\"%Y\")\n",
        "cards_df[\"year_pin_last_changed\"] = pd.to_datetime(cards_df[\"year_pin_last_changed\"], format=\"%Y\").dt.to_period(\"Y\")\n",
        "cards_df[\"card_on_dark_web\"]=cards_df[\"card_on_dark_web\"].astype(\"category\") \n",
        "\n",
        "##users_df##\n",
        "users_df[\"birth_year\"] = pd.to_datetime(users_df[\"birth_year\"], format=\"%Y\").dt.to_period(\"Y\")\n",
        "users_df[\"birth_month\"] = pd.to_datetime(users_df[\"birth_month\"], format=\"%m\").dt.to_period(\"M\")\n",
        "users_df[\"gender\"]=users_df[\"gender\"].astype(\"category\") \n",
        "users_df['per_capita_income'] = users_df['per_capita_income'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
        "users_df['yearly_income'] = users_df['yearly_income'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
        "users_df['total_debt'] = users_df['total_debt'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
        "\n",
        "##transactions_df##\n",
        "transactions_df[\"date\"] = pd.to_datetime(transactions_df[\"date\"])\n",
        "#浮點數轉整數原因確定？\n",
        "transactions_df['amount'] = transactions_df['amount'].replace(r'[\\$,]', '', regex=True).astype(float).astype(int)\n",
        "##負數取log調成1\n",
        "#transactions_df['amount'] = transactions_df['amount'].replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "\n",
        "transactions_df[\"use_chip\"]=transactions_df[\"use_chip\"].astype(\"category\") \n",
        "\n",
        "transactions_df.loc[\n",
        "    transactions_df['merchant_city'].str.lower() == 'online',\n",
        "    'merchant_state'\n",
        "] = 'online'\n",
        "\n",
        "transactions_df.loc[\n",
        "    transactions_df['merchant_city'].str.lower() == 'online',\n",
        "    'zip'\n",
        "] = -1\n",
        "## 我沒有全部改，這樣完之後仍有89006筆Missing，剩下都是在國外\n",
        "transactions_df['zip'] = transactions_df['zip'].fillna(-999)\n",
        "transactions_df[\"zip\"]=transactions_df[\"zip\"].astype(\"int64\")\n",
        "\n",
        "transactions_df['errors'] = transactions_df['errors'].astype('category')\n",
        "transactions_df['errors'] = transactions_df['errors'].cat.add_categories('No_error').fillna('No_error')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#cars one hot encoding\n",
        "##統一類別變數轉dummy variable(要注意共線性問題，應刪掉其中之一)\n",
        "\n",
        "#card_type 原始種類：Debit_57%, Credit_33%, Debit(Prepaid)_9%\n",
        "#card_brand 原始種類：MasterCard_52%, Visa_38%, Amex_7%, Discovery_3%\n",
        "#has_chip 原始種類：Yes_89%, No_11%\n",
        "#card_on_dark_web 原始種類：No_0%\n",
        "cols_to_encode = ['card_type', 'card_brand', 'has_chip']\n",
        "cards_df[cols_to_encode] = cards_df[cols_to_encode].astype('category')\n",
        "dummies_cards = pd.get_dummies(\n",
        "    cards_df[cols_to_encode], \n",
        "    prefix=cols_to_encode, \n",
        "    dtype='uint8'\n",
        "    )\n",
        "cards_df = pd.concat([cards_df, dummies_cards], axis=1)\n",
        "\n",
        "#use_chip 原始種類：Swiped_52%, Chipe_36%, Online_12%\n",
        "dummies_use = pd.get_dummies(transactions_df['use_chip'], prefix='use_chip', dtype='uint8')\n",
        "transactions_df = pd.concat([transactions_df, dummies_use], axis=1)\n",
        "\n",
        "#gender 原始種類：Female_51%, Male_49%\n",
        "dummies_gender = pd.get_dummies(users_df['gender'], prefix='gender', dtype='uint8')\n",
        "users_df = pd.concat([users_df, dummies_gender], axis=1)\n",
        "\n",
        "\n",
        "cards_df.drop(columns=[\"has_chip_NO\",\"has_chip\"], inplace=True)\n",
        "transactions_df.drop(columns=[\"use_chip\"], inplace=True)\n",
        "users_df.drop(columns=[\"gender_Female\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##不用執行～～(本來試圖建立對照表將Missing的zip補上)\n",
        "\n",
        "##檢查89006筆Missing的zip\n",
        "c_missing_zip = transactions_df[transactions_df[\"zip\"].isna()]\n",
        "c_mexico_zip = transactions_df[transactions_df[\"merchant_state\"]==\"Mexico\"]\n",
        "#c_mcc_mv_zip = c_missing_zip[\n",
        "#    (c_missing_zip[\"mcc_code\"] > 5400) & (c_missing_zip[\"mcc_code\"] < 5700)\n",
        "#]\n",
        "\n",
        "\n",
        "\n",
        "# 先建立 mapping table：一組 state+city 可能對應多個 zip\n",
        "mapping_df = (\n",
        "    transactions_df\n",
        "    .dropna(subset=[\"zip\"])                                   # 只要 zip 有值的 row\n",
        "    .drop_duplicates(subset=[\"merchant_state\", \"merchant_city\", \"zip\"]) \n",
        "    [[\"merchant_state\", \"merchant_city\", \"zip\"]]              # 只留下需要的欄位\n",
        ")\n",
        "\n",
        "print(mapping_df.head())\n",
        "\n",
        "\n",
        "# 假設 df 已經存在\n",
        "# 建立新的欄位 F，B 與 C 合併\n",
        "c_missing_zip[\"fullname\"] = c_missing_zip[\"merchant_city\"].astype(str) + c_missing_zip[\"merchant_state\"].astype(str)\n",
        "# 建立新的 DataFrame，只取 A, D, F\n",
        "df_small = c_missing_zip[[\"transaction_id\", \"fullname\",\"zip\"]]\n",
        "\n",
        "mapping_df[\"mfullname\"] = mapping_df[\"merchant_city\"].astype(str) + mapping_df[\"merchant_state\"].astype(str)\n",
        "\n",
        "# 先建立一個 lookup 字典\n",
        "lookup_dict = dict(zip(mapping_df[\"mfullname\"], mapping_df[\"zip\"]))\n",
        "\n",
        "# 用 map 當作 vlookup\n",
        "df_small[\"zip\"] = df_small[\"zip\"].fillna(df_small[\"fullname\"].map(lookup_dict))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "05_data資料整合\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#transactions_df.loc[transactions_df[\"transaction_id\"] == 10649266] #transaction_id vs id\n",
        "\n",
        "#原始資料筆數：13305915\n",
        "### transactions_df+train_fraud_labels_df      left 會有4390952 missing values\n",
        "merged = pd.merge(transactions_df, train_fraud_labels_df, left_on=\"transaction_id\", right_on=\"transactions_id\", how=\"outer\")\n",
        "### transactions_df train_fraud_labels_df(8914963) + users_df 對過去不會有missing values\n",
        "merged = pd.merge(merged,users_df , left_on=\"client_id\", right_on=\"client_id\", how=\"left\")\n",
        "### transactions_df train_fraud_labels_df users_df + cards_df 對過去不會有missing values\n",
        "merged = pd.merge(merged,cards_df , left_on=\"card_id\", right_on=\"card_id\", how=\"left\")\n",
        "\n",
        "#刪掉重複的columns\n",
        "merged.drop(columns=[\"transactions_id\"], inplace=True)\n",
        "merged.drop(columns=[\"client_id_y\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "del transactions_df, users_df, cards_df, train_fraud_labels_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged[\"is_fraud\"] = merged[\"is_fraud\"].astype(str)\n",
        "merged.loc[merged['is_fraud'].str.lower() == 'no','is_fraud'] = '0'\n",
        "merged.loc[merged['is_fraud'].str.lower() == 'yes','is_fraud'] = '1'\n",
        "merged[\"is_fraud\"] = pd.to_numeric(merged[\"is_fraud\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "merged = add_missing_flags(merged, [\"is_fraud\"])\n",
        "\n",
        "#merged.to_csv(\"merged.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "del cols_to_encode, dummies_cards, dummies_use, dummies_gender"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06_EDA_Exploratory-Data-Analysis\n",
        "=="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-1_資料型態\n",
        "=="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "merged資料：8914963x37"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-2_資料統計指標\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-3_類別型資料frequency barchart\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cat_cols = merged.select_dtypes(include=[\"category\"]).columns\n",
        "\n",
        "n_rows, n_cols = 4, 2\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 50))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(cat_cols):\n",
        "    ax = axes[i]\n",
        "    sns.countplot(data=merged, x=col, order=merged[col].value_counts().index, ax=ax)\n",
        "    ax.set_title(f\"Bar chart of {col}\")\n",
        "    ax.set_xlabel(col)\n",
        "    ax.set_ylabel(\"Count\")\n",
        "    if col == \"errors\":\n",
        "        ax.tick_params(axis='x', rotation=90)  # X軸標籤旋轉\n",
        "    else:\n",
        "        ax.tick_params(axis='x', rotation=0)  # X軸標籤旋轉\n",
        "    \n",
        "    # 在長條圖上加數字\n",
        "    for p in ax.patches:\n",
        "        height = p.get_height()\n",
        "        ax.text(x=p.get_x() + p.get_width()/2,\n",
        "                y=height + 0.05,\n",
        "                s=int(height),\n",
        "                ha='center')\n",
        "\n",
        "# 移除多餘空白子圖\n",
        "for j in range(i+1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-4_數值型資料histogram\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 設定 subplot 格式\n",
        "n_cols = 4   # 每列放4張圖\n",
        "n_rows = 6   # 每行放6列 (共 4x6=24)\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20,15))  # 調整大小\n",
        "axes = axes.flatten()  # 攤平成一維方便迭代\n",
        "num_cols = merged.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "for i, col in enumerate(num_cols):\n",
        "    sns.histplot(data=merged, x=col, bins=30, kde=True, ax=axes[i])\n",
        "    axes[i].set_title(col)\n",
        "\n",
        "# 把多餘的 subplot 關掉（避免空白框）\n",
        "for j in range(i+1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-5_類別型資料box plot\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 抓出數值型欄位\n",
        "num_cols = merged.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# 建立 3x8 subplot\n",
        "fig, axes = plt.subplots(8, 3, figsize=(30, 50))  # 依照需求調整 figsize\n",
        "axes = axes.flatten()  # 攤平成一維 array，方便迴圈\n",
        "\n",
        "# 逐一畫圖\n",
        "for i, col in enumerate(num_cols):\n",
        "    sns.boxplot(y=merged[col], ax=axes[i])  # 每個 subplot 畫一個 boxplot\n",
        "    axes[i].set_title(col, fontsize=10)\n",
        "\n",
        "# 如果欄位數小於 3x8，隱藏多餘的子圖\n",
        "for j in range(len(num_cols), len(axes)):\n",
        "    axes[j].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-7_數值型資料pair wise scatterplot(畫不出來？)\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cols = merged.select_dtypes(include=['int64', 'float64']).columns\n",
        "sns.pairplot(merged[num_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-8_針對詐騙標籤轉成dummy variable\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_to_encode = ['is_fraud']\n",
        "merged[cols_to_encode] = merged[cols_to_encode].astype('category')\n",
        "dummies_cards = pd.get_dummies(\n",
        "    merged[cols_to_encode], \n",
        "    prefix=cols_to_encode, \n",
        "    dtype='uint8'\n",
        "    )\n",
        "merged = pd.concat([merged, dummies_cards], axis=1)\n",
        "merged.drop(columns=[\"is_fraud_No\",\"is_fraud\"], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged[\"is_fraud_Yes\"]=merged[\"is_fraud_Yes\"].astype(\"int64\")\n",
        "target = 'is_fraud_Yes'  # 假設這是目標\n",
        "num_cols = merged.select_dtypes(include=['int64','float64']).columns.drop(target)\n",
        "\n",
        "for col in num_cols:\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.scatter(merged[col], merged[target], alpha=0.3)  # alpha降低透明度，避免太擠\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel(target)\n",
        "    plt.title(f\"{target} vs {col}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-9_其他觀察 詐騙與否跟時間的關係\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 確保 date 是 datetime 格式\n",
        "merged[\"date\"] = pd.to_datetime(merged[\"date\"])\n",
        "\n",
        "# 按天統計詐騙事件數\n",
        "fraud_per_day = merged.groupby(merged[\"date\"].dt.date)[\"is_fraud_Yes\"].sum()\n",
        "\n",
        "# 畫折線圖\n",
        "plt.figure(figsize=(12,5))\n",
        "fraud_per_day.plot(kind=\"line\", marker=\"o\")\n",
        "plt.title(\"Daily Fraud Counts 日期 vs 詐騙次數\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Number of Frauds\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 按小時\n",
        "merged[\"hour\"] = merged[\"date\"].dt.hour\n",
        "hourly_fraud = merged.groupby(\"hour\")[\"is_fraud_Yes\"].sum()\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "hourly_fraud.plot(kind=\"bar\")\n",
        "plt.title(\"Fraud Counts by Hour of Day\")\n",
        "plt.xlabel(\"Hour\")\n",
        "plt.ylabel(\"Number of Frauds\")\n",
        "plt.show()\n",
        "\n",
        "# 按星期幾\n",
        "merged[\"weekday\"] = merged[\"date\"].dt.day_name()\n",
        "weekday_fraud = merged.groupby(\"weekday\")[\"is_fraud_Yes\"].sum().reindex(\n",
        "    [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "weekday_fraud.plot(kind=\"bar\")\n",
        "plt.title(\"Fraud Counts by Weekday\")\n",
        "plt.ylabel(\"Number of Frauds\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 想確認原始交易分布與詐騙無關\n",
        "# 取出小時\n",
        "merged[\"hour\"] = merged[\"date\"].dt.hour\n",
        "\n",
        "# 按小時計算交易數\n",
        "transactions_per_hour = merged[\"hour\"].value_counts().sort_index()\n",
        "\n",
        "# 畫長條圖\n",
        "plt.figure(figsize=(12,5))\n",
        "transactions_per_hour.plot(kind=\"bar\")\n",
        "plt.title(\"Transaction Distribution by Hour of Day\")\n",
        "plt.xlabel(\"Hour of Day\")\n",
        "plt.ylabel(\"Number of Transactions\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-10_correlation and heatmap\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_df = merged.select_dtypes(include=['int64', 'float64'])\n",
        "corr = numeric_df.corr()\n",
        "print(corr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0)\n",
        "plt.title(\"Correlation Heatmap of Numeric Variables\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 原始資料 correlation ---\n",
        "corr_raw = numeric_df.corr()\n",
        "\n",
        "# --- 標準化後 correlation ---\n",
        "scaler = StandardScaler()\n",
        "num_scaled = scaler.fit_transform(numeric_df)   # 轉換成 Numpy array\n",
        "num_df_scaled = pd.DataFrame(num_scaled, columns=numeric_df.columns)\n",
        "corr_scaled = num_df_scaled.corr()\n",
        "\n",
        "# --- 繪圖 (上下對照) ---\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 14))\n",
        "\n",
        "sns.heatmap(corr_raw, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, ax=axes[0])\n",
        "axes[0].set_title(\"Correlation Heatmap (Raw Data)\")\n",
        "\n",
        "sns.heatmap(corr_scaled, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, ax=axes[1])\n",
        "axes[1].set_title(\"Correlation Heatmap (Standardized Data)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "07_categoracal 轉 dummy分析\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "WVTi5S6XrUyN",
        "outputId": "7c85d826-19f0-4213-a5de-613565d7244e"
      },
      "outputs": [],
      "source": [
        "info_df = pd.DataFrame({\n",
        "    \"column\": merged.columns,\n",
        "    \"dtype\": merged.dtypes.astype(str)\n",
        "})\n",
        "info_df.to_csv(\"info.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "08_Benchmark model\n",
        "==\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cols = merged.select_dtypes(include=['int64', 'float64','uint8']).columns\n",
        "df=merged[num_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_cleaned = df.dropna()\n",
        "del df\n",
        "\n",
        "df_cleaned.drop(columns=[\"is_fraud_missing_flag\",\"card_type_Debit (Prepaid)\", \"card_brand_Discover\", \"use_chip_Online Transaction\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df_cleaned, test_size=0.2, random_state=888)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is_fraud\n",
            "0    7121379\n",
            "1      10591\n",
            "Name: count, dtype: Int64\n",
            "is_fraud\n",
            "0    1780252\n",
            "1       2741\n",
            "Name: count, dtype: Int64\n"
          ]
        }
      ],
      "source": [
        "del df_cleaned, merged\n",
        "trainp = train_df['is_fraud'].value_counts(normalize=False)\n",
        "print(trainp)\n",
        "testp = test_df['is_fraud'].value_counts(normalize=False)\n",
        "print(testp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/andyw.p.chen/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  return 1 - self.ssr/self.centered_tss\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       features  VIF Factor\n",
            "24                  card_number   22.245532\n",
            "18            per_capita_income   12.898282\n",
            "19                yearly_income   12.619509\n",
            "30              card_brand_Amex    4.408913\n",
            "9              zip_missing_flag    2.108261\n",
            "8   merchant_state_missing_flag    1.989951\n",
            "6                           zip    1.922594\n",
            "11    use_chip_Chip Transaction    1.800531\n",
            "12   use_chip_Swipe Transaction    1.791158\n",
            "17                    longitude    1.746897\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "def calculate_vif(df):\n",
        "    # 1. 保留數值欄位\n",
        "    df_num = df.select_dtypes(include=[np.number]).copy()\n",
        "\n",
        "    # 2. 強制轉成 float64，避免 Int64 / uint8 / object 問題\n",
        "    df_num = df_num.astype(np.float64)\n",
        "\n",
        "    # 3. 檢查 inf / NaN\n",
        "    if not np.isfinite(df_num.values).all():\n",
        "        raise ValueError(\"Data contains NaN or infinite values, cannot compute VIF.\")\n",
        "\n",
        "    # 4. 加上截距\n",
        "    X = sm.add_constant(df_num)\n",
        "\n",
        "    # 5. 計算 VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"features\"] = X.columns\n",
        "    vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) \n",
        "                         for i in range(X.shape[1])]\n",
        "\n",
        "    return vif\n",
        "\n",
        "# 使用範例\n",
        "vif_result = calculate_vif(train_df)\n",
        "print(vif_result.sort_values(by=\"VIF Factor\", ascending=False).head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged.to_csv(\"merged.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4070 / 7131970\n"
          ]
        }
      ],
      "source": [
        "##第一次處理共線性\n",
        "train_df.drop(columns=[\"per_capita_income\"], inplace=True)\n",
        "##觀察card_number的異常處\n",
        "print(train_df[\"card_number\"].nunique(), \"/\", len(train_df))\n",
        "##第一次處理card_number\n",
        "train_df.drop(columns=[\"card_number\"], inplace=True)\n",
        "#再重跑一次VIF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       features   VIF Factor\n",
            "0                         const  3100.543997\n",
            "12   use_chip_Swipe Transaction   569.424426\n",
            "11    use_chip_Chip Transaction   524.571982\n",
            "8   merchant_state_missing_flag   251.088030\n",
            "9              zip_missing_flag    17.641667\n",
            "29        card_brand_Mastercard    11.382571\n",
            "30              card_brand_Visa    10.554099\n",
            "27              card_type_Debit     4.931201\n",
            "26             card_type_Credit     4.562805\n",
            "6                           zip     3.879815\n"
          ]
        }
      ],
      "source": [
        "vif_result = calculate_vif(train_df)\n",
        "print(vif_result.sort_values(by=\"VIF Factor\", ascending=False).head(10))\n",
        "##發現missing_flag的共線性問題，決定保留one hot encoding高vif值的變數"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.drop(columns=[\"zip_missing_flag\",\"merchant_state_missing_flag\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      features  VIF Factor\n",
            "0                        const  848.160979\n",
            "27       card_brand_Mastercard   11.382517\n",
            "28             card_brand_Visa   10.554078\n",
            "10  use_chip_Swipe Transaction    5.244474\n",
            "9    use_chip_Chip Transaction    5.144790\n",
            "25             card_type_Debit    4.931106\n",
            "24            card_type_Credit    4.562503\n",
            "6                          zip    3.645768\n",
            "26             card_brand_Amex    3.328279\n",
            "15                   longitude    2.709211\n"
          ]
        }
      ],
      "source": [
        "vif_result = calculate_vif(train_df)\n",
        "print(vif_result.sort_values(by=\"VIF Factor\", ascending=False).head(10))\n",
        "##移除missing_flag共線性問題，再次確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      variable   coefficient  p_value\n",
            "0    use_chip_Chip Transaction -5.792166e-01   0.0000\n",
            "1              card_type_Debit -2.431305e-01   0.0000\n",
            "2             card_type_Credit  1.187650e-01   0.0000\n",
            "3                       amount  2.634523e-03   0.0000\n",
            "4                  merchant_id  5.815498e-06   0.0000\n",
            "5                          zip -1.023342e-04   0.0000\n",
            "6                     mcc_code -5.383161e-04   0.0000\n",
            "7          errors_missing_flag -1.034501e+00   0.0000\n",
            "8                   total_debt -1.507820e-06   0.0000\n",
            "9   use_chip_Swipe Transaction -2.282721e+00   0.0000\n",
            "10                 current_age  6.811940e-03   0.0000\n",
            "11                credit_limit -1.325726e-05   0.0000\n",
            "12                    latitude -8.201997e-03   0.0000\n",
            "13            num_credit_cards  1.108020e-01   0.0000\n",
            "14               yearly_income -4.518766e-06   0.0000\n",
            "15                has_chip_YES  1.266255e-01   0.0002\n",
            "16                credit_score  4.469540e-04   0.0027\n",
            "17                   longitude -1.721663e-03   0.0035\n",
            "18                     card_id -1.531231e-05   0.0081\n",
            "19             card_brand_Visa -4.786636e-02   0.0180\n",
            "20             card_brand_Amex  8.191560e-02   0.0324\n",
            "21                 gender_Male -3.298179e-02   0.0902\n",
            "22              transaction_id  2.666966e-09   0.1970\n",
            "23       card_brand_Mastercard -2.159213e-02   0.2679\n",
            "24              retirement_age  2.897547e-03   0.2859\n",
            "25                         cvv  3.560710e-05   0.2907\n",
            "26                 client_id_x -1.477671e-05   0.3766\n",
            "27            num_cards_issued -7.095726e-03   0.7070\n"
          ]
        }
      ],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# assume train_df is your dataframe and \"is_fraud\" is the dependent variable\n",
        "y = train_df[\"is_fraud\"]\n",
        "\n",
        "# exclude the dependent variable itself\n",
        "independent_vars = train_df.columns.drop(\"is_fraud\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for var in independent_vars:\n",
        "    X = sm.add_constant(train_df[var])  # add intercept\n",
        "    model = sm.Logit(y, X)\n",
        "    try:\n",
        "        result = model.fit(disp=False)\n",
        "        coef = result.params[var]\n",
        "        pval = np.around(result.pvalues[var], 4)\n",
        "        results.append({\"variable\": var, \"coefficient\": coef, \"p_value\": pval})\n",
        "    except Exception as e:\n",
        "        results.append({\"variable\": var, \"coefficient\": None, \"p_value\": None})\n",
        "        print(f\"Skipped {var} due to error: {e}\")\n",
        "\n",
        "# convert to dataframe\n",
        "summary_df = pd.DataFrame(results)\n",
        "\n",
        "# optional: sort by p_value\n",
        "summary_df = summary_df.sort_values(\"p_value\", ascending=True).reset_index(drop=True)\n",
        "\n",
        "print(summary_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0: Base model estimated. -2LL = 159110.612\n",
            "Step 1: Added amount, p = 0.0000, -2LL = 156596.132\n",
            "Step 2: Added zip, p = 0.0000, -2LL = 132160.472\n",
            "Step 3: Added longitude, p = 0.0000, -2LL = 130365.785\n",
            "Step 4: Added merchant_id, p = 0.0000, -2LL = 129422.859\n",
            "Step 5: Added use_chip_Swipe Transaction, p = 0.0000, -2LL = 128369.766\n",
            "Step 6: Added credit_limit, p = 0.0000, -2LL = 127721.557\n",
            "Step 7: Added num_credit_cards, p = 0.0000, -2LL = 127399.629\n",
            "Step 8: Added errors_missing_flag, p = 0.0000, -2LL = 127194.361\n",
            "Step 9: Added use_chip_Chip Transaction, p = 0.0000, -2LL = 126969.403\n",
            "Step 10: Added transaction_id, p = 0.0000, -2LL = 126659.120\n",
            "Step 11: Added yearly_income, p = 0.0000, -2LL = 126479.431\n",
            "Step 12: Added latitude, p = 0.0000, -2LL = 126331.866\n",
            "Step 13: Added client_id_x, p = 0.0000, -2LL = 126287.731\n",
            "Step 14: Added has_chip_YES, p = 0.0000, -2LL = 126259.387\n",
            "Step 15: Added credit_score, p = 0.0000, -2LL = 126231.397\n",
            "Step 16: Added retirement_age, p = 0.0001, -2LL = 126215.109\n",
            "Step 17: Added card_type_Credit, p = 0.0000, -2LL = 126196.468\n",
            "Step 18: Added card_type_Debit, p = 0.0000, -2LL = 126161.194\n",
            "Step 19: Added mcc_code, p = 0.0029, -2LL = 126152.192\n",
            "Step 20: Added card_brand_Visa, p = 0.0138, -2LL = 126146.098\n",
            "Step 21: Added card_brand_Mastercard, p = 0.0255, -2LL = 126141.149\n",
            "Step 22: Added card_brand_Amex, p = 0.0000, -2LL = 126119.895\n",
            "Step 23: Added card_id, p = 0.0250, -2LL = 126114.885\n",
            "\n",
            "✅ No more variables meet the entry threshold. Stepwise selection finished.\n",
            "\n",
            "Final model summary:\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:               is_fraud   No. Observations:              7131970\n",
            "Model:                          Logit   Df Residuals:                  7131945\n",
            "Method:                           MLE   Df Model:                           24\n",
            "Date:                Mon, 06 Oct 2025   Pseudo R-squ.:                  0.2074\n",
            "Time:                        20:05:54   Log-Likelihood:                -63057.\n",
            "converged:                       True   LL-Null:                       -79555.\n",
            "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
            "==============================================================================================\n",
            "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "----------------------------------------------------------------------------------------------\n",
            "const                         -5.3101      0.254    -20.889      0.000      -5.808      -4.812\n",
            "amount                         0.0026   4.97e-05     52.698      0.000       0.003       0.003\n",
            "zip                        -9.421e-05   1.37e-06    -68.580      0.000   -9.69e-05   -9.15e-05\n",
            "longitude                     -0.0208      0.001    -35.590      0.000      -0.022      -0.020\n",
            "merchant_id                 1.066e-05   3.72e-07     28.683      0.000    9.93e-06    1.14e-05\n",
            "use_chip_Swipe Transaction    -0.7149      0.040    -17.660      0.000      -0.794      -0.636\n",
            "credit_limit                 -1.5e-05   1.31e-06    -11.413      0.000   -1.76e-05   -1.24e-05\n",
            "num_credit_cards               0.0933      0.006     14.741      0.000       0.081       0.106\n",
            "errors_missing_flag           -0.7900      0.048    -16.317      0.000      -0.885      -0.695\n",
            "use_chip_Chip Transaction      0.8156      0.034     23.947      0.000       0.749       0.882\n",
            "transaction_id             -4.274e-08    2.4e-09    -17.790      0.000   -4.74e-08    -3.8e-08\n",
            "yearly_income              -7.414e-06   5.83e-07    -12.711      0.000   -8.56e-06   -6.27e-06\n",
            "latitude                      -0.0233      0.002    -11.936      0.000      -0.027      -0.020\n",
            "client_id_x                   -0.0001    1.7e-05     -6.582      0.000      -0.000   -7.87e-05\n",
            "has_chip_YES                  -0.1911      0.035     -5.409      0.000      -0.260      -0.122\n",
            "credit_score                   0.0007      0.000      4.433      0.000       0.000       0.001\n",
            "retirement_age                 0.0133      0.003      4.553      0.000       0.008       0.019\n",
            "card_type_Credit              -0.3022      0.041     -7.423      0.000      -0.382      -0.222\n",
            "card_type_Debit               -0.2335      0.041     -5.739      0.000      -0.313      -0.154\n",
            "mcc_code                   -3.558e-05   1.16e-05     -3.073      0.002   -5.83e-05   -1.29e-05\n",
            "card_brand_Visa               -0.3294      0.056     -5.844      0.000      -0.440      -0.219\n",
            "card_brand_Mastercard         -0.2932      0.057     -5.142      0.000      -0.405      -0.181\n",
            "card_brand_Amex               -0.3027      0.064     -4.742      0.000      -0.428      -0.178\n",
            "card_id                    -1.296e-05   5.85e-06     -2.218      0.027   -2.44e-05   -1.51e-06\n",
            "cvv                         3.144e-05   3.39e-05      0.928      0.354    -3.5e-05    9.79e-05\n",
            "==============================================================================================\n",
            "\n",
            "Possibly complete quasi-separation: A fraction 0.49 of observations can be\n",
            "perfectly predicted. This might indicate that there is complete\n",
            "quasi-separation. In this case some parameters will not be identified.\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Step",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Variable Entered",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "-2 Log Likelihood",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "956e14ed-8550-4c2d-817f-39c5975b5e54",
              "rows": [
                [
                  "0",
                  "0",
                  null,
                  "159110.61205098676"
                ],
                [
                  "1",
                  "1",
                  "amount",
                  "156596.1318859173"
                ],
                [
                  "2",
                  "2",
                  "zip",
                  "132160.47242328618"
                ],
                [
                  "3",
                  "3",
                  "longitude",
                  "130365.78537629134"
                ],
                [
                  "4",
                  "4",
                  "merchant_id",
                  "129422.85897686762"
                ],
                [
                  "5",
                  "5",
                  "use_chip_Swipe Transaction",
                  "128369.76553755146"
                ],
                [
                  "6",
                  "6",
                  "credit_limit",
                  "127721.5573537219"
                ],
                [
                  "7",
                  "7",
                  "num_credit_cards",
                  "127399.6289361857"
                ],
                [
                  "8",
                  "8",
                  "errors_missing_flag",
                  "127194.36144428997"
                ],
                [
                  "9",
                  "9",
                  "use_chip_Chip Transaction",
                  "126969.403353223"
                ],
                [
                  "10",
                  "10",
                  "transaction_id",
                  "126659.12047431353"
                ],
                [
                  "11",
                  "11",
                  "yearly_income",
                  "126479.43146008762"
                ],
                [
                  "12",
                  "12",
                  "latitude",
                  "126331.86559310334"
                ],
                [
                  "13",
                  "13",
                  "client_id_x",
                  "126287.73082180246"
                ],
                [
                  "14",
                  "14",
                  "has_chip_YES",
                  "126259.38712661443"
                ],
                [
                  "15",
                  "15",
                  "credit_score",
                  "126231.39740436297"
                ],
                [
                  "16",
                  "16",
                  "retirement_age",
                  "126215.10906426272"
                ],
                [
                  "17",
                  "17",
                  "card_type_Credit",
                  "126196.46814774227"
                ],
                [
                  "18",
                  "18",
                  "card_type_Debit",
                  "126161.1941248596"
                ],
                [
                  "19",
                  "19",
                  "mcc_code",
                  "126152.1919911101"
                ],
                [
                  "20",
                  "20",
                  "card_brand_Visa",
                  "126146.09812282966"
                ],
                [
                  "21",
                  "21",
                  "card_brand_Mastercard",
                  "126141.1489606208"
                ],
                [
                  "22",
                  "22",
                  "card_brand_Amex",
                  "126119.89492591114"
                ],
                [
                  "23",
                  "23",
                  "card_id",
                  "126114.88498004613"
                ]
              ],
              "shape": {
                "columns": 3,
                "rows": 24
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Step</th>\n",
              "      <th>Variable Entered</th>\n",
              "      <th>-2 Log Likelihood</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>159110.612051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>amount</td>\n",
              "      <td>156596.131886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>zip</td>\n",
              "      <td>132160.472423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>longitude</td>\n",
              "      <td>130365.785376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>merchant_id</td>\n",
              "      <td>129422.858977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>use_chip_Swipe Transaction</td>\n",
              "      <td>128369.765538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>credit_limit</td>\n",
              "      <td>127721.557354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>num_credit_cards</td>\n",
              "      <td>127399.628936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>errors_missing_flag</td>\n",
              "      <td>127194.361444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>use_chip_Chip Transaction</td>\n",
              "      <td>126969.403353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>transaction_id</td>\n",
              "      <td>126659.120474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>yearly_income</td>\n",
              "      <td>126479.431460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>latitude</td>\n",
              "      <td>126331.865593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>client_id_x</td>\n",
              "      <td>126287.730822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>has_chip_YES</td>\n",
              "      <td>126259.387127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>credit_score</td>\n",
              "      <td>126231.397404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>retirement_age</td>\n",
              "      <td>126215.109064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>card_type_Credit</td>\n",
              "      <td>126196.468148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>card_type_Debit</td>\n",
              "      <td>126161.194125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>mcc_code</td>\n",
              "      <td>126152.191991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>card_brand_Visa</td>\n",
              "      <td>126146.098123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>card_brand_Mastercard</td>\n",
              "      <td>126141.148961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>card_brand_Amex</td>\n",
              "      <td>126119.894926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>card_id</td>\n",
              "      <td>126114.884980</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Step            Variable Entered  -2 Log Likelihood\n",
              "0      0                        None      159110.612051\n",
              "1      1                      amount      156596.131886\n",
              "2      2                         zip      132160.472423\n",
              "3      3                   longitude      130365.785376\n",
              "4      4                 merchant_id      129422.858977\n",
              "5      5  use_chip_Swipe Transaction      128369.765538\n",
              "6      6                credit_limit      127721.557354\n",
              "7      7            num_credit_cards      127399.628936\n",
              "8      8         errors_missing_flag      127194.361444\n",
              "9      9   use_chip_Chip Transaction      126969.403353\n",
              "10    10              transaction_id      126659.120474\n",
              "11    11               yearly_income      126479.431460\n",
              "12    12                    latitude      126331.865593\n",
              "13    13                 client_id_x      126287.730822\n",
              "14    14                has_chip_YES      126259.387127\n",
              "15    15                credit_score      126231.397404\n",
              "16    16              retirement_age      126215.109064\n",
              "17    17            card_type_Credit      126196.468148\n",
              "18    18             card_type_Debit      126161.194125\n",
              "19    19                    mcc_code      126152.191991\n",
              "20    20             card_brand_Visa      126146.098123\n",
              "21    21       card_brand_Mastercard      126141.148961\n",
              "22    22             card_brand_Amex      126119.894926\n",
              "23    23                     card_id      126114.884980"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "def stepwise_logit(train_df, target_col=\"is_fraud\", entry_threshold=0.05):\n",
        "    # ✅ 確保索引對齊\n",
        "    train_df = train_df.reset_index(drop=True)\n",
        "    y = train_df[target_col].reset_index(drop=True)\n",
        "    \n",
        "    candidate_vars = list(train_df.columns.drop(target_col))\n",
        "    included_vars = []\n",
        "    step_results = []\n",
        "    \n",
        "    # Base model (only intercept)\n",
        "    X_base = sm.add_constant(pd.DataFrame({\"intercept\": [1]*len(train_df)}))\n",
        "    base_model = sm.Logit(y, X_base).fit(disp=False)\n",
        "    base_ll = -2 * base_model.llf\n",
        "    step_results.append({\"Step\": 0, \"Variable Entered\": None, \"-2 Log Likelihood\": base_ll})\n",
        "    \n",
        "    print(f\"Step 0: Base model estimated. -2LL = {base_ll:.3f}\")\n",
        "    \n",
        "    step = 1\n",
        "    while True:\n",
        "        best_pval = 1\n",
        "        best_var = None\n",
        "        best_model = None\n",
        "        \n",
        "        for var in candidate_vars:\n",
        "            try:\n",
        "                X_temp = sm.add_constant(train_df[included_vars + [var]])\n",
        "                model_temp = sm.Logit(y, X_temp).fit(disp=False)\n",
        "                pval = model_temp.pvalues[var]\n",
        "                \n",
        "                if pval < best_pval:\n",
        "                    best_pval = pval\n",
        "                    best_var = var\n",
        "                    best_model = model_temp\n",
        "                    \n",
        "            except Exception:\n",
        "                continue\n",
        "        \n",
        "        if best_var is None or best_pval > entry_threshold:\n",
        "            print(\"\\n✅ No more variables meet the entry threshold. Stepwise selection finished.\")\n",
        "            break\n",
        "        \n",
        "        included_vars.append(best_var)\n",
        "        candidate_vars.remove(best_var)\n",
        "        \n",
        "        ll = -2 * best_model.llf\n",
        "        step_results.append({\"Step\": step, \"Variable Entered\": best_var, \"-2 Log Likelihood\": ll})\n",
        "        \n",
        "        print(f\"Step {step}: Added {best_var}, p = {best_pval:.4f}, -2LL = {ll:.3f}\")\n",
        "        step += 1\n",
        "    \n",
        "    print(\"\\nFinal model summary:\")\n",
        "    print(best_model.summary())\n",
        "    \n",
        "    step_df = pd.DataFrame(step_results)\n",
        "    return step_df, best_model\n",
        "\n",
        "# 🚀 執行\n",
        "step_df, final_model = stepwise_logit(train_df, target_col=\"is_fraud\")\n",
        "step_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_df.to_csv(\"summary_df.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "virtual",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
