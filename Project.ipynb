{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "01_import dataset\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "#https://drive.google.com/drive/folders/18qV82fNY3IIWu3BRoGqm_LNgJzE8Akbr?usp=drive_link\n",
        "#base_dir = \"/Users/Andypon/10_交大研究所/1141_01_機器學習與金融科技/data\"\n",
        "base_dir= '/Users/andyw.p.chen/Documents/Project/datasets'\n",
        "#base_dir=  \"c:\\Users\\user\\Downloads\\datasets\"\n",
        "\n",
        "def load_json_to_df(filename: str) -> pd.DataFrame:\n",
        "    file_path = os.path.join(base_dir, filename)\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # 如果是 { \"target\": {id: value, ...} }\n",
        "    if isinstance(data, dict) and len(data) == 1 and isinstance(next(iter(data.values())), dict):\n",
        "        key, inner = next(iter(data.items()))\n",
        "        return pd.DataFrame(list(inner.items()), columns=[\"id\", key])\n",
        "\n",
        "    # dict of scalar\n",
        "    if isinstance(data, dict):\n",
        "        return pd.DataFrame([{\"code\": k, \"desc\": v} for k, v in data.items()])\n",
        "\n",
        "    # list of dict\n",
        "    elif isinstance(data, list):\n",
        "        return pd.DataFrame(data)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported JSON structure in {filename}: {type(data)}\")\n",
        "\n",
        "\n",
        "def load_csv_to_df(filename: str) -> pd.DataFrame:\n",
        "    \"\"\"讀取 CSV 並轉為 DataFrame。\"\"\"\n",
        "    return pd.read_csv(os.path.join(base_dir, filename))\n",
        "\n",
        "# JSON 資料\n",
        "##mcc_codes_df = load_json_to_df(\"mcc_codes.json\")\n",
        "train_fraud_labels_df = load_json_to_df(\"train_fraud_labels.json\")\n",
        "\n",
        "# CSV 資料\n",
        "cards_df = load_csv_to_df(\"cards_data.csv\")\n",
        "transactions_df = load_csv_to_df(\"transactions_data.csv\")\n",
        "users_df = load_csv_to_df(\"users_data.csv\")\n",
        "\n",
        "# 簡單檢查\n",
        "#print(mcc_codes_df.head())\n",
        "#print(train_fraud_labels_df.head())\n",
        "#print(cards_df.head())\n",
        "#print(transactions_df.head())\n",
        "#print(users_df.apthead())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "02_rename variable in each data set\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_fraud_labels_df = train_fraud_labels_df.rename(columns={'id': 'transactions_id'})\n",
        "train_fraud_labels_df = train_fraud_labels_df.rename(columns={'target': 'is_fraud'})\n",
        "\n",
        "cards_df = cards_df.rename(columns={'id':'card_id'})\n",
        "\n",
        "users_df = users_df.rename(columns={'id':'client_id'})\n",
        "\n",
        "transactions_df = transactions_df.rename(columns={'mcc': 'mcc_code'})\n",
        "transactions_df = transactions_df.rename(columns={'id': 'transaction_id'})\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "03_變數型態統一及缺失值處理\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_missing_flags(df: pd.DataFrame, cols: list) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    在 DataFrame 中對指定欄位建立 missing flag 欄位\n",
        "    flag=1 表示缺失值，flag=0 表示非缺失值\n",
        "    \n",
        "    參數\n",
        "    ----\n",
        "    df : pd.DataFrame\n",
        "        輸入的資料框\n",
        "    cols : list\n",
        "        要檢查的欄位名稱清單\n",
        "    \n",
        "    回傳\n",
        "    ----\n",
        "    pd.DataFrame : 新的資料框 (含新增的 flag 欄位)\n",
        "    \"\"\"\n",
        "    for col in cols:\n",
        "        df[f\"{col}_missing_flag\"] = df[col].isna().astype(int)\n",
        "    return df\n",
        "\n",
        "transactions_df = add_missing_flags(transactions_df, [\"merchant_state\", \"zip\", \"errors\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "##train_fraud_labels_df##\n",
        "train_fraud_labels_df[\"is_fraud\"]=train_fraud_labels_df[\"is_fraud\"].astype(\"category\") \n",
        "train_fraud_labels_df[\"transactions_id\"]=train_fraud_labels_df[\"transactions_id\"].astype(int) #合併資料需要\n",
        "\n",
        "##cards_df##\n",
        "cards_df[\"card_brand\"]=cards_df[\"card_brand\"].astype(\"category\") \n",
        "cards_df[\"card_type\"]=cards_df[\"card_type\"].astype(\"category\")\n",
        "#####不要load這行 cards_df[\"expires\"]=pd.to_datetime(cards_df[\"expires\"], format=\"%m/%Y\")\n",
        "cards_df[\"expires\"] = pd.to_datetime(cards_df[\"expires\"], format=\"%m/%Y\").dt.to_period(\"M\")\n",
        "cards_df[\"has_chip\"]=cards_df[\"has_chip\"].astype(\"category\")\n",
        "\n",
        "cards_df['credit_limit'] = cards_df['credit_limit'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
        "#####不要load這行 cards_df[\"acct_open_date\"]=pd.to_datetime(cards_df[\"acct_open_date\"], format=\"%m/%Y\")\n",
        "cards_df[\"acct_open_date\"] = pd.to_datetime(cards_df[\"acct_open_date\"], format=\"%m/%Y\").dt.to_period(\"M\")\n",
        "#####不要load這行 cards_df[\"year_pin_last_changed\"]=pd.to_datetime(cards_df[\"year_pin_last_changed\"], format=\"%Y\")\n",
        "cards_df[\"year_pin_last_changed\"] = pd.to_datetime(cards_df[\"year_pin_last_changed\"], format=\"%Y\").dt.to_period(\"Y\")\n",
        "cards_df[\"card_on_dark_web\"]=cards_df[\"card_on_dark_web\"].astype(\"category\") \n",
        "\n",
        "##users_df##\n",
        "users_df[\"birth_year\"] = pd.to_datetime(users_df[\"birth_year\"], format=\"%Y\").dt.to_period(\"Y\")\n",
        "users_df[\"birth_month\"] = pd.to_datetime(users_df[\"birth_month\"], format=\"%m\").dt.to_period(\"M\")\n",
        "users_df[\"gender\"]=users_df[\"gender\"].astype(\"category\") \n",
        "users_df['per_capita_income'] = users_df['per_capita_income'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
        "users_df['yearly_income'] = users_df['yearly_income'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
        "users_df['total_debt'] = users_df['total_debt'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
        "\n",
        "##transactions_df##\n",
        "transactions_df[\"date\"] = pd.to_datetime(transactions_df[\"date\"])\n",
        "#浮點數轉整數原因確定？\n",
        "transactions_df['amount'] = transactions_df['amount'].replace(r'[\\$,]', '', regex=True).astype(float).astype(int)\n",
        "##負數取log調成1\n",
        "#transactions_df['amount'] = transactions_df['amount'].replace(r'[\\$,]', '', regex=True).astype(float)\n",
        "\n",
        "transactions_df[\"use_chip\"]=transactions_df[\"use_chip\"].astype(\"category\") \n",
        "\n",
        "transactions_df.loc[\n",
        "    transactions_df['merchant_city'].str.lower() == 'online',\n",
        "    'merchant_state'\n",
        "] = 'online'\n",
        "\n",
        "transactions_df.loc[\n",
        "    transactions_df['merchant_city'].str.lower() == 'online',\n",
        "    'zip'\n",
        "] = -1\n",
        "## 我沒有全部改，這樣完之後仍有89006筆Missing，剩下都是在國外\n",
        "transactions_df['zip'] = transactions_df['zip'].fillna(-999)\n",
        "transactions_df[\"zip\"]=transactions_df[\"zip\"].astype(\"int64\")\n",
        "\n",
        "transactions_df['errors'] = transactions_df['errors'].astype('category')\n",
        "transactions_df['errors'] = transactions_df['errors'].cat.add_categories('No_error').fillna('No_error')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#cars one hot encoding\n",
        "##統一類別變數轉dummy variable(要注意共線性問題，應刪掉其中之一)\n",
        "\n",
        "#card_type 原始種類：Debit_57%, Credit_33%, Debit(Prepaid)_9%\n",
        "#card_brand 原始種類：MasterCard_52%, Visa_38%, Amex_7%, Discovery_3%\n",
        "#has_chip 原始種類：Yes_89%, No_11%\n",
        "#card_on_dark_web 原始種類：No_0%\n",
        "cols_to_encode = ['card_type', 'card_brand', 'has_chip']\n",
        "cards_df[cols_to_encode] = cards_df[cols_to_encode].astype('category')\n",
        "dummies_cards = pd.get_dummies(\n",
        "    cards_df[cols_to_encode], \n",
        "    prefix=cols_to_encode, \n",
        "    dtype='uint8'\n",
        "    )\n",
        "cards_df = pd.concat([cards_df, dummies_cards], axis=1)\n",
        "\n",
        "#use_chip 原始種類：Swiped_52%, Chipe_36%, Online_12%\n",
        "dummies_use = pd.get_dummies(transactions_df['use_chip'], prefix='use_chip', dtype='uint8')\n",
        "transactions_df = pd.concat([transactions_df, dummies_use], axis=1)\n",
        "\n",
        "#gender 原始種類：Female_51%, Male_49%\n",
        "dummies_gender = pd.get_dummies(users_df['gender'], prefix='gender', dtype='uint8')\n",
        "users_df = pd.concat([users_df, dummies_gender], axis=1)\n",
        "\n",
        "\n",
        "cards_df.drop(columns=[\"has_chip_NO\",\"has_chip\"], inplace=True)\n",
        "transactions_df.drop(columns=[\"use_chip\"], inplace=True)\n",
        "users_df.drop(columns=[\"gender_Female\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##不用執行～～(本來試圖建立對照表將Missing的zip補上)\n",
        "\n",
        "##檢查89006筆Missing的zip\n",
        "c_missing_zip = transactions_df[transactions_df[\"zip\"].isna()]\n",
        "c_mexico_zip = transactions_df[transactions_df[\"merchant_state\"]==\"Mexico\"]\n",
        "#c_mcc_mv_zip = c_missing_zip[\n",
        "#    (c_missing_zip[\"mcc_code\"] > 5400) & (c_missing_zip[\"mcc_code\"] < 5700)\n",
        "#]\n",
        "\n",
        "\n",
        "\n",
        "# 先建立 mapping table：一組 state+city 可能對應多個 zip\n",
        "mapping_df = (\n",
        "    transactions_df\n",
        "    .dropna(subset=[\"zip\"])                                   # 只要 zip 有值的 row\n",
        "    .drop_duplicates(subset=[\"merchant_state\", \"merchant_city\", \"zip\"]) \n",
        "    [[\"merchant_state\", \"merchant_city\", \"zip\"]]              # 只留下需要的欄位\n",
        ")\n",
        "\n",
        "print(mapping_df.head())\n",
        "\n",
        "\n",
        "# 假設 df 已經存在\n",
        "# 建立新的欄位 F，B 與 C 合併\n",
        "c_missing_zip[\"fullname\"] = c_missing_zip[\"merchant_city\"].astype(str) + c_missing_zip[\"merchant_state\"].astype(str)\n",
        "# 建立新的 DataFrame，只取 A, D, F\n",
        "df_small = c_missing_zip[[\"transaction_id\", \"fullname\",\"zip\"]]\n",
        "\n",
        "mapping_df[\"mfullname\"] = mapping_df[\"merchant_city\"].astype(str) + mapping_df[\"merchant_state\"].astype(str)\n",
        "\n",
        "# 先建立一個 lookup 字典\n",
        "lookup_dict = dict(zip(mapping_df[\"mfullname\"], mapping_df[\"zip\"]))\n",
        "\n",
        "# 用 map 當作 vlookup\n",
        "df_small[\"zip\"] = df_small[\"zip\"].fillna(df_small[\"fullname\"].map(lookup_dict))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "05_data資料整合\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#transactions_df.loc[transactions_df[\"transaction_id\"] == 10649266] #transaction_id vs id\n",
        "\n",
        "#原始資料筆數：13305915\n",
        "### transactions_df+train_fraud_labels_df      left 會有4390952 missing values\n",
        "merged = pd.merge(transactions_df, train_fraud_labels_df, left_on=\"transaction_id\", right_on=\"transactions_id\", how=\"outer\")\n",
        "### transactions_df train_fraud_labels_df(8914963) + users_df 對過去不會有missing values\n",
        "merged = pd.merge(merged,users_df , left_on=\"client_id\", right_on=\"client_id\", how=\"left\")\n",
        "### transactions_df train_fraud_labels_df users_df + cards_df 對過去不會有missing values\n",
        "merged = pd.merge(merged,cards_df , left_on=\"card_id\", right_on=\"card_id\", how=\"left\")\n",
        "\n",
        "#刪掉重複的columns\n",
        "merged.drop(columns=[\"transactions_id\"], inplace=True)\n",
        "merged.drop(columns=[\"client_id_y\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "del transactions_df, users_df, cards_df, train_fraud_labels_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged[\"is_fraud\"] = merged[\"is_fraud\"].astype(str)\n",
        "merged.loc[merged['is_fraud'].str.lower() == 'no','is_fraud'] = '0'\n",
        "merged.loc[merged['is_fraud'].str.lower() == 'yes','is_fraud'] = '1'\n",
        "merged[\"is_fraud\"] = pd.to_numeric(merged[\"is_fraud\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "merged = add_missing_flags(merged, [\"is_fraud\"])\n",
        "\n",
        "#merged.to_csv(\"merged.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "del cols_to_encode, dummies_cards, dummies_use, dummies_gender"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06_EDA_Exploratory-Data-Analysis\n",
        "=="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-1_資料型態\n",
        "=="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "merged資料：8914963x37"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-2_資料統計指標\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-3_類別型資料frequency barchart\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cat_cols = merged.select_dtypes(include=[\"category\"]).columns\n",
        "\n",
        "n_rows, n_cols = 4, 2\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 50))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(cat_cols):\n",
        "    ax = axes[i]\n",
        "    sns.countplot(data=merged, x=col, order=merged[col].value_counts().index, ax=ax)\n",
        "    ax.set_title(f\"Bar chart of {col}\")\n",
        "    ax.set_xlabel(col)\n",
        "    ax.set_ylabel(\"Count\")\n",
        "    if col == \"errors\":\n",
        "        ax.tick_params(axis='x', rotation=90)  # X軸標籤旋轉\n",
        "    else:\n",
        "        ax.tick_params(axis='x', rotation=0)  # X軸標籤旋轉\n",
        "    \n",
        "    # 在長條圖上加數字\n",
        "    for p in ax.patches:\n",
        "        height = p.get_height()\n",
        "        ax.text(x=p.get_x() + p.get_width()/2,\n",
        "                y=height + 0.05,\n",
        "                s=int(height),\n",
        "                ha='center')\n",
        "\n",
        "# 移除多餘空白子圖\n",
        "for j in range(i+1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-4_數值型資料histogram\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 設定 subplot 格式\n",
        "n_cols = 4   # 每列放4張圖\n",
        "n_rows = 6   # 每行放6列 (共 4x6=24)\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20,15))  # 調整大小\n",
        "axes = axes.flatten()  # 攤平成一維方便迭代\n",
        "num_cols = merged.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "for i, col in enumerate(num_cols):\n",
        "    sns.histplot(data=merged, x=col, bins=30, kde=True, ax=axes[i])\n",
        "    axes[i].set_title(col)\n",
        "\n",
        "# 把多餘的 subplot 關掉（避免空白框）\n",
        "for j in range(i+1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-5_類別型資料box plot\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 抓出數值型欄位\n",
        "num_cols = merged.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# 建立 3x8 subplot\n",
        "fig, axes = plt.subplots(8, 3, figsize=(30, 50))  # 依照需求調整 figsize\n",
        "axes = axes.flatten()  # 攤平成一維 array，方便迴圈\n",
        "\n",
        "# 逐一畫圖\n",
        "for i, col in enumerate(num_cols):\n",
        "    sns.boxplot(y=merged[col], ax=axes[i])  # 每個 subplot 畫一個 boxplot\n",
        "    axes[i].set_title(col, fontsize=10)\n",
        "\n",
        "# 如果欄位數小於 3x8，隱藏多餘的子圖\n",
        "for j in range(len(num_cols), len(axes)):\n",
        "    axes[j].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-7_數值型資料pair wise scatterplot(畫不出來？)\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cols = merged.select_dtypes(include=['int64', 'float64']).columns\n",
        "sns.pairplot(merged[num_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-8_針對詐騙標籤轉成dummy variable\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_to_encode = ['is_fraud']\n",
        "merged[cols_to_encode] = merged[cols_to_encode].astype('category')\n",
        "dummies_cards = pd.get_dummies(\n",
        "    merged[cols_to_encode], \n",
        "    prefix=cols_to_encode, \n",
        "    dtype='uint8'\n",
        "    )\n",
        "merged = pd.concat([merged, dummies_cards], axis=1)\n",
        "merged.drop(columns=[\"is_fraud_No\",\"is_fraud\"], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged[\"is_fraud_Yes\"]=merged[\"is_fraud_Yes\"].astype(\"int64\")\n",
        "target = 'is_fraud_Yes'  # 假設這是目標\n",
        "num_cols = merged.select_dtypes(include=['int64','float64']).columns.drop(target)\n",
        "\n",
        "for col in num_cols:\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.scatter(merged[col], merged[target], alpha=0.3)  # alpha降低透明度，避免太擠\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel(target)\n",
        "    plt.title(f\"{target} vs {col}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-9_其他觀察 詐騙與否跟時間的關係\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 確保 date 是 datetime 格式\n",
        "merged[\"date\"] = pd.to_datetime(merged[\"date\"])\n",
        "\n",
        "# 按天統計詐騙事件數\n",
        "fraud_per_day = merged.groupby(merged[\"date\"].dt.date)[\"is_fraud_Yes\"].sum()\n",
        "\n",
        "# 畫折線圖\n",
        "plt.figure(figsize=(12,5))\n",
        "fraud_per_day.plot(kind=\"line\", marker=\"o\")\n",
        "plt.title(\"Daily Fraud Counts 日期 vs 詐騙次數\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Number of Frauds\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 按小時\n",
        "merged[\"hour\"] = merged[\"date\"].dt.hour\n",
        "hourly_fraud = merged.groupby(\"hour\")[\"is_fraud_Yes\"].sum()\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "hourly_fraud.plot(kind=\"bar\")\n",
        "plt.title(\"Fraud Counts by Hour of Day\")\n",
        "plt.xlabel(\"Hour\")\n",
        "plt.ylabel(\"Number of Frauds\")\n",
        "plt.show()\n",
        "\n",
        "# 按星期幾\n",
        "merged[\"weekday\"] = merged[\"date\"].dt.day_name()\n",
        "weekday_fraud = merged.groupby(\"weekday\")[\"is_fraud_Yes\"].sum().reindex(\n",
        "    [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "weekday_fraud.plot(kind=\"bar\")\n",
        "plt.title(\"Fraud Counts by Weekday\")\n",
        "plt.ylabel(\"Number of Frauds\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 想確認原始交易分布與詐騙無關\n",
        "# 取出小時\n",
        "merged[\"hour\"] = merged[\"date\"].dt.hour\n",
        "\n",
        "# 按小時計算交易數\n",
        "transactions_per_hour = merged[\"hour\"].value_counts().sort_index()\n",
        "\n",
        "# 畫長條圖\n",
        "plt.figure(figsize=(12,5))\n",
        "transactions_per_hour.plot(kind=\"bar\")\n",
        "plt.title(\"Transaction Distribution by Hour of Day\")\n",
        "plt.xlabel(\"Hour of Day\")\n",
        "plt.ylabel(\"Number of Transactions\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "06-10_correlation and heatmap\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_df = merged.select_dtypes(include=['int64', 'float64'])\n",
        "corr = numeric_df.corr()\n",
        "print(corr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0)\n",
        "plt.title(\"Correlation Heatmap of Numeric Variables\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 原始資料 correlation ---\n",
        "corr_raw = numeric_df.corr()\n",
        "\n",
        "# --- 標準化後 correlation ---\n",
        "scaler = StandardScaler()\n",
        "num_scaled = scaler.fit_transform(numeric_df)   # 轉換成 Numpy array\n",
        "num_df_scaled = pd.DataFrame(num_scaled, columns=numeric_df.columns)\n",
        "corr_scaled = num_df_scaled.corr()\n",
        "\n",
        "# --- 繪圖 (上下對照) ---\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 14))\n",
        "\n",
        "sns.heatmap(corr_raw, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, ax=axes[0])\n",
        "axes[0].set_title(\"Correlation Heatmap (Raw Data)\")\n",
        "\n",
        "sns.heatmap(corr_scaled, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, ax=axes[1])\n",
        "axes[1].set_title(\"Correlation Heatmap (Standardized Data)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "07_categoracal 轉 dummy分析\n",
        "=="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "WVTi5S6XrUyN",
        "outputId": "7c85d826-19f0-4213-a5de-613565d7244e"
      },
      "outputs": [],
      "source": [
        "info_df = pd.DataFrame({\n",
        "    \"column\": merged.columns,\n",
        "    \"dtype\": merged.dtypes.astype(str)\n",
        "})\n",
        "info_df.to_csv(\"info.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "08_Benchmark model\n",
        "==\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cols = merged.select_dtypes(include=['int64', 'float64','uint8']).columns\n",
        "df=merged[num_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_cleaned = df.dropna()\n",
        "del df\n",
        "\n",
        "df_cleaned.drop(columns=[\"is_fraud_missing_flag\",\"card_type_Debit (Prepaid)\", \"card_brand_Discover\", \"use_chip_Online Transaction\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df_cleaned, test_size=0.2, random_state=888)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "is_fraud\n",
            "0    7121379\n",
            "1      10591\n",
            "Name: count, dtype: Int64\n",
            "is_fraud\n",
            "0    1780252\n",
            "1       2741\n",
            "Name: count, dtype: Int64\n"
          ]
        }
      ],
      "source": [
        "del df_cleaned, merged\n",
        "trainp = train_df['is_fraud'].value_counts(normalize=False)\n",
        "print(trainp)\n",
        "testp = test_df['is_fraud'].value_counts(normalize=False)\n",
        "print(testp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/andyw.p.chen/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  return 1 - self.ssr/self.centered_tss\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       features  VIF Factor\n",
            "24                  card_number   22.245532\n",
            "18            per_capita_income   12.898282\n",
            "19                yearly_income   12.619509\n",
            "30              card_brand_Amex    4.408913\n",
            "9              zip_missing_flag    2.108261\n",
            "8   merchant_state_missing_flag    1.989951\n",
            "6                           zip    1.922594\n",
            "11    use_chip_Chip Transaction    1.800531\n",
            "12   use_chip_Swipe Transaction    1.791158\n",
            "17                    longitude    1.746897\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "def calculate_vif(df):\n",
        "    # 1. 保留數值欄位\n",
        "    df_num = df.select_dtypes(include=[np.number]).copy()\n",
        "\n",
        "    # 2. 強制轉成 float64，避免 Int64 / uint8 / object 問題\n",
        "    df_num = df_num.astype(np.float64)\n",
        "\n",
        "    # 3. 檢查 inf / NaN\n",
        "    if not np.isfinite(df_num.values).all():\n",
        "        raise ValueError(\"Data contains NaN or infinite values, cannot compute VIF.\")\n",
        "\n",
        "    # 4. 加上截距\n",
        "    X = sm.add_constant(df_num)\n",
        "\n",
        "    # 5. 計算 VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"features\"] = X.columns\n",
        "    vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) \n",
        "                         for i in range(X.shape[1])]\n",
        "\n",
        "    return vif\n",
        "\n",
        "# 使用範例\n",
        "vif_result = calculate_vif(train_df)\n",
        "print(vif_result.sort_values(by=\"VIF Factor\", ascending=False).head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4070 / 7131970\n"
          ]
        }
      ],
      "source": [
        "##第一次處理共線性\n",
        "train_df.drop(columns=[\"per_capita_income\"], inplace=True)\n",
        "##觀察card_number的異常處\n",
        "print(train_df[\"card_number\"].nunique(), \"/\", len(train_df))\n",
        "##第一次處理card_number\n",
        "train_df.drop(columns=[\"card_number\"], inplace=True)\n",
        "#再重跑一次VIF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       features   VIF Factor\n",
            "0                         const  3100.543997\n",
            "12   use_chip_Swipe Transaction   569.424426\n",
            "11    use_chip_Chip Transaction   524.571982\n",
            "8   merchant_state_missing_flag   251.088030\n",
            "9              zip_missing_flag    17.641667\n",
            "29        card_brand_Mastercard    11.382571\n",
            "30              card_brand_Visa    10.554099\n",
            "27              card_type_Debit     4.931201\n",
            "26             card_type_Credit     4.562805\n",
            "6                           zip     3.879815\n"
          ]
        }
      ],
      "source": [
        "vif_result = calculate_vif(train_df)\n",
        "print(vif_result.sort_values(by=\"VIF Factor\", ascending=False).head(10))\n",
        "##發現missing_flag的共線性問題，決定保留one hot encoding高vif值的變數"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.drop(columns=[\"zip_missing_flag\",\"merchant_state_missing_flag\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      features  VIF Factor\n",
            "0                        const  848.160979\n",
            "27       card_brand_Mastercard   11.382517\n",
            "28             card_brand_Visa   10.554078\n",
            "10  use_chip_Swipe Transaction    5.244474\n",
            "9    use_chip_Chip Transaction    5.144790\n",
            "25             card_type_Debit    4.931106\n",
            "24            card_type_Credit    4.562503\n",
            "6                          zip    3.645768\n",
            "26             card_brand_Amex    3.328279\n",
            "15                   longitude    2.709211\n"
          ]
        }
      ],
      "source": [
        "vif_result = calculate_vif(train_df)\n",
        "print(vif_result.sort_values(by=\"VIF Factor\", ascending=False).head(10))\n",
        "##移除missing_flag共線性問題，再次確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      variable   coefficient  p_value\n",
            "0    use_chip_Chip Transaction -5.792166e-01   0.0000\n",
            "1              card_type_Debit -2.431305e-01   0.0000\n",
            "2             card_type_Credit  1.187650e-01   0.0000\n",
            "3                       amount  2.634523e-03   0.0000\n",
            "4                  merchant_id  5.815498e-06   0.0000\n",
            "5                          zip -1.023342e-04   0.0000\n",
            "6                     mcc_code -5.383161e-04   0.0000\n",
            "7          errors_missing_flag -1.034501e+00   0.0000\n",
            "8                   total_debt -1.507820e-06   0.0000\n",
            "9   use_chip_Swipe Transaction -2.282721e+00   0.0000\n",
            "10                 current_age  6.811940e-03   0.0000\n",
            "11                credit_limit -1.325726e-05   0.0000\n",
            "12                    latitude -8.201997e-03   0.0000\n",
            "13            num_credit_cards  1.108020e-01   0.0000\n",
            "14               yearly_income -4.518766e-06   0.0000\n",
            "15                has_chip_YES  1.266255e-01   0.0002\n",
            "16                credit_score  4.469540e-04   0.0027\n",
            "17                   longitude -1.721663e-03   0.0035\n",
            "18                     card_id -1.531231e-05   0.0081\n",
            "19             card_brand_Visa -4.786636e-02   0.0180\n",
            "20             card_brand_Amex  8.191560e-02   0.0324\n",
            "21                 gender_Male -3.298179e-02   0.0902\n",
            "22              transaction_id  2.666966e-09   0.1970\n",
            "23       card_brand_Mastercard -2.159213e-02   0.2679\n",
            "24              retirement_age  2.897547e-03   0.2859\n",
            "25                         cvv  3.560710e-05   0.2907\n",
            "26                 client_id_x -1.477671e-05   0.3766\n",
            "27            num_cards_issued -7.095726e-03   0.7070\n"
          ]
        }
      ],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# assume train_df is your dataframe and \"is_fraud\" is the dependent variable\n",
        "y = train_df[\"is_fraud\"]\n",
        "\n",
        "# exclude the dependent variable itself\n",
        "independent_vars = train_df.columns.drop(\"is_fraud\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for var in independent_vars:\n",
        "    X = sm.add_constant(train_df[var])  # add intercept\n",
        "    model = sm.Logit(y, X)\n",
        "    try:\n",
        "        result = model.fit(disp=False)\n",
        "        coef = result.params[var]\n",
        "        pval = np.around(result.pvalues[var], 4)\n",
        "        results.append({\"variable\": var, \"coefficient\": coef, \"p_value\": pval})\n",
        "    except Exception as e:\n",
        "        results.append({\"variable\": var, \"coefficient\": None, \"p_value\": None})\n",
        "        print(f\"Skipped {var} due to error: {e}\")\n",
        "\n",
        "# convert to dataframe\n",
        "summary_df = pd.DataFrame(results)\n",
        "\n",
        "# optional: sort by p_value\n",
        "summary_df = summary_df.sort_values(\"p_value\", ascending=True).reset_index(drop=True)\n",
        "\n",
        "print(summary_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table: Logistic Regression Stepwise Estimation — Adding amount, zip\n",
            "\n",
            "Overall Model Fit: Goodness-of-Fit Measures\n",
            "\n",
            "                       Measure      Value Change_from_Base Change_pvalue\n",
            "-2 Log Likelihood (−2LL) value 132160.472        -26950.14           0.0\n",
            "              Cox and Snell R2      0.004                               \n",
            "                 Nagelkerke R2      0.171                               \n",
            "          Pseudo R2 (McFadden)      0.169                               \n",
            "            Hosmer-Lemeshow χ2  31787.956                            0.0\n",
            "\n",
            "\n",
            "Variables in the Equation\n",
            "\n",
            "Independent Variable       B  Std. Error       Wald  df  Sig.  Exp(B)\n",
            "            Constant -5.0423      0.0118 182312.966   1   0.0  0.0065\n",
            "\n",
            "\n",
            "Variables Not in the Equation (candidates and LRT vs base)\n",
            "\n",
            "      Independent Variable  Score Statistic (LRT)  Significance\n",
            "                    amount               2514.480        0.0000\n",
            "                       zip              25168.126        0.0000\n",
            "                  mcc_code               1850.618        0.0000\n",
            "use_chip_Swipe Transaction               8580.841        0.0000\n",
            " use_chip_Chip Transaction                707.825        0.0000\n",
            "       errors_missing_flag                348.748        0.0000\n",
            "          num_credit_cards                330.237        0.0000\n",
            "               merchant_id                241.641        0.0000\n",
            "              credit_limit                223.331        0.0000\n",
            "           card_type_Debit                151.787        0.0000\n",
            "               current_age                125.967        0.0000\n",
            "             yearly_income                105.587        0.0000\n",
            "                total_debt                 59.954        0.0000\n",
            "          card_type_Credit                 32.764        0.0000\n",
            "                  latitude                 18.643        0.0000\n",
            "              has_chip_YES                 14.268        0.0002\n",
            "              credit_score                  9.045        0.0026\n",
            "                 longitude                  8.450        0.0037\n",
            "                   card_id                  6.996        0.0082\n",
            "           card_brand_Visa                  5.618        0.0178\n",
            "           card_brand_Amex                  4.471        0.0345\n",
            "               gender_Male                  2.872        0.0901\n",
            "            transaction_id                  1.665        0.1970\n",
            "     card_brand_Mastercard                  1.227        0.2680\n",
            "            retirement_age                  1.140        0.2857\n",
            "                       cvv                  1.116        0.2907\n",
            "               client_id_x                  0.782        0.3767\n",
            "          num_cards_issued                  0.141        0.7070\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/yb/xnfk9z6x34527z3924bcjqcr0000gn/T/ipykernel_2851/2800889624.py:17: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  grouped = df.groupby(\"group\")\n"
          ]
        }
      ],
      "source": [
        "#(寫錯了不要使用)放入第一個變數會怎樣\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import chi2\n",
        "from sklearn.utils import check_array\n",
        "\n",
        "def hosmer_lemeshow_test(y_true, y_prob, g=10):\n",
        "    \"\"\"\n",
        "    Hosmer-Lemeshow test (group into g quantiles by predicted prob).\n",
        "    Returns (chi2, pvalue, table_df)\n",
        "    \"\"\"\n",
        "    # create dataframe\n",
        "    df = pd.DataFrame({\"y\": np.asarray(y_true), \"yhat\": np.asarray(y_prob)})\n",
        "    # create g groups by quantile of predicted prob\n",
        "    df[\"group\"] = pd.qcut(df[\"yhat\"], q=g, duplicates=\"drop\")\n",
        "    grouped = df.groupby(\"group\")\n",
        "    \n",
        "    obs = grouped[\"y\"].sum()\n",
        "    n = grouped.size()\n",
        "    exp = grouped[\"yhat\"].sum()\n",
        "    \n",
        "    # HL chi2: sum ( (O - E)^2 / (E*(1 - E/n)) )  -- alternative formulation:\n",
        "    # Common simple formula: sum((O - E)^2 / (E*(1 - E/n_i))) is unstable;\n",
        "    # We'll use classical: sum((O - E)^2 / (E*(1 - E/n_i))) where E is expected count in group\n",
        "    # But many use: sum((O - E)^2 / (E*(1 - E/n_i))) ; here we fallback to standard HL:\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        term = (obs - exp) ** 2 / (exp * (1 - exp / n))\n",
        "        term = term.replace([np.inf, -np.inf], 0).fillna(0)\n",
        "    chi2_stat = term.sum()\n",
        "    df_hl = max(1, len(n) - 2)\n",
        "    pvalue = chi2.sf(chi2_stat, df_hl)\n",
        "    \n",
        "    table = pd.DataFrame({\n",
        "        \"group\": n.index.astype(str),\n",
        "        \"n_obs\": n.values,\n",
        "        \"y_obs\": obs.values,\n",
        "        \"y_exp\": exp.values\n",
        "    })\n",
        "    return chi2_stat, pvalue, table\n",
        "\n",
        "def table_for_first_step(train_df, target_col=\"is_fraud\", g_hl=10, max_vars_display=None):\n",
        "    \"\"\"\n",
        "    Automatically pick the best single variable to add (by LRT vs base) and\n",
        "    produce three tables in the style of the textbook for the first step:\n",
        "      - Overall Model Fit (with change from base)\n",
        "      - Variables in the Equation (the added variable)\n",
        "      - Variables Not in the Equation (LRT for other candidates)\n",
        "    Returns: dict with dataframes: goodness_df, in_eq_df, not_in_eq_df\n",
        "    \"\"\"\n",
        "    train_df = train_df.reset_index(drop=True)\n",
        "    y = train_df[target_col].astype(int).reset_index(drop=True)\n",
        "    candidates = list(train_df.columns.drop(target_col))\n",
        "    n = len(train_df)\n",
        "    \n",
        "    # Base model (intercept only)\n",
        "    X_base = sm.add_constant(pd.DataFrame({\"intercept\": np.ones(n)}))\n",
        "    base_model = sm.Logit(y, X_base).fit(disp=False)\n",
        "    ll_base = base_model.llf\n",
        "    minus2ll_base = -2 * ll_base\n",
        "    \n",
        "    # For each candidate, fit model with that single variable and compute LRT\n",
        "    lrt_list = []\n",
        "    for var in candidates:\n",
        "        try:\n",
        "            Xv = sm.add_constant(train_df[[var]])\n",
        "            mv = sm.Logit(y, Xv).fit(disp=False)\n",
        "            ll_v = mv.llf\n",
        "            lr_stat = -2 * (ll_base - ll_v)   # change in -2LL\n",
        "            pval = chi2.sf(lr_stat, df=1)\n",
        "            lrt_list.append({\"variable\": var, \"lr_stat\": lr_stat, \"p_value\": pval, \"ll_v\": ll_v})\n",
        "        except Exception as e:\n",
        "            lrt_list.append({\"variable\": var, \"lr_stat\": None, \"p_value\": None, \"ll_v\": None})\n",
        "            # continue even on errors\n",
        "    \n",
        "    lrt_df = pd.DataFrame(lrt_list).sort_values(\"p_value\", na_position=\"last\").reset_index(drop=True)\n",
        "    \n",
        "    # pick best variable (smallest p-value, and lr_stat not null)\n",
        "    ###best_row = lrt_df.dropna(subset=[\"p_value\"]).sort_values(\"p_value\").iloc[0]  ###原本只有1個\n",
        "    ###best_var = best_row[\"variable\"]                                              ###原本只有1個\n",
        "    k = 2  # 想放幾個變數就改這裡\n",
        "    top_k_vars = lrt_df.dropna(subset=[\"p_value\"]).sort_values(\"p_value\").head(k)[\"variable\"].tolist()\n",
        "    \n",
        "    # Fit model with the chosen variable\n",
        "    #X_best = sm.add_constant(train_df[[best_var]])  ###原本只有1個\n",
        "    X_best = sm.add_constant(train_df[top_k_vars])\n",
        "    best_var = \", \".join(top_k_vars)\n",
        "\n",
        "    best_model = sm.Logit(y, X_best).fit(disp=False)\n",
        "    ll_best = best_model.llf\n",
        "    minus2ll_best = -2 * ll_best\n",
        "    change_from_base = minus2ll_best - minus2ll_base  # how -2LL changed (positive if decreased in LL)\n",
        "    # significance of change (LRT)\n",
        "    lr_stat_best = -2 * (ll_base - ll_best)\n",
        "    p_change = chi2.sf(lr_stat_best, df=1)\n",
        "    \n",
        "    # R-squared variants\n",
        "    ll_null = ll_base\n",
        "    ll_model = ll_best\n",
        "    # McFadden\n",
        "    pseudo_r2 = 1 - (ll_model / ll_null)\n",
        "    # Cox & Snell\n",
        "    try:\n",
        "        r_cs = 1 - np.exp((2.0 / n) * (ll_null - ll_model))\n",
        "    except:\n",
        "        r_cs = np.nan\n",
        "    # Nagelkerke (adjusted Cox & Snell)\n",
        "    try:\n",
        "        r_max = 1 - np.exp((2.0 / n) * ll_null)\n",
        "        nagelkerke = r_cs / r_max if r_max != 0 else np.nan\n",
        "    except:\n",
        "        nagelkerke = np.nan\n",
        "    \n",
        "    # Hosmer-Lemeshow\n",
        "    preds = best_model.predict(X_best)\n",
        "    hl_chi2, hl_p, hl_table = hosmer_lemeshow_test(y, preds, g=g_hl)\n",
        "    \n",
        "    # Build Goodness-of-Fit DataFrame (layout like textbook)\n",
        "    goodness_rows = [\n",
        "        {\"Measure\": \"-2 Log Likelihood (−2LL) value\", \"Value\": round(minus2ll_best, 3),\n",
        "         \"Change_from_Base\": round(change_from_base, 3), \"Change_pvalue\": round(p_change, 4)},\n",
        "        {\"Measure\": \"Cox and Snell R2\", \"Value\": round(r_cs, 3), \"Change_from_Base\": \"\", \"Change_pvalue\": \"\"},\n",
        "        {\"Measure\": \"Nagelkerke R2\", \"Value\": round(nagelkerke, 3), \"Change_from_Base\": \"\", \"Change_pvalue\": \"\"},\n",
        "        {\"Measure\": \"Pseudo R2 (McFadden)\", \"Value\": round(pseudo_r2, 3), \"Change_from_Base\": \"\", \"Change_pvalue\": \"\"},\n",
        "        {\"Measure\": \"Hosmer-Lemeshow χ2\", \"Value\": round(hl_chi2, 3), \"Change_from_Base\": \"\", \"Change_pvalue\": round(hl_p, 4)}\n",
        "    ]\n",
        "    goodness_df = pd.DataFrame(goodness_rows)\n",
        "    \n",
        "    # Variables in the Equation (the chosen variable)\n",
        "    params = best_model.params\n",
        "    bse = best_model.bse\n",
        "    z = params / bse\n",
        "    wald = (z**2)\n",
        "    pvals = best_model.pvalues\n",
        "    expb = np.exp(params)\n",
        "    in_eq = []\n",
        "    # list chosen var then constant\n",
        "    for var in [best_var, \"const\"]:\n",
        "        if var in params.index:\n",
        "            in_eq.append({\n",
        "                \"Independent Variable\": var if var != \"const\" else \"Constant\",\n",
        "                \"B\": round(params[var], 4),\n",
        "                \"Std. Error\": round(bse[var], 4),\n",
        "                \"Wald\": round(wald[var], 3),\n",
        "                \"df\": 1,\n",
        "                \"Sig.\": round(pvals[var], 4),\n",
        "                \"Exp(B)\": round(expb[var], 4)\n",
        "            })\n",
        "    in_eq_df = pd.DataFrame(in_eq)\n",
        "    \n",
        "    # Variables Not in the Equation: show LRT for all other candidates (vs base model)\n",
        "    not_in = []\n",
        "    for _, row in lrt_df.iterrows():\n",
        "        var = row[\"variable\"]\n",
        "        if var == best_var:\n",
        "            continue\n",
        "        not_in.append({\n",
        "            \"Independent Variable\": var,\n",
        "            \"Score Statistic (LRT)\": None if pd.isna(row[\"lr_stat\"]) else round(row[\"lr_stat\"], 3),\n",
        "            \"Significance\": None if pd.isna(row[\"p_value\"]) else round(row[\"p_value\"], 4)\n",
        "        })\n",
        "    not_in_eq_df = pd.DataFrame(not_in)\n",
        "    \n",
        "    # Optionally truncate long lists\n",
        "    if max_vars_display is not None:\n",
        "        not_in_eq_df = not_in_eq_df.head(max_vars_display)\n",
        "    \n",
        "    # Print summary in textbook style\n",
        "    print(\"Table: Logistic Regression Stepwise Estimation — Adding\", best_var)\n",
        "    print(\"\\nOverall Model Fit: Goodness-of-Fit Measures\\n\")\n",
        "    print(goodness_df.to_string(index=False))\n",
        "    print(\"\\n\\nVariables in the Equation\\n\")\n",
        "    print(in_eq_df.to_string(index=False))\n",
        "    print(\"\\n\\nVariables Not in the Equation (candidates and LRT vs base)\\n\")\n",
        "    print(not_in_eq_df.to_string(index=False))\n",
        "    \n",
        "    return {\n",
        "        \"best_var\": best_var,\n",
        "        \"goodness_df\": goodness_df,\n",
        "        \"in_eq_df\": in_eq_df,\n",
        "        \"not_in_eq_df\": not_in_eq_df,\n",
        "        \"hl_table\": hl_table,\n",
        "        \"best_model\": best_model\n",
        "    }\n",
        "\n",
        "# ===== Example usage =====\n",
        "results = table_for_first_step(train_df, target_col=\"is_fraud\")\n",
        "good_df, in_df, notin_df = results[\"goodness_df\"], results[\"in_eq_df\"], results[\"not_in_eq_df\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#(寫錯了不要使用)\n",
        "from scipy.stats import chi2\n",
        "def table_for_first_step(train_df, target_col=\"is_fraud\", g_hl=10, max_vars_display=None, k=1):\n",
        "    \"\"\"\n",
        "    Automatically pick the best k variables (default=1) to add (by LRT vs base)\n",
        "    and produce tables like textbook.\n",
        "    \"\"\"\n",
        "    train_df = train_df.reset_index(drop=True)\n",
        "    y = train_df[target_col].astype(int).reset_index(drop=True)\n",
        "    candidates = list(train_df.columns.drop(target_col))\n",
        "    n = len(train_df)\n",
        "    \n",
        "    # Base model\n",
        "    X_base = sm.add_constant(pd.DataFrame({\"intercept\": np.ones(n)}))\n",
        "    base_model = sm.Logit(y, X_base).fit(disp=False)\n",
        "    ll_base = base_model.llf\n",
        "    minus2ll_base = -2 * ll_base\n",
        "\n",
        "    # Fit single-variable models for all candidates\n",
        "    lrt_list = []\n",
        "    for var in candidates:\n",
        "        try:\n",
        "            Xv = sm.add_constant(train_df[[var]])\n",
        "            mv = sm.Logit(y, Xv).fit(disp=False)\n",
        "            ll_v = mv.llf\n",
        "            lr_stat = -2 * (ll_base - ll_v)\n",
        "            pval = chi2.sf(lr_stat, df=1)\n",
        "            lrt_list.append({\"variable\": var, \"lr_stat\": lr_stat, \"p_value\": pval, \"ll_v\": ll_v})\n",
        "        except Exception:\n",
        "            lrt_list.append({\"variable\": var, \"lr_stat\": None, \"p_value\": None, \"ll_v\": None})\n",
        "    \n",
        "    lrt_df = pd.DataFrame(lrt_list).sort_values(\"p_value\", na_position=\"last\").reset_index(drop=True)\n",
        "\n",
        "    # ✅ pick top k variables\n",
        "    top_k_vars = lrt_df.dropna(subset=[\"p_value\"]).sort_values(\"p_value\").head(k)[\"variable\"].tolist()\n",
        "    best_var_display = \", \".join(top_k_vars)\n",
        "\n",
        "    # Fit model with chosen variables\n",
        "    X_best = sm.add_constant(train_df[top_k_vars])\n",
        "    best_model = sm.Logit(y, X_best).fit(disp=False)\n",
        "    ll_best = best_model.llf\n",
        "    minus2ll_best = -2 * ll_best\n",
        "\n",
        "    # Model fit improvements\n",
        "    change_from_base = minus2ll_best - minus2ll_base\n",
        "    df_lr = len(best_model.params) - len(base_model.params)\n",
        "    lr_stat_best = -2 * (ll_base - ll_best)\n",
        "    p_change = chi2.sf(lr_stat_best, df=df_lr)\n",
        "\n",
        "    # R2 variants\n",
        "    ll_null = ll_base\n",
        "    ll_model = ll_best\n",
        "    pseudo_r2 = 1 - (ll_model / ll_null)\n",
        "    r_cs = 1 - np.exp((2.0 / n) * (ll_null - ll_model))\n",
        "    r_max = 1 - np.exp((2.0 / n) * ll_null)\n",
        "    nagelkerke = r_cs / r_max if r_max != 0 else np.nan\n",
        "\n",
        "    # Hosmer-Lemeshow\n",
        "    preds = best_model.predict(X_best)\n",
        "    hl_chi2, hl_p, hl_table = hosmer_lemeshow_test(y, preds, g=g_hl)\n",
        "\n",
        "    # ✅ Table 1: Goodness of Fit\n",
        "    goodness_rows = [\n",
        "        {\"Measure\": \"-2 Log Likelihood (−2LL) value\", \"Value\": round(minus2ll_best, 3),\n",
        "         \"Change_from_Base\": round(change_from_base, 3), \"Change_pvalue\": round(p_change, 4)},\n",
        "        {\"Measure\": \"Cox and Snell R2\", \"Value\": round(r_cs, 3), \"Change_from_Base\": \"\", \"Change_pvalue\": \"\"},\n",
        "        {\"Measure\": \"Nagelkerke R2\", \"Value\": round(nagelkerke, 3), \"Change_from_Base\": \"\", \"Change_pvalue\": \"\"},\n",
        "        {\"Measure\": \"Pseudo R2 (McFadden)\", \"Value\": round(pseudo_r2, 3), \"Change_from_Base\": \"\", \"Change_pvalue\": \"\"},\n",
        "        {\"Measure\": \"Hosmer-Lemeshow χ2\", \"Value\": round(hl_chi2, 3), \"Change_from_Base\": \"\", \"Change_pvalue\": round(hl_p, 4)}\n",
        "    ]\n",
        "    goodness_df = pd.DataFrame(goodness_rows)\n",
        "\n",
        "    # ✅ Table 2: Variables in the Equation\n",
        "    params = best_model.params\n",
        "    bse = best_model.bse\n",
        "    z = params / bse\n",
        "    wald = (z ** 2)\n",
        "    pvals = best_model.pvalues\n",
        "    expb = np.exp(params)\n",
        "    in_eq = []\n",
        "    for var in top_k_vars + [\"const\"]:\n",
        "        if var in params.index:\n",
        "            in_eq.append({\n",
        "                \"Independent Variable\": var if var != \"const\" else \"Constant\",\n",
        "                \"B\": round(params[var], 4),\n",
        "                \"Std. Error\": round(bse[var], 4),\n",
        "                \"Wald\": round(wald[var], 3),\n",
        "                \"df\": 1,\n",
        "                \"Sig.\": round(pvals[var], 4),\n",
        "                \"Exp(B)\": round(expb[var], 4)\n",
        "            })\n",
        "    in_eq_df = pd.DataFrame(in_eq)\n",
        "\n",
        "    # ✅ Table 3: Variables Not in the Equation\n",
        "    not_in = []\n",
        "    for _, row in lrt_df.iterrows():\n",
        "        var = row[\"variable\"]\n",
        "        if var in top_k_vars:\n",
        "            continue\n",
        "        not_in.append({\n",
        "            \"Independent Variable\": var,\n",
        "            \"Score Statistic (LRT)\": None if pd.isna(row[\"lr_stat\"]) else round(row[\"lr_stat\"], 3),\n",
        "            \"Significance\": None if pd.isna(row[\"p_value\"]) else round(row[\"p_value\"], 4)\n",
        "        })\n",
        "    not_in_eq_df = pd.DataFrame(not_in)\n",
        "\n",
        "    if max_vars_display is not None:\n",
        "        not_in_eq_df = not_in_eq_df.head(max_vars_display)\n",
        "\n",
        "    # print results\n",
        "    print(f\"Table: Logistic Regression Stepwise Estimation — Adding {best_var_display}\")\n",
        "    print(\"\\nOverall Model Fit: Goodness-of-Fit Measures\\n\")\n",
        "    print(goodness_df.to_string(index=False))\n",
        "    print(\"\\n\\nVariables in the Equation\\n\")\n",
        "    print(in_eq_df.to_string(index=False))\n",
        "    print(\"\\n\\nVariables Not in the Equation (candidates and LRT vs base)\\n\")\n",
        "    print(not_in_eq_df.to_string(index=False))\n",
        "\n",
        "    return {\n",
        "        \"best_vars\": top_k_vars,\n",
        "        \"goodness_df\": goodness_df,\n",
        "        \"in_eq_df\": in_eq_df,\n",
        "        \"not_in_eq_df\": not_in_eq_df,\n",
        "        \"hl_table\": hl_table,\n",
        "        \"best_model\": best_model\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Matrix — Training Sample\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                   16                 10575   10591        0.2\n",
            "  Normal (0)                   54               7121325 7121379      100.0\n",
            "       Total                   70               7131900 7131970       99.9\n",
            "\n",
            "Classification Matrix — Holdout (Test) Sample\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                    4                  2737    2741        0.1\n",
            "  Normal (0)                   15               1780237 1780252      100.0\n",
            "       Total                   19               1782974 1782993       99.8\n"
          ]
        }
      ],
      "source": [
        "#(寫錯了先不要用)\n",
        "#在 train 與 test 上做預測並分類，並產出分類矩陣\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def classification_table(model, df, target_col=\"is_fraud\", cutoff=0.5):\n",
        "    \"\"\"\n",
        "    建立分類矩陣 (confusion matrix) 與正確率統計\n",
        "    \"\"\"\n",
        "    y_true = df[target_col].astype(int)\n",
        "    X = sm.add_constant(df[model.params.index.drop(\"const\")])\n",
        "    y_pred_prob = model.predict(X)\n",
        "    y_pred = (y_pred_prob >= cutoff).astype(int)\n",
        "    \n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
        "    TP, FN, FP, TN = cm.ravel()  # 注意順序是 [ [TP, FN], [FP, TN] ]\n",
        "    \n",
        "    fraud_total = TP + FN\n",
        "    normal_total = FP + TN\n",
        "    \n",
        "    fraud_correct = TP / fraud_total if fraud_total > 0 else 0\n",
        "    normal_correct = TN / normal_total if normal_total > 0 else 0\n",
        "    overall_correct = (TP + TN) / (fraud_total + normal_total)\n",
        "    \n",
        "    table = pd.DataFrame({\n",
        "        \"Actual Group\": [\"Fraud (1)\", \"Normal (0)\", \"Total\"],\n",
        "        \"Predicted Fraud (1)\": [TP, FP, TP+FP],\n",
        "        \"Predicted Normal (0)\": [FN, TN, FN+TN],\n",
        "        \"Total\": [fraud_total, normal_total, fraud_total + normal_total],\n",
        "        \"% Correct\": [round(fraud_correct*100, 1), round(normal_correct*100, 1), round(overall_correct*100, 1)]\n",
        "    })\n",
        "    \n",
        "    return table\n",
        "\n",
        "# 產出訓練集和測試集的分類矩陣\n",
        "best_model = results[\"best_model\"]\n",
        "\n",
        "train_table = classification_table(best_model, train_df, target_col=\"is_fraud\")\n",
        "test_table = classification_table(best_model, test_df, target_col=\"is_fraud\")\n",
        "\n",
        "print(\"Classification Matrix — Training Sample\")\n",
        "print(train_table.to_string(index=False))\n",
        "\n",
        "print(\"\\nClassification Matrix — Holdout (Test) Sample\")\n",
        "print(test_table.to_string(index=False))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0: Base model estimated. -2LL = 159110.612\n",
            "Step 1: Added amount, p = 0.0000, -2LL = 156596.132\n",
            "Step 2: Added zip, p = 0.0000, -2LL = 132160.472\n",
            "Step 3: Added longitude, p = 0.0000, -2LL = 130365.785\n",
            "Step 4: Added merchant_id, p = 0.0000, -2LL = 129422.859\n",
            "Step 5: Added use_chip_Swipe Transaction, p = 0.0000, -2LL = 128369.766\n",
            "Step 6: Added credit_limit, p = 0.0000, -2LL = 127721.557\n",
            "Step 7: Added num_credit_cards, p = 0.0000, -2LL = 127399.629\n",
            "Step 8: Added errors_missing_flag, p = 0.0000, -2LL = 127194.361\n",
            "Step 9: Added use_chip_Chip Transaction, p = 0.0000, -2LL = 126969.403\n",
            "Step 10: Added transaction_id, p = 0.0000, -2LL = 126659.120\n",
            "Step 11: Added yearly_income, p = 0.0000, -2LL = 126479.431\n",
            "Step 12: Added latitude, p = 0.0000, -2LL = 126331.866\n",
            "Step 13: Added client_id_x, p = 0.0000, -2LL = 126287.731\n",
            "Step 14: Added has_chip_YES, p = 0.0000, -2LL = 126259.387\n",
            "Step 15: Added credit_score, p = 0.0000, -2LL = 126231.397\n",
            "Step 16: Added retirement_age, p = 0.0001, -2LL = 126215.109\n",
            "Step 17: Added card_type_Credit, p = 0.0000, -2LL = 126196.468\n",
            "Step 18: Added card_type_Debit, p = 0.0000, -2LL = 126161.194\n",
            "Step 19: Added mcc_code, p = 0.0029, -2LL = 126152.192\n",
            "Step 20: Added card_brand_Visa, p = 0.0138, -2LL = 126146.098\n",
            "Step 21: Added card_brand_Mastercard, p = 0.0255, -2LL = 126141.149\n",
            "Step 22: Added card_brand_Amex, p = 0.0000, -2LL = 126119.895\n",
            "Step 23: Added card_id, p = 0.0250, -2LL = 126114.885\n",
            "\n",
            "✅ No more variables meet the entry threshold. Stepwise selection finished.\n",
            "\n",
            "Final model summary:\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:               is_fraud   No. Observations:              7131970\n",
            "Model:                          Logit   Df Residuals:                  7131945\n",
            "Method:                           MLE   Df Model:                           24\n",
            "Date:                Mon, 06 Oct 2025   Pseudo R-squ.:                  0.2074\n",
            "Time:                        20:05:54   Log-Likelihood:                -63057.\n",
            "converged:                       True   LL-Null:                       -79555.\n",
            "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
            "==============================================================================================\n",
            "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "----------------------------------------------------------------------------------------------\n",
            "const                         -5.3101      0.254    -20.889      0.000      -5.808      -4.812\n",
            "amount                         0.0026   4.97e-05     52.698      0.000       0.003       0.003\n",
            "zip                        -9.421e-05   1.37e-06    -68.580      0.000   -9.69e-05   -9.15e-05\n",
            "longitude                     -0.0208      0.001    -35.590      0.000      -0.022      -0.020\n",
            "merchant_id                 1.066e-05   3.72e-07     28.683      0.000    9.93e-06    1.14e-05\n",
            "use_chip_Swipe Transaction    -0.7149      0.040    -17.660      0.000      -0.794      -0.636\n",
            "credit_limit                 -1.5e-05   1.31e-06    -11.413      0.000   -1.76e-05   -1.24e-05\n",
            "num_credit_cards               0.0933      0.006     14.741      0.000       0.081       0.106\n",
            "errors_missing_flag           -0.7900      0.048    -16.317      0.000      -0.885      -0.695\n",
            "use_chip_Chip Transaction      0.8156      0.034     23.947      0.000       0.749       0.882\n",
            "transaction_id             -4.274e-08    2.4e-09    -17.790      0.000   -4.74e-08    -3.8e-08\n",
            "yearly_income              -7.414e-06   5.83e-07    -12.711      0.000   -8.56e-06   -6.27e-06\n",
            "latitude                      -0.0233      0.002    -11.936      0.000      -0.027      -0.020\n",
            "client_id_x                   -0.0001    1.7e-05     -6.582      0.000      -0.000   -7.87e-05\n",
            "has_chip_YES                  -0.1911      0.035     -5.409      0.000      -0.260      -0.122\n",
            "credit_score                   0.0007      0.000      4.433      0.000       0.000       0.001\n",
            "retirement_age                 0.0133      0.003      4.553      0.000       0.008       0.019\n",
            "card_type_Credit              -0.3022      0.041     -7.423      0.000      -0.382      -0.222\n",
            "card_type_Debit               -0.2335      0.041     -5.739      0.000      -0.313      -0.154\n",
            "mcc_code                   -3.558e-05   1.16e-05     -3.073      0.002   -5.83e-05   -1.29e-05\n",
            "card_brand_Visa               -0.3294      0.056     -5.844      0.000      -0.440      -0.219\n",
            "card_brand_Mastercard         -0.2932      0.057     -5.142      0.000      -0.405      -0.181\n",
            "card_brand_Amex               -0.3027      0.064     -4.742      0.000      -0.428      -0.178\n",
            "card_id                    -1.296e-05   5.85e-06     -2.218      0.027   -2.44e-05   -1.51e-06\n",
            "cvv                         3.144e-05   3.39e-05      0.928      0.354    -3.5e-05    9.79e-05\n",
            "==============================================================================================\n",
            "\n",
            "Possibly complete quasi-separation: A fraction 0.49 of observations can be\n",
            "perfectly predicted. This might indicate that there is complete\n",
            "quasi-separation. In this case some parameters will not be identified.\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Step",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Variable Entered",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "-2 Log Likelihood",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "956e14ed-8550-4c2d-817f-39c5975b5e54",
              "rows": [
                [
                  "0",
                  "0",
                  null,
                  "159110.61205098676"
                ],
                [
                  "1",
                  "1",
                  "amount",
                  "156596.1318859173"
                ],
                [
                  "2",
                  "2",
                  "zip",
                  "132160.47242328618"
                ],
                [
                  "3",
                  "3",
                  "longitude",
                  "130365.78537629134"
                ],
                [
                  "4",
                  "4",
                  "merchant_id",
                  "129422.85897686762"
                ],
                [
                  "5",
                  "5",
                  "use_chip_Swipe Transaction",
                  "128369.76553755146"
                ],
                [
                  "6",
                  "6",
                  "credit_limit",
                  "127721.5573537219"
                ],
                [
                  "7",
                  "7",
                  "num_credit_cards",
                  "127399.6289361857"
                ],
                [
                  "8",
                  "8",
                  "errors_missing_flag",
                  "127194.36144428997"
                ],
                [
                  "9",
                  "9",
                  "use_chip_Chip Transaction",
                  "126969.403353223"
                ],
                [
                  "10",
                  "10",
                  "transaction_id",
                  "126659.12047431353"
                ],
                [
                  "11",
                  "11",
                  "yearly_income",
                  "126479.43146008762"
                ],
                [
                  "12",
                  "12",
                  "latitude",
                  "126331.86559310334"
                ],
                [
                  "13",
                  "13",
                  "client_id_x",
                  "126287.73082180246"
                ],
                [
                  "14",
                  "14",
                  "has_chip_YES",
                  "126259.38712661443"
                ],
                [
                  "15",
                  "15",
                  "credit_score",
                  "126231.39740436297"
                ],
                [
                  "16",
                  "16",
                  "retirement_age",
                  "126215.10906426272"
                ],
                [
                  "17",
                  "17",
                  "card_type_Credit",
                  "126196.46814774227"
                ],
                [
                  "18",
                  "18",
                  "card_type_Debit",
                  "126161.1941248596"
                ],
                [
                  "19",
                  "19",
                  "mcc_code",
                  "126152.1919911101"
                ],
                [
                  "20",
                  "20",
                  "card_brand_Visa",
                  "126146.09812282966"
                ],
                [
                  "21",
                  "21",
                  "card_brand_Mastercard",
                  "126141.1489606208"
                ],
                [
                  "22",
                  "22",
                  "card_brand_Amex",
                  "126119.89492591114"
                ],
                [
                  "23",
                  "23",
                  "card_id",
                  "126114.88498004613"
                ]
              ],
              "shape": {
                "columns": 3,
                "rows": 24
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Step</th>\n",
              "      <th>Variable Entered</th>\n",
              "      <th>-2 Log Likelihood</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>159110.612051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>amount</td>\n",
              "      <td>156596.131886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>zip</td>\n",
              "      <td>132160.472423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>longitude</td>\n",
              "      <td>130365.785376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>merchant_id</td>\n",
              "      <td>129422.858977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>use_chip_Swipe Transaction</td>\n",
              "      <td>128369.765538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>credit_limit</td>\n",
              "      <td>127721.557354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>num_credit_cards</td>\n",
              "      <td>127399.628936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>errors_missing_flag</td>\n",
              "      <td>127194.361444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>use_chip_Chip Transaction</td>\n",
              "      <td>126969.403353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>transaction_id</td>\n",
              "      <td>126659.120474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>yearly_income</td>\n",
              "      <td>126479.431460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>latitude</td>\n",
              "      <td>126331.865593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>client_id_x</td>\n",
              "      <td>126287.730822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>has_chip_YES</td>\n",
              "      <td>126259.387127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>credit_score</td>\n",
              "      <td>126231.397404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>retirement_age</td>\n",
              "      <td>126215.109064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>card_type_Credit</td>\n",
              "      <td>126196.468148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>card_type_Debit</td>\n",
              "      <td>126161.194125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>mcc_code</td>\n",
              "      <td>126152.191991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>card_brand_Visa</td>\n",
              "      <td>126146.098123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>card_brand_Mastercard</td>\n",
              "      <td>126141.148961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>card_brand_Amex</td>\n",
              "      <td>126119.894926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>card_id</td>\n",
              "      <td>126114.884980</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Step            Variable Entered  -2 Log Likelihood\n",
              "0      0                        None      159110.612051\n",
              "1      1                      amount      156596.131886\n",
              "2      2                         zip      132160.472423\n",
              "3      3                   longitude      130365.785376\n",
              "4      4                 merchant_id      129422.858977\n",
              "5      5  use_chip_Swipe Transaction      128369.765538\n",
              "6      6                credit_limit      127721.557354\n",
              "7      7            num_credit_cards      127399.628936\n",
              "8      8         errors_missing_flag      127194.361444\n",
              "9      9   use_chip_Chip Transaction      126969.403353\n",
              "10    10              transaction_id      126659.120474\n",
              "11    11               yearly_income      126479.431460\n",
              "12    12                    latitude      126331.865593\n",
              "13    13                 client_id_x      126287.730822\n",
              "14    14                has_chip_YES      126259.387127\n",
              "15    15                credit_score      126231.397404\n",
              "16    16              retirement_age      126215.109064\n",
              "17    17            card_type_Credit      126196.468148\n",
              "18    18             card_type_Debit      126161.194125\n",
              "19    19                    mcc_code      126152.191991\n",
              "20    20             card_brand_Visa      126146.098123\n",
              "21    21       card_brand_Mastercard      126141.148961\n",
              "22    22             card_brand_Amex      126119.894926\n",
              "23    23                     card_id      126114.884980"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Stepwise Selection all variables\n",
        "\n",
        "def stepwise_logit(train_df, target_col=\"is_fraud\", entry_threshold=0.05):\n",
        "    # ✅ 確保索引對齊\n",
        "    train_df = train_df.reset_index(drop=True)\n",
        "    y = train_df[target_col].reset_index(drop=True)\n",
        "    \n",
        "    candidate_vars = list(train_df.columns.drop(target_col))\n",
        "    included_vars = []\n",
        "    step_results = []\n",
        "    \n",
        "    # Base model (only intercept)\n",
        "    X_base = sm.add_constant(pd.DataFrame({\"intercept\": [1]*len(train_df)}))\n",
        "    base_model = sm.Logit(y, X_base).fit(disp=False)\n",
        "    base_ll = -2 * base_model.llf\n",
        "    step_results.append({\"Step\": 0, \"Variable Entered\": None, \"-2 Log Likelihood\": base_ll})\n",
        "    \n",
        "    print(f\"Step 0: Base model estimated. -2LL = {base_ll:.3f}\")\n",
        "    \n",
        "    step = 1\n",
        "    while True:\n",
        "        best_pval = 1\n",
        "        best_var = None\n",
        "        best_model = None\n",
        "        \n",
        "        for var in candidate_vars:\n",
        "            try:\n",
        "                X_temp = sm.add_constant(train_df[included_vars + [var]])\n",
        "                model_temp = sm.Logit(y, X_temp).fit(disp=False)\n",
        "                pval = model_temp.pvalues[var]\n",
        "                \n",
        "                if pval < best_pval:\n",
        "                    best_pval = pval\n",
        "                    best_var = var\n",
        "                    best_model = model_temp\n",
        "                    \n",
        "            except Exception:\n",
        "                continue\n",
        "        \n",
        "        if best_var is None or best_pval > entry_threshold:\n",
        "            print(\"\\n✅ No more variables meet the entry threshold. Stepwise selection finished.\")\n",
        "            break\n",
        "        \n",
        "        included_vars.append(best_var)\n",
        "        candidate_vars.remove(best_var)\n",
        "        \n",
        "        ll = -2 * best_model.llf\n",
        "        step_results.append({\"Step\": step, \"Variable Entered\": best_var, \"-2 Log Likelihood\": ll})\n",
        "        \n",
        "        print(f\"Step {step}: Added {best_var}, p = {best_pval:.4f}, -2LL = {ll:.3f}\")\n",
        "        step += 1\n",
        "    \n",
        "    print(\"\\nFinal model summary:\")\n",
        "    print(best_model.summary())\n",
        "    \n",
        "    step_df = pd.DataFrame(step_results)\n",
        "    return step_df, best_model\n",
        "\n",
        "# 🚀 執行\n",
        "step_df, final_model = stepwise_logit(train_df, target_col=\"is_fraud\")\n",
        "step_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def stepwise_logit_with_k_tables(train_df, test_df, dep_var=\"is_fraud\", k=314657018,\n",
        "                                 threshold_in=0.05, threshold_out=0.10):\n",
        "    \"\"\"\n",
        "    Stepwise logistic regression (forward + backward) with flexible k control,\n",
        "    and 3 formatted output tables like table_for_first_step().\n",
        "    \"\"\"\n",
        "\n",
        "    y_train = train_df[dep_var]\n",
        "    X_train = train_df.drop(columns=[dep_var])\n",
        "    y_test = test_df[dep_var]\n",
        "    X_test = test_df.drop(columns=[dep_var])\n",
        "\n",
        "    included = []\n",
        "    step = 0\n",
        "    full_mode = (k == 314657018)\n",
        "    base_model = None\n",
        "\n",
        "    while True:\n",
        "        step += 1\n",
        "        changed = False\n",
        "\n",
        "        # ---------- Forward Step ----------\n",
        "        excluded = list(set(X_train.columns) - set(included))\n",
        "        new_pvals = pd.Series(index=excluded, dtype=float)\n",
        "        for new_var in excluded:\n",
        "            try:\n",
        "                model = sm.Logit(y_train, sm.add_constant(X_train[included + [new_var]])).fit(disp=False)\n",
        "                new_pvals[new_var] = model.pvalues[new_var]\n",
        "            except Exception:\n",
        "                new_pvals[new_var] = np.nan\n",
        "\n",
        "        if new_pvals.empty:\n",
        "            break\n",
        "\n",
        "        best_pval = new_pvals.min()\n",
        "        if best_pval < threshold_in:\n",
        "            best_var = new_pvals.idxmin()\n",
        "            included.append(best_var)\n",
        "            changed = True\n",
        "\n",
        "        # ---------- Backward Step ----------\n",
        "        if included:\n",
        "            model = sm.Logit(y_train, sm.add_constant(X_train[included])).fit(disp=False)\n",
        "            pvalues = model.pvalues.iloc[1:]\n",
        "            worst_pval = pvalues.max()\n",
        "            if worst_pval > threshold_out:\n",
        "                worst_var = pvalues.idxmax()\n",
        "                included.remove(worst_var)\n",
        "                changed = True\n",
        "\n",
        "        # ---------- 結束條件 ----------\n",
        "        if not changed:\n",
        "            break\n",
        "        if not full_mode and len(included) >= k:\n",
        "            break\n",
        "\n",
        "    # ========= Final Model =========\n",
        "    final_model = sm.Logit(y_train, sm.add_constant(X_train[included])).fit(disp=False)\n",
        "    ll_full = final_model.llf\n",
        "    ll_null = sm.Logit(y_train, sm.add_constant(np.ones(len(y_train)))).fit(disp=False).llf\n",
        "\n",
        "    # 1️⃣ Overall Model Fit\n",
        "    ll_diff = -2 * (ll_null - ll_full)\n",
        "    df_diff = len(final_model.params) - 1\n",
        "    p_value = stats.chi2.sf(ll_diff, df_diff)\n",
        "\n",
        "    overall_fit = pd.DataFrame({\n",
        "        \"Measure\": [\n",
        "            \"-2 Log Likelihood (−2LL) value\",\n",
        "            \"Cox and Snell R2\",\n",
        "            \"Nagelkerke R2\",\n",
        "            \"Pseudo R2 (McFadden)\",\n",
        "            \"Hosmer-Lemeshow χ2\"\n",
        "        ],\n",
        "        \"Value\": [\n",
        "            round(-2 * ll_full, 3),\n",
        "            round(1 - np.exp((2 / len(y_train)) * (ll_null - ll_full)), 3),\n",
        "            round((1 - np.exp((2 / len(y_train)) * (ll_null - ll_full))) / (1 - np.exp(2 * ll_null / len(y_train))), 3),\n",
        "            round(1 - (ll_full / ll_null), 3),\n",
        "            round(ll_diff, 3)\n",
        "        ],\n",
        "        \"Change_from_Base\": [\n",
        "            round(-2 * (ll_null - ll_full), 3),\n",
        "            \"\", \"\", \"\", \"\"\n",
        "        ],\n",
        "        \"Change_pvalue\": [\n",
        "            round(p_value, 4),\n",
        "            \"\", \"\", \"\", \"\"\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    # 2️⃣ Variables in the Equation\n",
        "    coef_df = pd.DataFrame({\n",
        "        \"Independent Variable\": final_model.params.index,\n",
        "        \"B\": final_model.params.values,\n",
        "        \"Std. Error\": final_model.bse.values,\n",
        "        \"Wald\": (final_model.params / final_model.bse) ** 2,\n",
        "        \"df\": 1,\n",
        "        \"Sig.\": final_model.pvalues.values,\n",
        "        \"Exp(B)\": np.exp(final_model.params.values)\n",
        "    })\n",
        "    coef_df = coef_df.reset_index(drop=True)\n",
        "\n",
        "    # 3️⃣ Variables Not in the Equation\n",
        "    excluded_vars = [v for v in X_train.columns if v not in included]\n",
        "    not_in_eq = []\n",
        "    for var in excluded_vars:\n",
        "        try:\n",
        "            temp_model = sm.Logit(y_train, sm.add_constant(X_train[included + [var]])).fit(disp=False)\n",
        "            lr_stat = -2 * (final_model.llf - temp_model.llf)\n",
        "            p_val = stats.chi2.sf(lr_stat, 1)\n",
        "            not_in_eq.append({\"Independent Variable\": var,\n",
        "                              \"Score Statistic (LRT)\": round(lr_stat, 3),\n",
        "                              \"Significance\": round(p_val, 4)})\n",
        "        except Exception:\n",
        "            not_in_eq.append({\"Independent Variable\": var,\n",
        "                              \"Score Statistic (LRT)\": None,\n",
        "                              \"Significance\": None})\n",
        "\n",
        "    not_in_eq_df = pd.DataFrame(not_in_eq)\n",
        "\n",
        "    # 額外：Train / Test Accuracy\n",
        "    train_pred = (final_model.predict(sm.add_constant(X_train[included])) > 0.5).astype(int)\n",
        "    test_pred = (final_model.predict(sm.add_constant(X_test[included])) > 0.5).astype(int)\n",
        "    train_acc = (train_pred == y_train).mean()\n",
        "    test_acc = (test_pred == y_test).mean()\n",
        "\n",
        "    print(f\"\\n✅ Stepwise completed with {len(included)} variables: {included}\")\n",
        "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    return overall_fit, coef_df, not_in_eq_df, final_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Stepwise completed with 1 variables: ['amount']\n",
            "Train Accuracy: 0.9985, Test Accuracy: 0.9985\n",
            "=== Overall Model Fit ===\n",
            "                          Measure       Value Change_from_Base Change_pvalue\n",
            "0  -2 Log Likelihood (−2LL) value  156596.132          2514.48           0.0\n",
            "1                Cox and Snell R2       0.000                               \n",
            "2                   Nagelkerke R2       0.016                               \n",
            "3            Pseudo R2 (McFadden)       0.016                               \n",
            "4              Hosmer-Lemeshow χ2    2514.480                               \n",
            "\n",
            "=== Variables in the Equation ===\n",
            "  Independent Variable         B  Std. Error           Wald  df  Sig.  \\\n",
            "0                const -6.669261    0.010435  408490.171355   1   0.0   \n",
            "1               amount  0.002635    0.000041    4155.604769   1   0.0   \n",
            "\n",
            "     Exp(B)  \n",
            "0  0.001269  \n",
            "1  1.002638  \n",
            "\n",
            "=== Variables Not in the Equation ===\n",
            "          Independent Variable  Score Statistic (LRT)  Significance\n",
            "0               transaction_id                  2.224        0.1359\n",
            "1                  client_id_x                  0.810        0.3680\n",
            "2                      card_id                  7.316        0.0068\n",
            "3                  merchant_id                269.892        0.0000\n",
            "4                          zip              24435.659        0.0000\n",
            "5                     mcc_code               1213.597        0.0000\n",
            "6          errors_missing_flag                338.804        0.0000\n",
            "7    use_chip_Chip Transaction                665.857        0.0000\n",
            "8   use_chip_Swipe Transaction               8443.861        0.0000\n",
            "9                  current_age                126.100        0.0000\n",
            "10              retirement_age                  1.915        0.1664\n",
            "11                    latitude                 21.875        0.0000\n",
            "12                   longitude                 11.576        0.0007\n",
            "13               yearly_income                321.943        0.0000\n",
            "14                  total_debt                123.778        0.0000\n",
            "15                credit_score                 14.251        0.0002\n",
            "16            num_credit_cards                337.445        0.0000\n",
            "17                 gender_Male                  1.713        0.1906\n",
            "18                         cvv                  0.770        0.3801\n",
            "19            num_cards_issued                  0.034        0.8539\n",
            "20                credit_limit                397.394        0.0000\n",
            "21            card_type_Credit                  3.281        0.0701\n",
            "22             card_type_Debit                 98.707        0.0000\n",
            "23             card_brand_Amex                  0.704        0.4015\n",
            "24       card_brand_Mastercard                  0.076        0.7825\n",
            "25             card_brand_Visa                  8.015        0.0046\n",
            "26                has_chip_YES                 14.057        0.0002\n",
            "\n",
            "================================================\n",
            "\n",
            "=== Accuracy in Training and Testing dataset ===\n",
            "\n",
            "=== Classification Matrix — Training Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                   10                 10581   10591        0.1\n",
            "  Normal (0)                   63               7121316 7121379      100.0\n",
            "       Total                   73               7131897 7131970       99.9\n",
            "\n",
            "=== Classification Matrix — Holdout (Test) Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                    2                  2739    2741        0.1\n",
            "  Normal (0)                   20               1780232 1780252      100.0\n",
            "       Total                   22               1782971 1782993       99.8\n"
          ]
        }
      ],
      "source": [
        "overall_fit, coef_df, not_in_eq_df, final_model = stepwise_logit_with_k_tables(\n",
        "    train_df, test_df, dep_var=\"is_fraud\", k=1\n",
        ")\n",
        "\n",
        "\n",
        "print(\"=== Overall Model Fit ===\")\n",
        "print(overall_fit)\n",
        "\n",
        "print(\"\\n=== Variables in the Equation ===\")\n",
        "print(coef_df)\n",
        "\n",
        "print(\"\\n=== Variables Not in the Equation ===\")\n",
        "print(not_in_eq_df)\n",
        "\n",
        "print(\"\\n================================================\")\n",
        "print(\"\\n=== Accuracy in Training and Testing dataset ===\")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def classification_table(model, df, target_col=\"is_fraud\", cutoff=0.5):\n",
        "    y_true = df[target_col].astype(int)\n",
        "    X = sm.add_constant(df[model.params.index.drop(\"const\")])\n",
        "    y_pred_prob = model.predict(X)\n",
        "    y_pred = (y_pred_prob >= cutoff).astype(int)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
        "    TP, FN, FP, TN = cm.ravel()\n",
        "\n",
        "    fraud_total = TP + FN\n",
        "    normal_total = FP + TN\n",
        "\n",
        "    fraud_correct = TP / fraud_total if fraud_total > 0 else 0\n",
        "    normal_correct = TN / normal_total if normal_total > 0 else 0\n",
        "    overall_correct = (TP + TN) / (fraud_total + normal_total)\n",
        "\n",
        "    table = pd.DataFrame({\n",
        "        \"Actual Group\": [\"Fraud (1)\", \"Normal (0)\", \"Total\"],\n",
        "        \"Predicted Fraud (1)\": [TP, FP, TP + FP],\n",
        "        \"Predicted Normal (0)\": [FN, TN, FN + TN],\n",
        "        \"Total\": [fraud_total, normal_total, fraud_total + normal_total],\n",
        "        \"% Correct\": [\n",
        "            round(fraud_correct * 100, 1),\n",
        "            round(normal_correct * 100, 1),\n",
        "            round(overall_correct * 100, 1),\n",
        "        ],\n",
        "    })\n",
        "    return table\n",
        "\n",
        "# Step 3. 產出訓練集和測試集的結果表\n",
        "train_table = classification_table(final_model, train_df, target_col=\"is_fraud\")\n",
        "test_table = classification_table(final_model, test_df, target_col=\"is_fraud\")\n",
        "\n",
        "print(\"\\n=== Classification Matrix — Training Sample ===\")\n",
        "print(train_table.to_string(index=False))\n",
        "print(\"\\n=== Classification Matrix — Holdout (Test) Sample ===\")\n",
        "print(test_table.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Stepwise completed with 2 variables: ['amount', 'zip']\n",
            "Train Accuracy: 0.9985, Test Accuracy: 0.9985\n",
            "=== Overall Model Fit ===\n",
            "                          Measure       Value Change_from_Base Change_pvalue\n",
            "0  -2 Log Likelihood (−2LL) value  132160.472         26950.14           0.0\n",
            "1                Cox and Snell R2       0.004                               \n",
            "2                   Nagelkerke R2       0.171                               \n",
            "3            Pseudo R2 (McFadden)       0.169                               \n",
            "4              Hosmer-Lemeshow χ2   26950.140                               \n",
            "\n",
            "=== Variables in the Equation ===\n",
            "  Independent Variable         B  Std. Error           Wald  df  Sig.  \\\n",
            "0                const -5.042287    0.011809  182312.965555   1   0.0   \n",
            "1               amount  0.002291    0.000045    2574.184666   1   0.0   \n",
            "2                  zip -0.000101    0.000001    7453.420607   1   0.0   \n",
            "\n",
            "     Exp(B)  \n",
            "0  0.006459  \n",
            "1  1.002293  \n",
            "2  0.999899  \n",
            "\n",
            "=== Variables Not in the Equation ===\n",
            "          Independent Variable  Score Statistic (LRT)  Significance\n",
            "0               transaction_id                  1.149        0.2838\n",
            "1                  client_id_x                 43.012        0.0000\n",
            "2                      card_id                  5.104        0.0239\n",
            "3                  merchant_id                741.511        0.0000\n",
            "4                     mcc_code                  0.388        0.5336\n",
            "5          errors_missing_flag                237.637        0.0000\n",
            "6    use_chip_Chip Transaction                385.363        0.0000\n",
            "7   use_chip_Swipe Transaction               1460.427        0.0000\n",
            "8                  current_age                157.508        0.0000\n",
            "9               retirement_age                 30.813        0.0000\n",
            "10                    latitude                504.700        0.0000\n",
            "11                   longitude               1794.687        0.0000\n",
            "12               yearly_income               1190.288        0.0000\n",
            "13                  total_debt                344.124        0.0000\n",
            "14                credit_score                 95.914        0.0000\n",
            "15            num_credit_cards                452.970        0.0000\n",
            "16                 gender_Male                  3.306        0.0690\n",
            "17                         cvv                  7.397        0.0065\n",
            "18            num_cards_issued                  4.242        0.0394\n",
            "19                credit_limit                987.600        0.0000\n",
            "20            card_type_Credit                 15.493        0.0001\n",
            "21             card_type_Debit                131.113        0.0000\n",
            "22             card_brand_Amex                  0.092        0.7621\n",
            "23       card_brand_Mastercard                  0.286        0.5925\n",
            "24             card_brand_Visa                  7.784        0.0053\n",
            "25                has_chip_YES                  0.049        0.8254\n",
            "\n",
            "================================================\n",
            "\n",
            "=== Accuracy in Training and Testing dataset ===\n",
            "\n",
            "=== Classification Matrix — Training Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                   16                 10575   10591        0.2\n",
            "  Normal (0)                   57               7121322 7121379      100.0\n",
            "       Total                   73               7131897 7131970       99.9\n",
            "\n",
            "=== Classification Matrix — Holdout (Test) Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                    4                  2737    2741        0.1\n",
            "  Normal (0)                   16               1780236 1780252      100.0\n",
            "       Total                   20               1782973 1782993       99.8\n"
          ]
        }
      ],
      "source": [
        "overall_fit, coef_df, not_in_eq_df, final_model = stepwise_logit_with_k_tables(\n",
        "    train_df, test_df, dep_var=\"is_fraud\", k=2\n",
        ")\n",
        "\n",
        "\n",
        "print(\"=== Overall Model Fit ===\")\n",
        "print(overall_fit)\n",
        "\n",
        "print(\"\\n=== Variables in the Equation ===\")\n",
        "print(coef_df)\n",
        "\n",
        "print(\"\\n=== Variables Not in the Equation ===\")\n",
        "print(not_in_eq_df)\n",
        "\n",
        "print(\"\\n================================================\")\n",
        "print(\"\\n=== Accuracy in Training and Testing dataset ===\")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def classification_table(model, df, target_col=\"is_fraud\", cutoff=0.5):\n",
        "    y_true = df[target_col].astype(int)\n",
        "    X = sm.add_constant(df[model.params.index.drop(\"const\")])\n",
        "    y_pred_prob = model.predict(X)\n",
        "    y_pred = (y_pred_prob >= cutoff).astype(int)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
        "    TP, FN, FP, TN = cm.ravel()\n",
        "\n",
        "    fraud_total = TP + FN\n",
        "    normal_total = FP + TN\n",
        "\n",
        "    fraud_correct = TP / fraud_total if fraud_total > 0 else 0\n",
        "    normal_correct = TN / normal_total if normal_total > 0 else 0\n",
        "    overall_correct = (TP + TN) / (fraud_total + normal_total)\n",
        "\n",
        "    table = pd.DataFrame({\n",
        "        \"Actual Group\": [\"Fraud (1)\", \"Normal (0)\", \"Total\"],\n",
        "        \"Predicted Fraud (1)\": [TP, FP, TP + FP],\n",
        "        \"Predicted Normal (0)\": [FN, TN, FN + TN],\n",
        "        \"Total\": [fraud_total, normal_total, fraud_total + normal_total],\n",
        "        \"% Correct\": [\n",
        "            round(fraud_correct * 100, 1),\n",
        "            round(normal_correct * 100, 1),\n",
        "            round(overall_correct * 100, 1),\n",
        "        ],\n",
        "    })\n",
        "    return table\n",
        "\n",
        "# Step 3. 產出訓練集和測試集的結果表\n",
        "train_table = classification_table(final_model, train_df, target_col=\"is_fraud\")\n",
        "test_table = classification_table(final_model, test_df, target_col=\"is_fraud\")\n",
        "\n",
        "print(\"\\n=== Classification Matrix — Training Sample ===\")\n",
        "print(train_table.to_string(index=False))\n",
        "print(\"\\n=== Classification Matrix — Holdout (Test) Sample ===\")\n",
        "print(test_table.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Stepwise completed with 3 variables: ['amount', 'zip', 'longitude']\n",
            "Train Accuracy: 0.9985, Test Accuracy: 0.9985\n",
            "=== Overall Model Fit ===\n",
            "                          Measure       Value Change_from_Base Change_pvalue\n",
            "0  -2 Log Likelihood (−2LL) value  130365.785        28744.827           0.0\n",
            "1                Cox and Snell R2       0.004                               \n",
            "2                   Nagelkerke R2       0.182                               \n",
            "3            Pseudo R2 (McFadden)       0.181                               \n",
            "4              Hosmer-Lemeshow χ2   28744.827                               \n",
            "\n",
            "=== Variables in the Equation ===\n",
            "  Independent Variable         B  Std. Error          Wald  df  Sig.    Exp(B)\n",
            "0                const -7.173969    0.050525  20160.905638   1   0.0  0.000766\n",
            "1               amount  0.002290    0.000045   2569.711326   1   0.0  1.002293\n",
            "2                  zip -0.000090    0.000001   6942.907659   1   0.0  0.999911\n",
            "3            longitude -0.023565    0.000522   2040.979358   1   0.0  0.976711\n",
            "\n",
            "=== Variables Not in the Equation ===\n",
            "          Independent Variable  Score Statistic (LRT)  Significance\n",
            "0               transaction_id                  1.366        0.2425\n",
            "1                  client_id_x                 84.225        0.0000\n",
            "2                      card_id                 18.269        0.0000\n",
            "3                  merchant_id                942.926        0.0000\n",
            "4                     mcc_code                 15.292        0.0001\n",
            "5          errors_missing_flag                224.322        0.0000\n",
            "6    use_chip_Chip Transaction                786.069        0.0000\n",
            "7   use_chip_Swipe Transaction                975.627        0.0000\n",
            "8                  current_age                 42.508        0.0000\n",
            "9               retirement_age                 22.077        0.0000\n",
            "10                    latitude                110.494        0.0000\n",
            "11               yearly_income                791.044        0.0000\n",
            "12                  total_debt                190.573        0.0000\n",
            "13                credit_score                 76.326        0.0000\n",
            "14            num_credit_cards                271.419        0.0000\n",
            "15                 gender_Male                  0.107        0.7433\n",
            "16                         cvv                  4.247        0.0393\n",
            "17            num_cards_issued                  2.148        0.1427\n",
            "18                credit_limit                817.642        0.0000\n",
            "19            card_type_Credit                  9.912        0.0016\n",
            "20             card_type_Debit                109.428        0.0000\n",
            "21             card_brand_Amex                  0.038        0.8458\n",
            "22       card_brand_Mastercard                  0.022        0.8831\n",
            "23             card_brand_Visa                  7.596        0.0059\n",
            "24                has_chip_YES                  2.757        0.0968\n",
            "\n",
            "================================================\n",
            "\n",
            "=== Accuracy in Training and Testing dataset ===\n",
            "\n",
            "=== Classification Matrix — Training Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                   14                 10577   10591        0.1\n",
            "  Normal (0)                   54               7121325 7121379      100.0\n",
            "       Total                   68               7131902 7131970       99.9\n",
            "\n",
            "=== Classification Matrix — Holdout (Test) Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                    4                  2737    2741        0.1\n",
            "  Normal (0)                   14               1780238 1780252      100.0\n",
            "       Total                   18               1782975 1782993       99.8\n"
          ]
        }
      ],
      "source": [
        "overall_fit, coef_df, not_in_eq_df, final_model = stepwise_logit_with_k_tables(\n",
        "    train_df, test_df, dep_var=\"is_fraud\", k=3\n",
        ")\n",
        "\n",
        "\n",
        "print(\"=== Overall Model Fit ===\")\n",
        "print(overall_fit)\n",
        "\n",
        "print(\"\\n=== Variables in the Equation ===\")\n",
        "print(coef_df)\n",
        "\n",
        "print(\"\\n=== Variables Not in the Equation ===\")\n",
        "print(not_in_eq_df)\n",
        "\n",
        "print(\"\\n================================================\")\n",
        "print(\"\\n=== Accuracy in Training and Testing dataset ===\")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def classification_table(model, df, target_col=\"is_fraud\", cutoff=0.5):\n",
        "    y_true = df[target_col].astype(int)\n",
        "    X = sm.add_constant(df[model.params.index.drop(\"const\")])\n",
        "    y_pred_prob = model.predict(X)\n",
        "    y_pred = (y_pred_prob >= cutoff).astype(int)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
        "    TP, FN, FP, TN = cm.ravel()\n",
        "\n",
        "    fraud_total = TP + FN\n",
        "    normal_total = FP + TN\n",
        "\n",
        "    fraud_correct = TP / fraud_total if fraud_total > 0 else 0\n",
        "    normal_correct = TN / normal_total if normal_total > 0 else 0\n",
        "    overall_correct = (TP + TN) / (fraud_total + normal_total)\n",
        "\n",
        "    table = pd.DataFrame({\n",
        "        \"Actual Group\": [\"Fraud (1)\", \"Normal (0)\", \"Total\"],\n",
        "        \"Predicted Fraud (1)\": [TP, FP, TP + FP],\n",
        "        \"Predicted Normal (0)\": [FN, TN, FN + TN],\n",
        "        \"Total\": [fraud_total, normal_total, fraud_total + normal_total],\n",
        "        \"% Correct\": [\n",
        "            round(fraud_correct * 100, 1),\n",
        "            round(normal_correct * 100, 1),\n",
        "            round(overall_correct * 100, 1),\n",
        "        ],\n",
        "    })\n",
        "    return table\n",
        "\n",
        "# Step 3. 產出訓練集和測試集的結果表\n",
        "train_table = classification_table(final_model, train_df, target_col=\"is_fraud\")\n",
        "test_table = classification_table(final_model, test_df, target_col=\"is_fraud\")\n",
        "\n",
        "print(\"\\n=== Classification Matrix — Training Sample ===\")\n",
        "print(train_table.to_string(index=False))\n",
        "print(\"\\n=== Classification Matrix — Holdout (Test) Sample ===\")\n",
        "print(test_table.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Stepwise completed with 4 variables: ['amount', 'zip', 'longitude', 'merchant_id']\n",
            "Train Accuracy: 0.9985, Test Accuracy: 0.9985\n",
            "=== Overall Model Fit ===\n",
            "                          Measure       Value Change_from_Base Change_pvalue\n",
            "0  -2 Log Likelihood (−2LL) value  129422.859        29687.753           0.0\n",
            "1                Cox and Snell R2       0.004                               \n",
            "2                   Nagelkerke R2       0.188                               \n",
            "3            Pseudo R2 (McFadden)       0.187                               \n",
            "4              Hosmer-Lemeshow χ2   29687.753                               \n",
            "\n",
            "=== Variables in the Equation ===\n",
            "  Independent Variable         B    Std. Error          Wald  df  \\\n",
            "0                const -7.811634  5.447445e-02  20563.548341   1   \n",
            "1               amount  0.002258  4.587596e-05   2423.164577   1   \n",
            "2                  zip -0.000091  1.088713e-06   7041.973083   1   \n",
            "3            longitude -0.024936  5.202238e-04   2297.553695   1   \n",
            "4          merchant_id  0.000011  3.543440e-07    959.021651   1   \n",
            "\n",
            "            Sig.    Exp(B)  \n",
            "0   0.000000e+00  0.000405  \n",
            "1   0.000000e+00  1.002261  \n",
            "2   0.000000e+00  0.999909  \n",
            "3   0.000000e+00  0.975373  \n",
            "4  1.451004e-210  1.000011  \n",
            "\n",
            "=== Variables Not in the Equation ===\n",
            "          Independent Variable  Score Statistic (LRT)  Significance\n",
            "0               transaction_id                  0.866        0.3522\n",
            "1                  client_id_x                 68.583        0.0000\n",
            "2                      card_id                 11.664        0.0006\n",
            "3                     mcc_code                 13.195        0.0003\n",
            "4          errors_missing_flag                217.195        0.0000\n",
            "5    use_chip_Chip Transaction                712.651        0.0000\n",
            "6   use_chip_Swipe Transaction               1053.093        0.0000\n",
            "7                  current_age                 61.879        0.0000\n",
            "8               retirement_age                 27.315        0.0000\n",
            "9                     latitude                166.212        0.0000\n",
            "10               yearly_income                739.286        0.0000\n",
            "11                  total_debt                213.273        0.0000\n",
            "12                credit_score                 79.717        0.0000\n",
            "13            num_credit_cards                229.339        0.0000\n",
            "14                 gender_Male                  0.000        0.9972\n",
            "15                         cvv                  1.242        0.2651\n",
            "16            num_cards_issued                  0.607        0.4358\n",
            "17                credit_limit                725.316        0.0000\n",
            "18            card_type_Credit                  3.059        0.0803\n",
            "19             card_type_Debit                 86.571        0.0000\n",
            "20             card_brand_Amex                  0.102        0.7498\n",
            "21       card_brand_Mastercard                  0.357        0.5505\n",
            "22             card_brand_Visa                  8.674        0.0032\n",
            "23                has_chip_YES                  1.845        0.1743\n",
            "\n",
            "================================================\n",
            "\n",
            "=== Accuracy in Training and Testing dataset ===\n",
            "\n",
            "=== Classification Matrix — Training Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                   12                 10579   10591        0.1\n",
            "  Normal (0)                   51               7121328 7121379      100.0\n",
            "       Total                   63               7131907 7131970       99.9\n",
            "\n",
            "=== Classification Matrix — Holdout (Test) Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                    3                  2738    2741        0.1\n",
            "  Normal (0)                   13               1780239 1780252      100.0\n",
            "       Total                   16               1782977 1782993       99.8\n"
          ]
        }
      ],
      "source": [
        "overall_fit, coef_df, not_in_eq_df, final_model = stepwise_logit_with_k_tables(\n",
        "    train_df, test_df, dep_var=\"is_fraud\", k=4\n",
        ")\n",
        "\n",
        "\n",
        "print(\"=== Overall Model Fit ===\")\n",
        "print(overall_fit)\n",
        "\n",
        "print(\"\\n=== Variables in the Equation ===\")\n",
        "print(coef_df)\n",
        "\n",
        "print(\"\\n=== Variables Not in the Equation ===\")\n",
        "print(not_in_eq_df)\n",
        "\n",
        "print(\"\\n================================================\")\n",
        "print(\"\\n=== Accuracy in Training and Testing dataset ===\")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def classification_table(model, df, target_col=\"is_fraud\", cutoff=0.5):\n",
        "    y_true = df[target_col].astype(int)\n",
        "    X = sm.add_constant(df[model.params.index.drop(\"const\")])\n",
        "    y_pred_prob = model.predict(X)\n",
        "    y_pred = (y_pred_prob >= cutoff).astype(int)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
        "    TP, FN, FP, TN = cm.ravel()\n",
        "\n",
        "    fraud_total = TP + FN\n",
        "    normal_total = FP + TN\n",
        "\n",
        "    fraud_correct = TP / fraud_total if fraud_total > 0 else 0\n",
        "    normal_correct = TN / normal_total if normal_total > 0 else 0\n",
        "    overall_correct = (TP + TN) / (fraud_total + normal_total)\n",
        "\n",
        "    table = pd.DataFrame({\n",
        "        \"Actual Group\": [\"Fraud (1)\", \"Normal (0)\", \"Total\"],\n",
        "        \"Predicted Fraud (1)\": [TP, FP, TP + FP],\n",
        "        \"Predicted Normal (0)\": [FN, TN, FN + TN],\n",
        "        \"Total\": [fraud_total, normal_total, fraud_total + normal_total],\n",
        "        \"% Correct\": [\n",
        "            round(fraud_correct * 100, 1),\n",
        "            round(normal_correct * 100, 1),\n",
        "            round(overall_correct * 100, 1),\n",
        "        ],\n",
        "    })\n",
        "    return table\n",
        "\n",
        "# Step 3. 產出訓練集和測試集的結果表\n",
        "train_table = classification_table(final_model, train_df, target_col=\"is_fraud\")\n",
        "test_table = classification_table(final_model, test_df, target_col=\"is_fraud\")\n",
        "\n",
        "print(\"\\n=== Classification Matrix — Training Sample ===\")\n",
        "print(train_table.to_string(index=False))\n",
        "print(\"\\n=== Classification Matrix — Holdout (Test) Sample ===\")\n",
        "print(test_table.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Stepwise completed with 23 variables: ['amount', 'zip', 'longitude', 'merchant_id', 'use_chip_Swipe Transaction', 'credit_limit', 'num_credit_cards', 'errors_missing_flag', 'use_chip_Chip Transaction', 'transaction_id', 'yearly_income', 'latitude', 'client_id_x', 'has_chip_YES', 'credit_score', 'retirement_age', 'card_type_Credit', 'card_type_Debit', 'mcc_code', 'card_brand_Visa', 'card_brand_Mastercard', 'card_brand_Amex', 'card_id']\n",
            "Train Accuracy: 0.9985, Test Accuracy: 0.9985\n",
            "=== Overall Model Fit ===\n",
            "                          Measure       Value Change_from_Base Change_pvalue\n",
            "0  -2 Log Likelihood (−2LL) value  126114.885        32995.727           0.0\n",
            "1                Cox and Snell R2       0.005                               \n",
            "2                   Nagelkerke R2       0.209                               \n",
            "3            Pseudo R2 (McFadden)       0.207                               \n",
            "4              Hosmer-Lemeshow χ2   32995.727                               \n",
            "\n",
            "=== Variables in the Equation ===\n",
            "          Independent Variable             B    Std. Error         Wald  df  \\\n",
            "0                        const -5.292035e+00  2.534512e-01   435.970008   1   \n",
            "1                       amount  2.619412e-03  4.970449e-05  2777.258399   1   \n",
            "2                          zip -9.419831e-05  1.373477e-06  4703.738293   1   \n",
            "3                    longitude -2.077493e-02  5.837857e-04  1266.403609   1   \n",
            "4                  merchant_id  1.067403e-05  3.716056e-07   825.072135   1   \n",
            "5   use_chip_Swipe Transaction -7.152812e-01  4.048087e-02   312.215235   1   \n",
            "6                 credit_limit -1.501740e-05  1.314672e-06   130.483201   1   \n",
            "7             num_credit_cards  9.361115e-02  6.316508e-03   219.634747   1   \n",
            "8          errors_missing_flag -7.901281e-01  4.841736e-02   266.313303   1   \n",
            "9    use_chip_Chip Transaction  8.149060e-01  3.404956e-02   572.785473   1   \n",
            "10              transaction_id -4.272704e-08  2.402336e-09   316.328158   1   \n",
            "11               yearly_income -7.409976e-06  5.832643e-07   161.399760   1   \n",
            "12                    latitude -2.335531e-02  1.954936e-03   142.727125   1   \n",
            "13                 client_id_x -1.123827e-04  1.703471e-05    43.524055   1   \n",
            "14                has_chip_YES -1.904791e-01  3.531443e-02    29.093100   1   \n",
            "15                credit_score  7.019687e-04  1.583567e-04    19.650009   1   \n",
            "16              retirement_age  1.319879e-02  2.910833e-03    20.560504   1   \n",
            "17            card_type_Credit -3.022556e-01  4.071155e-02    55.120543   1   \n",
            "18             card_type_Debit -2.331958e-01  4.067593e-02    32.867493   1   \n",
            "19                    mcc_code -3.544164e-05  1.157822e-05     9.370090   1   \n",
            "20             card_brand_Visa -3.294481e-01  5.637146e-02    34.155089   1   \n",
            "21       card_brand_Mastercard -2.931285e-01  5.702473e-02    26.423457   1   \n",
            "22             card_brand_Amex -3.024703e-01  6.384412e-02    22.445213   1   \n",
            "23                     card_id -1.309347e-05  5.842951e-06     5.021638   1   \n",
            "\n",
            "             Sig.    Exp(B)  \n",
            "0    8.157121e-97  0.005032  \n",
            "1    0.000000e+00  1.002623  \n",
            "2    0.000000e+00  0.999906  \n",
            "3   2.260800e-277  0.979439  \n",
            "4   1.909993e-181  1.000011  \n",
            "5    7.188794e-70  0.489055  \n",
            "6    3.212394e-30  0.999985  \n",
            "7    1.086563e-49  1.098133  \n",
            "8    7.218198e-60  0.453787  \n",
            "9   1.391246e-126  2.258963  \n",
            "10   9.135286e-71  1.000000  \n",
            "11   5.595331e-37  0.999993  \n",
            "12   6.743637e-33  0.976915  \n",
            "13   4.187797e-11  0.999888  \n",
            "14   6.898222e-08  0.826563  \n",
            "15   9.300289e-06  1.000702  \n",
            "16   5.777589e-06  1.013286  \n",
            "17   1.133599e-13  0.739149  \n",
            "18   9.865930e-09  0.791998  \n",
            "19   2.205546e-03  0.999965  \n",
            "20   5.088997e-09  0.719321  \n",
            "21   2.741904e-07  0.745926  \n",
            "22   2.162237e-06  0.738990  \n",
            "23   2.503248e-02  0.999987  \n",
            "\n",
            "=== Variables Not in the Equation ===\n",
            "  Independent Variable  Score Statistic (LRT)  Significance\n",
            "0          current_age                  0.474        0.4911\n",
            "1           total_debt                  0.841        0.3591\n",
            "2          gender_Male                  0.079        0.7780\n",
            "3                  cvv                  0.861        0.3535\n",
            "4     num_cards_issued                  0.707        0.4005\n",
            "\n",
            "================================================\n",
            "\n",
            "=== Accuracy in Training and Testing dataset ===\n",
            "\n",
            "=== Classification Matrix — Training Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                   20                 10571   10591        0.2\n",
            "  Normal (0)                   49               7121330 7121379      100.0\n",
            "       Total                   69               7131901 7131970       99.9\n",
            "\n",
            "=== Classification Matrix — Holdout (Test) Sample ===\n",
            "Actual Group  Predicted Fraud (1)  Predicted Normal (0)   Total  % Correct\n",
            "   Fraud (1)                    7                  2734    2741        0.3\n",
            "  Normal (0)                   14               1780238 1780252      100.0\n",
            "       Total                   21               1782972 1782993       99.8\n"
          ]
        }
      ],
      "source": [
        "overall_fit, coef_df, not_in_eq_df, final_model = stepwise_logit_with_k_tables(\n",
        "    train_df, test_df, dep_var=\"is_fraud\", k=314657018\n",
        ")\n",
        "\n",
        "\n",
        "print(\"=== Overall Model Fit ===\")\n",
        "print(overall_fit)\n",
        "\n",
        "print(\"\\n=== Variables in the Equation ===\")\n",
        "print(coef_df)\n",
        "\n",
        "print(\"\\n=== Variables Not in the Equation ===\")\n",
        "print(not_in_eq_df)\n",
        "\n",
        "print(\"\\n================================================\")\n",
        "print(\"\\n=== Accuracy in Training and Testing dataset ===\")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def classification_table(model, df, target_col=\"is_fraud\", cutoff=0.5):\n",
        "    y_true = df[target_col].astype(int)\n",
        "    X = sm.add_constant(df[model.params.index.drop(\"const\")])\n",
        "    y_pred_prob = model.predict(X)\n",
        "    y_pred = (y_pred_prob >= cutoff).astype(int)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
        "    TP, FN, FP, TN = cm.ravel()\n",
        "\n",
        "    fraud_total = TP + FN\n",
        "    normal_total = FP + TN\n",
        "\n",
        "    fraud_correct = TP / fraud_total if fraud_total > 0 else 0\n",
        "    normal_correct = TN / normal_total if normal_total > 0 else 0\n",
        "    overall_correct = (TP + TN) / (fraud_total + normal_total)\n",
        "\n",
        "    table = pd.DataFrame({\n",
        "        \"Actual Group\": [\"Fraud (1)\", \"Normal (0)\", \"Total\"],\n",
        "        \"Predicted Fraud (1)\": [TP, FP, TP + FP],\n",
        "        \"Predicted Normal (0)\": [FN, TN, FN + TN],\n",
        "        \"Total\": [fraud_total, normal_total, fraud_total + normal_total],\n",
        "        \"% Correct\": [\n",
        "            round(fraud_correct * 100, 1),\n",
        "            round(normal_correct * 100, 1),\n",
        "            round(overall_correct * 100, 1),\n",
        "        ],\n",
        "    })\n",
        "    return table\n",
        "\n",
        "# Step 3. 產出訓練集和測試集的結果表\n",
        "train_table = classification_table(final_model, train_df, target_col=\"is_fraud\")\n",
        "test_table = classification_table(final_model, test_df, target_col=\"is_fraud\")\n",
        "\n",
        "print(\"\\n=== Classification Matrix — Training Sample ===\")\n",
        "print(train_table.to_string(index=False))\n",
        "print(\"\\n=== Classification Matrix — Holdout (Test) Sample ===\")\n",
        "print(test_table.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Cutoff      TN      FP   FN   TP  Accuracy  Sensitivity  Specificity  Youden   PPV   NPV\n",
            "   0.00       0 1780252    0 2741       0.2        100.0          0.0     0.0   0.2    NC\n",
            "   0.10 1780039     213 2713   28      99.8          1.0        100.0     1.0  11.6  99.8\n",
            "   0.20 1780186      66 2727   14      99.8          0.5        100.0     0.5  17.5  99.8\n",
            "   0.30 1780223      29 2732    9      99.8          0.3        100.0     0.3  23.7  99.8\n",
            "   0.40 1780230      22 2733    8      99.8          0.3        100.0     0.3  26.7  99.8\n",
            "   0.42 1780230      22 2733    8      99.8          0.3        100.0     0.3  26.7  99.8\n",
            "   0.44 1780233      19 2733    8      99.8          0.3        100.0     0.3  29.6  99.8\n",
            "   0.46 1780236      16 2733    8      99.8          0.3        100.0     0.3  33.3  99.8\n",
            "   0.48 1780237      15 2733    8      99.8          0.3        100.0     0.3  34.8  99.8\n",
            "   0.50 1780238      14 2734    7      99.8          0.3        100.0     0.3  33.3  99.8\n",
            "   0.52 1780238      14 2734    7      99.8          0.3        100.0     0.3  33.3  99.8\n",
            "   0.54 1780238      14 2734    7      99.8          0.3        100.0     0.3  33.3  99.8\n",
            "   0.56 1780239      13 2734    7      99.8          0.3        100.0     0.3  35.0  99.8\n",
            "   0.58 1780239      13 2734    7      99.8          0.3        100.0     0.3  35.0  99.8\n",
            "   0.60 1780239      13 2735    6      99.8          0.2        100.0     0.2  31.6  99.8\n",
            "   0.70 1780241      11 2737    4      99.8          0.1        100.0     0.1  26.7  99.8\n",
            "   0.80 1780244       8 2739    2      99.8          0.1        100.0     0.1  20.0  99.8\n",
            "   0.90 1780246       6 2739    2      99.8          0.1        100.0     0.1  25.0  99.8\n",
            "   1.00 1780252       0 2741    0      99.8          0.0        100.0     0.0    NC  99.8\n"
          ]
        }
      ],
      "source": [
        "## 一些模型檢驗診斷\n",
        "def cutoff_analysis(model, df, target_col=\"is_fraud\", cutoffs=None):\n",
        "    \"\"\"\n",
        "    產出類似 Table 8.7 的結果\n",
        "    \"\"\"\n",
        "    if cutoffs is None:\n",
        "        cutoffs = np.arange(0, 1.01, 0.02)  # 預設 0, 0.02, ..., 1\n",
        "    \n",
        "    y_true = df[target_col].astype(int)\n",
        "    X = sm.add_constant(df[model.params.index.drop(\"const\")])\n",
        "    y_prob = model.predict(X)\n",
        "\n",
        "    rows = []\n",
        "    for cutoff in cutoffs:\n",
        "        y_pred = (y_prob >= cutoff).astype(int)\n",
        "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])  # 注意順序 [0,1]\n",
        "        TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "        total = TP + TN + FP + FN\n",
        "        accuracy = (TP + TN) / total if total > 0 else np.nan\n",
        "        sensitivity = TP / (TP + FN) if (TP + FN) > 0 else np.nan\n",
        "        specificity = TN / (TN + FP) if (TN + FP) > 0 else np.nan\n",
        "        youden = sensitivity + specificity - 1 if not np.isnan(sensitivity) and not np.isnan(specificity) else np.nan\n",
        "        ppv = TP / (TP + FP) if (TP + FP) > 0 else np.nan\n",
        "        npv = TN / (TN + FN) if (TN + FN) > 0 else np.nan\n",
        "\n",
        "        rows.append({\n",
        "            \"Cutoff\": cutoff,\n",
        "            \"TN\": TN, \"FP\": FP, \"FN\": FN, \"TP\": TP,\n",
        "            \"Accuracy\": round(accuracy*100, 1),\n",
        "            \"Sensitivity\": round(sensitivity*100, 1) if not np.isnan(sensitivity) else \"NC\",\n",
        "            \"Specificity\": round(specificity*100, 1) if not np.isnan(specificity) else \"NC\",\n",
        "            \"Youden\": round(youden*100, 1) if not np.isnan(youden) else \"NC\",\n",
        "            \"PPV\": round(ppv*100, 1) if not np.isnan(ppv) else \"NC\",\n",
        "            \"NPV\": round(npv*100, 1) if not np.isnan(npv) else \"NC\",\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "cutoff_table_all = cutoff_analysis(final_model, test_df, target_col=\"is_fraud\",\n",
        "                               cutoffs=[0,0.1,0.2,0.3,0.4,0.42,0.44,0.46,0.48,0.5,0.52,0.54,0.56,0.58,0.6,0.7,0.8,0.9,1])\n",
        "\n",
        "print(cutoff_table_all.to_string(index=False))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Cutoff      TN      FP   FN   TP  Accuracy  Sensitivity  Specificity  Youden   PPV    NPV\n",
            " 0.0000       0 1780252    0 2741       0.2        100.0          0.0     0.0   0.2     NC\n",
            " 0.0005 1203478  576774  216 2525      67.6         92.1         67.6    59.7   0.4  100.0\n",
            " 0.0010 1355117  425135  240 2501      76.1         91.2         76.1    67.4   0.6  100.0\n",
            " 0.0015 1427657  352595  273 2468      80.2         90.0         80.2    70.2   0.7  100.0\n",
            " 0.0020 1470930  309322  290 2451      82.6         89.4         82.6    72.0   0.8  100.0\n",
            " 0.0025 1503977  276275  346 2395      84.5         87.4         84.5    71.9   0.9  100.0\n",
            " 0.0030 1532171  248081  390 2351      86.1         85.8         86.1    71.8   0.9  100.0\n",
            " 0.0035 1557720  222532  446 2295      87.5         83.7         87.5    71.2   1.0  100.0\n",
            " 0.0040 1580618  199634  491 2250      88.8         82.1         88.8    70.9   1.1  100.0\n",
            " 0.0045 1601462  178790  540 2201      89.9         80.3         90.0    70.3   1.2  100.0\n",
            " 0.0050 1619913  160339  627 2114      91.0         77.1         91.0    68.1   1.3  100.0\n",
            " 0.0055 1636786  143466  694 2047      91.9         74.7         91.9    66.6   1.4  100.0\n",
            " 0.0060 1651852  128400  760 1981      92.8         72.3         92.8    65.1   1.5  100.0\n",
            " 0.0065 1665011  115241  842 1899      93.5         69.3         93.5    62.8   1.6   99.9\n",
            " 0.0070 1676622  103630  924 1817      94.1         66.3         94.2    60.5   1.7   99.9\n",
            " 0.0075 1686795   93457 1012 1729      94.7         63.1         94.8    57.8   1.8   99.9\n",
            " 0.0080 1696058   84194 1100 1641      95.2         59.9         95.3    55.1   1.9   99.9\n",
            " 0.0085 1704040   76212 1173 1568      95.7         57.2         95.7    52.9   2.0   99.9\n",
            " 0.0090 1711268   68984 1247 1494      96.1         54.5         96.1    50.6   2.1   99.9\n",
            " 0.0095 1717662   62590 1320 1421      96.4         51.8         96.5    48.3   2.2   99.9\n",
            " 0.0100 1723418   56834 1388 1353      96.7         49.4         96.8    46.2   2.3   99.9\n",
            " 0.0105 1728553   51699 1467 1274      97.0         46.5         97.1    43.6   2.4   99.9\n",
            " 0.0110 1733078   47174 1532 1209      97.3         44.1         97.4    41.5   2.5   99.9\n",
            " 0.0115 1736980   43272 1587 1154      97.5         42.1         97.6    39.7   2.6   99.9\n",
            " 0.0120 1740543   39709 1638 1103      97.7         40.2         97.8    38.0   2.7   99.9\n",
            " 0.0125 1743936   36316 1693 1048      97.9         38.2         98.0    36.2   2.8   99.9\n",
            " 0.0130 1747029   33223 1747  994      98.0         36.3         98.1    34.4   2.9   99.9\n",
            " 0.0135 1749639   30613 1785  956      98.2         34.9         98.3    33.2   3.0   99.9\n",
            " 0.0140 1752047   28205 1827  914      98.3         33.3         98.4    31.8   3.1   99.9\n",
            " 0.0145 1754168   26084 1872  869      98.4         31.7         98.5    30.2   3.2   99.9\n",
            " 0.0150 1756081   24171 1910  831      98.5         30.3         98.6    29.0   3.3   99.9\n",
            " 0.0155 1757857   22395 1953  788      98.6         28.7         98.7    27.5   3.4   99.9\n",
            " 0.0160 1759386   20866 1987  754      98.7         27.5         98.8    26.3   3.5   99.9\n",
            " 0.0165 1760767   19485 2016  725      98.8         26.5         98.9    25.4   3.6   99.9\n",
            " 0.0170 1762080   18172 2049  692      98.9         25.2         99.0    24.2   3.7   99.9\n",
            " 0.0175 1763262   16990 2086  655      98.9         23.9         99.0    22.9   3.7   99.9\n",
            " 0.0180 1764295   15957 2113  628      99.0         22.9         99.1    22.0   3.8   99.9\n",
            " 0.0185 1765318   14934 2134  607      99.0         22.1         99.2    21.3   3.9   99.9\n",
            " 0.0190 1766219   14033 2170  571      99.1         20.8         99.2    20.0   3.9   99.9\n",
            " 0.0195 1767065   13187 2189  552      99.1         20.1         99.3    19.4   4.0   99.9\n",
            " 0.0200 1767885   12367 2223  518      99.2         18.9         99.3    18.2   4.0   99.9\n",
            " 0.0205 1768618   11634 2242  499      99.2         18.2         99.3    17.6   4.1   99.9\n",
            " 0.0210 1769335   10917 2267  474      99.3         17.3         99.4    16.7   4.2   99.9\n",
            " 0.0215 1770024   10228 2291  450      99.3         16.4         99.4    15.8   4.2   99.9\n",
            " 0.0220 1770635    9617 2315  426      99.3         15.5         99.5    15.0   4.2   99.9\n",
            " 0.0225 1771179    9073 2345  396      99.4         14.4         99.5    13.9   4.2   99.9\n",
            " 0.0230 1771689    8563 2357  384      99.4         14.0         99.5    13.5   4.3   99.9\n",
            " 0.0235 1772146    8106 2372  369      99.4         13.5         99.5    13.0   4.4   99.9\n",
            " 0.0240 1772618    7634 2385  356      99.4         13.0         99.6    12.6   4.5   99.9\n",
            " 0.0245 1773046    7206 2399  342      99.5         12.5         99.6    12.1   4.5   99.9\n",
            " 0.0250 1773402    6850 2415  326      99.5         11.9         99.6    11.5   4.5   99.9\n",
            " 0.0255 1773726    6526 2430  311      99.5         11.3         99.6    11.0   4.5   99.9\n",
            " 0.0260 1774036    6216 2441  300      99.5         10.9         99.7    10.6   4.6   99.9\n",
            " 0.0265 1774323    5929 2450  291      99.5         10.6         99.7    10.3   4.7   99.9\n",
            " 0.0270 1774643    5609 2461  280      99.5         10.2         99.7     9.9   4.8   99.9\n",
            " 0.0275 1774901    5351 2466  275      99.6         10.0         99.7     9.7   4.9   99.9\n",
            " 0.0280 1775157    5095 2476  265      99.6          9.7         99.7     9.4   4.9   99.9\n",
            " 0.0285 1775382    4870 2487  254      99.6          9.3         99.7     9.0   5.0   99.9\n",
            " 0.0290 1775598    4654 2498  243      99.6          8.9         99.7     8.6   5.0   99.9\n",
            " 0.0295 1775801    4451 2505  236      99.6          8.6         99.7     8.4   5.0   99.9\n",
            " 0.0300 1776004    4248 2511  230      99.6          8.4         99.8     8.2   5.1   99.9\n",
            " 0.0305 1776170    4082 2515  226      99.6          8.2         99.8     8.0   5.2   99.9\n",
            " 0.0310 1776341    3911 2523  218      99.6          8.0         99.8     7.7   5.3   99.9\n",
            " 0.0315 1776512    3740 2536  205      99.6          7.5         99.8     7.3   5.2   99.9\n",
            " 0.0320 1776652    3600 2540  201      99.7          7.3         99.8     7.1   5.3   99.9\n",
            " 0.0325 1776807    3445 2544  197      99.7          7.2         99.8     7.0   5.4   99.9\n",
            " 0.0330 1776937    3315 2557  184      99.7          6.7         99.8     6.5   5.3   99.9\n",
            " 0.0335 1777064    3188 2563  178      99.7          6.5         99.8     6.3   5.3   99.9\n",
            " 0.0340 1777188    3064 2566  175      99.7          6.4         99.8     6.2   5.4   99.9\n",
            " 0.0345 1777291    2961 2573  168      99.7          6.1         99.8     6.0   5.4   99.9\n",
            " 0.0350 1777417    2835 2581  160      99.7          5.8         99.8     5.7   5.3   99.9\n",
            " 0.0355 1777535    2717 2583  158      99.7          5.8         99.8     5.6   5.5   99.9\n",
            " 0.0360 1777634    2618 2587  154      99.7          5.6         99.9     5.5   5.6   99.9\n",
            " 0.0365 1777752    2500 2589  152      99.7          5.5         99.9     5.4   5.7   99.9\n",
            " 0.0370 1777839    2413 2593  148      99.7          5.4         99.9     5.3   5.8   99.9\n",
            " 0.0375 1777927    2325 2594  147      99.7          5.4         99.9     5.2   5.9   99.9\n",
            " 0.0380 1778023    2229 2598  143      99.7          5.2         99.9     5.1   6.0   99.9\n",
            " 0.0385 1778115    2137 2602  139      99.7          5.1         99.9     5.0   6.1   99.9\n",
            " 0.0390 1778182    2070 2608  133      99.7          4.9         99.9     4.7   6.0   99.9\n",
            " 0.0395 1778258    1994 2612  129      99.7          4.7         99.9     4.6   6.1   99.9\n",
            " 0.0400 1778319    1933 2614  127      99.7          4.6         99.9     4.5   6.2   99.9\n",
            " 0.0405 1778379    1873 2618  123      99.7          4.5         99.9     4.4   6.2   99.9\n",
            " 0.0410 1778441    1811 2620  121      99.8          4.4         99.9     4.3   6.3   99.9\n",
            " 0.0415 1778509    1743 2625  116      99.8          4.2         99.9     4.1   6.2   99.9\n",
            " 0.0420 1778572    1680 2629  112      99.8          4.1         99.9     4.0   6.2   99.9\n",
            " 0.0425 1778618    1634 2633  108      99.8          3.9         99.9     3.8   6.2   99.9\n",
            " 0.0430 1778669    1583 2636  105      99.8          3.8         99.9     3.7   6.2   99.9\n",
            " 0.0435 1778731    1521 2637  104      99.8          3.8         99.9     3.7   6.4   99.9\n",
            " 0.0440 1778776    1476 2639  102      99.8          3.7         99.9     3.6   6.5   99.9\n",
            " 0.0445 1778818    1434 2641  100      99.8          3.6         99.9     3.6   6.5   99.9\n",
            " 0.0450 1778846    1406 2643   98      99.8          3.6         99.9     3.5   6.5   99.9\n",
            " 0.0455 1778891    1361 2645   96      99.8          3.5         99.9     3.4   6.6   99.9\n",
            " 0.0460 1778931    1321 2650   91      99.8          3.3         99.9     3.2   6.4   99.9\n",
            " 0.0465 1778970    1282 2653   88      99.8          3.2         99.9     3.1   6.4   99.9\n",
            " 0.0470 1779005    1247 2656   85      99.8          3.1         99.9     3.0   6.4   99.9\n",
            " 0.0475 1779032    1220 2656   85      99.8          3.1         99.9     3.0   6.5   99.9\n",
            " 0.0480 1779070    1182 2656   85      99.8          3.1         99.9     3.0   6.7   99.9\n",
            " 0.0485 1779098    1154 2658   83      99.8          3.0         99.9     3.0   6.7   99.9\n",
            " 0.0490 1779129    1123 2658   83      99.8          3.0         99.9     3.0   6.9   99.9\n",
            " 0.0495 1779161    1091 2660   81      99.8          3.0         99.9     2.9   6.9   99.9\n",
            " 0.0500 1779183    1069 2660   81      99.8          3.0         99.9     2.9   7.0   99.9\n",
            " 0.0505 1779209    1043 2662   79      99.8          2.9         99.9     2.8   7.0   99.9\n",
            " 0.0510 1779229    1023 2664   77      99.8          2.8         99.9     2.8   7.0   99.9\n",
            " 0.0515 1779254     998 2664   77      99.8          2.8         99.9     2.8   7.2   99.9\n",
            " 0.0520 1779288     964 2664   77      99.8          2.8         99.9     2.8   7.4   99.9\n",
            " 0.0525 1779315     937 2664   77      99.8          2.8         99.9     2.8   7.6   99.9\n",
            " 0.0530 1779334     918 2665   76      99.8          2.8         99.9     2.7   7.6   99.9\n",
            " 0.0535 1779361     891 2668   73      99.8          2.7         99.9     2.6   7.6   99.9\n",
            " 0.0540 1779381     871 2670   71      99.8          2.6        100.0     2.5   7.5   99.9\n",
            " 0.0545 1779397     855 2671   70      99.8          2.6        100.0     2.5   7.6   99.9\n",
            " 0.0550 1779409     843 2674   67      99.8          2.4        100.0     2.4   7.4   99.8\n",
            " 0.0555 1779424     828 2674   67      99.8          2.4        100.0     2.4   7.5   99.8\n",
            " 0.0560 1779437     815 2674   67      99.8          2.4        100.0     2.4   7.6   99.8\n",
            " 0.0565 1779449     803 2674   67      99.8          2.4        100.0     2.4   7.7   99.8\n",
            " 0.0570 1779464     788 2675   66      99.8          2.4        100.0     2.4   7.7   99.8\n",
            " 0.0575 1779490     762 2676   65      99.8          2.4        100.0     2.3   7.9   99.8\n",
            " 0.0580 1779514     738 2678   63      99.8          2.3        100.0     2.3   7.9   99.8\n",
            " 0.0585 1779529     723 2679   62      99.8          2.3        100.0     2.2   7.9   99.8\n",
            " 0.0590 1779546     706 2681   60      99.8          2.2        100.0     2.1   7.8   99.8\n",
            " 0.0595 1779553     699 2682   59      99.8          2.2        100.0     2.1   7.8   99.8\n",
            " 0.0600 1779571     681 2684   57      99.8          2.1        100.0     2.0   7.7   99.8\n",
            " 0.0605 1779584     668 2684   57      99.8          2.1        100.0     2.0   7.9   99.8\n",
            " 0.0610 1779601     651 2684   57      99.8          2.1        100.0     2.0   8.1   99.8\n",
            " 0.0615 1779613     639 2684   57      99.8          2.1        100.0     2.0   8.2   99.8\n",
            " 0.0620 1779622     630 2684   57      99.8          2.1        100.0     2.0   8.3   99.8\n",
            " 0.0625 1779630     622 2685   56      99.8          2.0        100.0     2.0   8.3   99.8\n",
            " 0.0630 1779638     614 2685   56      99.8          2.0        100.0     2.0   8.4   99.8\n",
            " 0.0635 1779651     601 2685   56      99.8          2.0        100.0     2.0   8.5   99.8\n",
            " 0.0640 1779657     595 2686   55      99.8          2.0        100.0     2.0   8.5   99.8\n",
            " 0.0645 1779666     586 2687   54      99.8          2.0        100.0     1.9   8.4   99.8\n",
            " 0.0650 1779681     571 2689   52      99.8          1.9        100.0     1.9   8.3   99.8\n",
            " 0.0655 1779693     559 2691   50      99.8          1.8        100.0     1.8   8.2   99.8\n",
            " 0.0660 1779702     550 2691   50      99.8          1.8        100.0     1.8   8.3   99.8\n",
            " 0.0665 1779714     538 2692   49      99.8          1.8        100.0     1.8   8.3   99.8\n",
            " 0.0670 1779721     531 2693   48      99.8          1.8        100.0     1.7   8.3   99.8\n",
            " 0.0675 1779732     520 2693   48      99.8          1.8        100.0     1.7   8.5   99.8\n",
            " 0.0680 1779744     508 2694   47      99.8          1.7        100.0     1.7   8.5   99.8\n",
            " 0.0685 1779751     501 2694   47      99.8          1.7        100.0     1.7   8.6   99.8\n",
            " 0.0690 1779760     492 2694   47      99.8          1.7        100.0     1.7   8.7   99.8\n",
            " 0.0695 1779767     485 2696   45      99.8          1.6        100.0     1.6   8.5   99.8\n",
            " 0.0700 1779774     478 2696   45      99.8          1.6        100.0     1.6   8.6   99.8\n",
            " 0.0705 1779785     467 2696   45      99.8          1.6        100.0     1.6   8.8   99.8\n",
            " 0.0710 1779795     457 2698   43      99.8          1.6        100.0     1.5   8.6   99.8\n",
            " 0.0715 1779804     448 2698   43      99.8          1.6        100.0     1.5   8.8   99.8\n",
            " 0.0720 1779815     437 2698   43      99.8          1.6        100.0     1.5   9.0   99.8\n",
            " 0.0725 1779821     431 2698   43      99.8          1.6        100.0     1.5   9.1   99.8\n",
            " 0.0730 1779826     426 2698   43      99.8          1.6        100.0     1.5   9.2   99.8\n",
            " 0.0735 1779832     420 2699   42      99.8          1.5        100.0     1.5   9.1   99.8\n",
            " 0.0740 1779836     416 2699   42      99.8          1.5        100.0     1.5   9.2   99.8\n",
            " 0.0745 1779842     410 2699   42      99.8          1.5        100.0     1.5   9.3   99.8\n",
            " 0.0750 1779849     403 2701   40      99.8          1.5        100.0     1.4   9.0   99.8\n",
            " 0.0755 1779852     400 2701   40      99.8          1.5        100.0     1.4   9.1   99.8\n",
            " 0.0760 1779862     390 2702   39      99.8          1.4        100.0     1.4   9.1   99.8\n",
            " 0.0765 1779870     382 2703   38      99.8          1.4        100.0     1.4   9.0   99.8\n",
            " 0.0770 1779874     378 2704   37      99.8          1.3        100.0     1.3   8.9   99.8\n",
            " 0.0775 1779877     375 2704   37      99.8          1.3        100.0     1.3   9.0   99.8\n",
            " 0.0780 1779879     373 2704   37      99.8          1.3        100.0     1.3   9.0   99.8\n",
            " 0.0785 1779884     368 2704   37      99.8          1.3        100.0     1.3   9.1   99.8\n",
            " 0.0790 1779888     364 2704   37      99.8          1.3        100.0     1.3   9.2   99.8\n",
            " 0.0795 1779893     359 2704   37      99.8          1.3        100.0     1.3   9.3   99.8\n",
            " 0.0800 1779899     353 2704   37      99.8          1.3        100.0     1.3   9.5   99.8\n",
            " 0.0805 1779905     347 2704   37      99.8          1.3        100.0     1.3   9.6   99.8\n",
            " 0.0810 1779914     338 2704   37      99.8          1.3        100.0     1.3   9.9   99.8\n",
            " 0.0815 1779920     332 2705   36      99.8          1.3        100.0     1.3   9.8   99.8\n",
            " 0.0820 1779925     327 2705   36      99.8          1.3        100.0     1.3   9.9   99.8\n",
            " 0.0825 1779934     318 2705   36      99.8          1.3        100.0     1.3  10.2   99.8\n",
            " 0.0830 1779939     313 2705   36      99.8          1.3        100.0     1.3  10.3   99.8\n",
            " 0.0835 1779944     308 2707   34      99.8          1.2        100.0     1.2   9.9   99.8\n",
            " 0.0840 1779950     302 2707   34      99.8          1.2        100.0     1.2  10.1   99.8\n",
            " 0.0845 1779958     294 2707   34      99.8          1.2        100.0     1.2  10.4   99.8\n",
            " 0.0850 1779961     291 2707   34      99.8          1.2        100.0     1.2  10.5   99.8\n",
            " 0.0855 1779961     291 2707   34      99.8          1.2        100.0     1.2  10.5   99.8\n",
            " 0.0860 1779967     285 2707   34      99.8          1.2        100.0     1.2  10.7   99.8\n",
            " 0.0865 1779970     282 2708   33      99.8          1.2        100.0     1.2  10.5   99.8\n",
            " 0.0870 1779974     278 2708   33      99.8          1.2        100.0     1.2  10.6   99.8\n",
            " 0.0875 1779979     273 2708   33      99.8          1.2        100.0     1.2  10.8   99.8\n",
            " 0.0880 1779983     269 2709   32      99.8          1.2        100.0     1.2  10.6   99.8\n",
            " 0.0885 1779986     266 2709   32      99.8          1.2        100.0     1.2  10.7   99.8\n",
            " 0.0890 1779990     262 2709   32      99.8          1.2        100.0     1.2  10.9   99.8\n",
            " 0.0895 1779990     262 2709   32      99.8          1.2        100.0     1.2  10.9   99.8\n",
            " 0.0900 1779993     259 2710   31      99.8          1.1        100.0     1.1  10.7   99.8\n",
            " 0.0905 1779995     257 2710   31      99.8          1.1        100.0     1.1  10.8   99.8\n",
            " 0.0910 1779996     256 2711   30      99.8          1.1        100.0     1.1  10.5   99.8\n",
            " 0.0915 1779999     253 2711   30      99.8          1.1        100.0     1.1  10.6   99.8\n",
            " 0.0920 1780003     249 2711   30      99.8          1.1        100.0     1.1  10.8   99.8\n",
            " 0.0925 1780004     248 2711   30      99.8          1.1        100.0     1.1  10.8   99.8\n",
            " 0.0930 1780006     246 2711   30      99.8          1.1        100.0     1.1  10.9   99.8\n",
            " 0.0935 1780008     244 2712   29      99.8          1.1        100.0     1.0  10.6   99.8\n",
            " 0.0940 1780009     243 2712   29      99.8          1.1        100.0     1.0  10.7   99.8\n",
            " 0.0945 1780009     243 2712   29      99.8          1.1        100.0     1.0  10.7   99.8\n",
            " 0.0950 1780014     238 2712   29      99.8          1.1        100.0     1.0  10.9   99.8\n",
            " 0.0955 1780017     235 2712   29      99.8          1.1        100.0     1.0  11.0   99.8\n",
            " 0.0960 1780020     232 2712   29      99.8          1.1        100.0     1.0  11.1   99.8\n",
            " 0.0965 1780023     229 2713   28      99.8          1.0        100.0     1.0  10.9   99.8\n",
            " 0.0970 1780025     227 2713   28      99.8          1.0        100.0     1.0  11.0   99.8\n",
            " 0.0975 1780026     226 2713   28      99.8          1.0        100.0     1.0  11.0   99.8\n",
            " 0.0980 1780028     224 2713   28      99.8          1.0        100.0     1.0  11.1   99.8\n",
            " 0.0985 1780031     221 2713   28      99.8          1.0        100.0     1.0  11.2   99.8\n",
            " 0.0990 1780034     218 2713   28      99.8          1.0        100.0     1.0  11.4   99.8\n",
            " 0.0995 1780035     217 2713   28      99.8          1.0        100.0     1.0  11.4   99.8\n",
            " 0.1000 1780039     213 2713   28      99.8          1.0        100.0     1.0  11.6   99.8\n",
            " 0.1005 1780043     209 2713   28      99.8          1.0        100.0     1.0  11.8   99.8\n",
            " 0.1010 1780043     209 2714   27      99.8          1.0        100.0     1.0  11.4   99.8\n",
            " 0.1015 1780045     207 2714   27      99.8          1.0        100.0     1.0  11.5   99.8\n",
            " 0.1020 1780047     205 2715   26      99.8          0.9        100.0     0.9  11.3   99.8\n",
            " 0.1025 1780050     202 2715   26      99.8          0.9        100.0     0.9  11.4   99.8\n",
            " 0.1030 1780053     199 2715   26      99.8          0.9        100.0     0.9  11.6   99.8\n",
            " 0.1035 1780054     198 2715   26      99.8          0.9        100.0     0.9  11.6   99.8\n",
            " 0.1040 1780058     194 2715   26      99.8          0.9        100.0     0.9  11.8   99.8\n",
            " 0.1045 1780062     190 2715   26      99.8          0.9        100.0     0.9  12.0   99.8\n",
            " 0.1050 1780065     187 2715   26      99.8          0.9        100.0     0.9  12.2   99.8\n",
            " 0.1055 1780067     185 2715   26      99.8          0.9        100.0     0.9  12.3   99.8\n",
            " 0.1060 1780067     185 2715   26      99.8          0.9        100.0     0.9  12.3   99.8\n",
            " 0.1065 1780068     184 2715   26      99.8          0.9        100.0     0.9  12.4   99.8\n",
            " 0.1070 1780069     183 2715   26      99.8          0.9        100.0     0.9  12.4   99.8\n",
            " 0.1075 1780073     179 2715   26      99.8          0.9        100.0     0.9  12.7   99.8\n",
            " 0.1080 1780076     176 2715   26      99.8          0.9        100.0     0.9  12.9   99.8\n",
            " 0.1085 1780076     176 2715   26      99.8          0.9        100.0     0.9  12.9   99.8\n",
            " 0.1090 1780077     175 2715   26      99.8          0.9        100.0     0.9  12.9   99.8\n",
            " 0.1095 1780078     174 2715   26      99.8          0.9        100.0     0.9  13.0   99.8\n",
            " 0.2000 1780186      66 2727   14      99.8          0.5        100.0     0.5  17.5   99.8\n",
            " 0.3000 1780223      29 2732    9      99.8          0.3        100.0     0.3  23.7   99.8\n",
            " 0.4000 1780230      22 2733    8      99.8          0.3        100.0     0.3  26.7   99.8\n",
            " 0.5000 1780238      14 2734    7      99.8          0.3        100.0     0.3  33.3   99.8\n",
            " 0.6000 1780239      13 2735    6      99.8          0.2        100.0     0.2  31.6   99.8\n",
            " 0.7000 1780241      11 2737    4      99.8          0.1        100.0     0.1  26.7   99.8\n",
            " 0.8000 1780244       8 2739    2      99.8          0.1        100.0     0.1  20.0   99.8\n",
            " 0.9000 1780246       6 2739    2      99.8          0.1        100.0     0.1  25.0   99.8\n",
            " 1.0000 1780252       0 2741    0      99.8          0.0        100.0     0.0    NC   99.8\n"
          ]
        }
      ],
      "source": [
        "cutoffs_v1 = [round(x, 4) for x in np.arange(0, 0.11, 0.0005)]  # 0 ~ 0.2 間隔 0.02\n",
        "cutoffs_v1 += [round(x, 4) for x in np.arange(0.2, 1.01, 0.1)]  # 0.3 ~ 1 間隔 0.1\n",
        "\n",
        "cutoff_table_zoom = cutoff_analysis(final_model, test_df, target_col=\"is_fraud\", cutoffs=cutoffs_v1)\n",
        "print(cutoff_table_zoom.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cutoff_table_zoom.to_csv(\"cutoff_table_zoom(test).csv\", index=False)\n",
        "\n",
        "overall_fit, coef_df, not_in_eq_df, final_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'LogitResults' object has no attribute 'to_csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m names = [\u001b[33m\"\u001b[39m\u001b[33moverall_fit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcoef_df\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnot_in_eq_df\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfinal_model\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m df, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(dfs, names):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/statsmodels/base/wrapper.py:34\u001b[39m, in \u001b[36mResultsWrapper.__getattribute__\u001b[39m\u001b[34m(self, attr)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m obj = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m data = results.model.data\n\u001b[32m     36\u001b[39m how = \u001b[38;5;28mself\u001b[39m._wrap_attrs.get(attr)\n",
            "\u001b[31mAttributeError\u001b[39m: 'LogitResults' object has no attribute 'to_csv'"
          ]
        }
      ],
      "source": [
        "dfs = [overall_fit, coef_df, not_in_eq_df, final_model]\n",
        "names = [\"overall_fit\", \"coef_df\", \"not_in_eq_df\", \"final_model\"]\n",
        "\n",
        "for df, name in zip(dfs, names):\n",
        "    df.to_csv(f\"{name}.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "virtual",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
