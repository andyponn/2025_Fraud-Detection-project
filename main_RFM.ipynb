{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-1_import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#https://drive.google.com/drive/folders/18qV82fNY3IIWu3BRoGqm_LNgJzE8Akbr?usp=drive_link\n",
    "#base_dir = \"/Users/Andypon/10_äº¤å¤§ç ”ç©¶æ‰€/1141_01_æ©Ÿå™¨å­¸ç¿’èˆ‡é‡‘èç§‘æŠ€/data\"\n",
    "base_dir= '/Users/andyw.p.chen/Documents/Project/datasets'\n",
    "#base_dir=  \"c:\\Users\\user\\Downloads\\datasets\"\n",
    "\n",
    "def load_json_to_df(filename: str) -> pd.DataFrame:\n",
    "    file_path = os.path.join(base_dir, filename)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # å¦‚æœæ˜¯ { \"target\": {id: value, ...} }\n",
    "    if isinstance(data, dict) and len(data) == 1 and isinstance(next(iter(data.values())), dict):\n",
    "        key, inner = next(iter(data.items()))\n",
    "        return pd.DataFrame(list(inner.items()), columns=[\"id\", key])\n",
    "\n",
    "    # dict of scalar\n",
    "    if isinstance(data, dict):\n",
    "        return pd.DataFrame([{\"code\": k, \"desc\": v} for k, v in data.items()])\n",
    "\n",
    "    # list of dict\n",
    "    elif isinstance(data, list):\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported JSON structure in {filename}: {type(data)}\")\n",
    "\n",
    "\n",
    "def load_csv_to_df(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"è®€å– CSV ä¸¦è½‰ç‚º DataFrameã€‚\"\"\"\n",
    "    return pd.read_csv(os.path.join(base_dir, filename))\n",
    "\n",
    "# JSON è³‡æ–™\n",
    "##mcc_codes_df = load_json_to_df(\"mcc_codes.json\")\n",
    "train_fraud_labels_df = load_json_to_df(\"train_fraud_labels.json\")\n",
    "\n",
    "# CSV è³‡æ–™\n",
    "cards_df = load_csv_to_df(\"cards_data.csv\")\n",
    "transactions_df = load_csv_to_df(\"transactions_data.csv\")\n",
    "users_df = load_csv_to_df(\"users_data.csv\")\n",
    "\n",
    "# ç°¡å–®æª¢æŸ¥\n",
    "#print(mcc_codes_df.head())\n",
    "#print(train_fraud_labels_df.head())\n",
    "#print(cards_df.head())\n",
    "#print(transactions_df.head())\n",
    "#print(users_df.apthead())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-2_rename variable in each data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraud_labels_df = train_fraud_labels_df.rename(columns={'id': 'transactions_id'})\n",
    "train_fraud_labels_df = train_fraud_labels_df.rename(columns={'target': 'is_fraud'})\n",
    "\n",
    "cards_df = cards_df.rename(columns={'id':'card_id'})\n",
    "\n",
    "users_df = users_df.rename(columns={'id':'client_id'})\n",
    "\n",
    "transactions_df = transactions_df.rename(columns={'mcc': 'mcc_code'})\n",
    "transactions_df = transactions_df.rename(columns={'id': 'transaction_id'})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-3_è®Šæ•¸å‹æ…‹çµ±ä¸€åŠç¼ºå¤±å€¼è™•ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_flags(df: pd.DataFrame, cols: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    åœ¨ DataFrame ä¸­å°æŒ‡å®šæ¬„ä½å»ºç«‹ missing flag æ¬„ä½\n",
    "    flag=1 è¡¨ç¤ºç¼ºå¤±å€¼ï¼Œflag=0 è¡¨ç¤ºéç¼ºå¤±å€¼\n",
    "    \n",
    "    åƒæ•¸\n",
    "    ----\n",
    "    df : pd.DataFrame\n",
    "        è¼¸å…¥çš„è³‡æ–™æ¡†\n",
    "    cols : list\n",
    "        è¦æª¢æŸ¥çš„æ¬„ä½åç¨±æ¸…å–®\n",
    "    \n",
    "    å›å‚³\n",
    "    ----\n",
    "    pd.DataFrame : æ–°çš„è³‡æ–™æ¡† (å«æ–°å¢çš„ flag æ¬„ä½)\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        df[f\"{col}_missing_flag\"] = df[col].isna().astype(int)\n",
    "    return df\n",
    "\n",
    "transactions_df = add_missing_flags(transactions_df, [\"merchant_state\", \"zip\", \"errors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train_fraud_labels_df##\n",
    "train_fraud_labels_df[\"is_fraud\"]=train_fraud_labels_df[\"is_fraud\"].astype(\"category\") \n",
    "train_fraud_labels_df[\"transactions_id\"]=train_fraud_labels_df[\"transactions_id\"].astype(int) #åˆä½µè³‡æ–™éœ€è¦\n",
    "\n",
    "##cards_df##\n",
    "cards_df[\"card_brand\"]=cards_df[\"card_brand\"].astype(\"category\") \n",
    "cards_df[\"card_type\"]=cards_df[\"card_type\"].astype(\"category\")\n",
    "#####ä¸è¦loadé€™è¡Œ cards_df[\"expires\"]=pd.to_datetime(cards_df[\"expires\"], format=\"%m/%Y\")\n",
    "cards_df[\"expires\"] = pd.to_datetime(cards_df[\"expires\"], format=\"%m/%Y\").dt.to_period(\"M\")\n",
    "cards_df[\"has_chip\"]=cards_df[\"has_chip\"].astype(\"category\")\n",
    "\n",
    "cards_df['credit_limit'] = cards_df['credit_limit'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
    "#####ä¸è¦loadé€™è¡Œ cards_df[\"acct_open_date\"]=pd.to_datetime(cards_df[\"acct_open_date\"], format=\"%m/%Y\")\n",
    "cards_df[\"acct_open_date\"] = pd.to_datetime(cards_df[\"acct_open_date\"], format=\"%m/%Y\").dt.to_period(\"M\")\n",
    "#####ä¸è¦loadé€™è¡Œ cards_df[\"year_pin_last_changed\"]=pd.to_datetime(cards_df[\"year_pin_last_changed\"], format=\"%Y\")\n",
    "cards_df[\"year_pin_last_changed\"] = pd.to_datetime(cards_df[\"year_pin_last_changed\"], format=\"%Y\").dt.to_period(\"Y\")\n",
    "cards_df[\"card_on_dark_web\"]=cards_df[\"card_on_dark_web\"].astype(\"category\") \n",
    "\n",
    "##users_df##\n",
    "users_df[\"birth_year\"] = pd.to_datetime(users_df[\"birth_year\"], format=\"%Y\").dt.to_period(\"Y\")\n",
    "users_df[\"birth_month\"] = pd.to_datetime(users_df[\"birth_month\"], format=\"%m\").dt.to_period(\"M\")\n",
    "users_df[\"gender\"]=users_df[\"gender\"].astype(\"category\") \n",
    "users_df['per_capita_income'] = users_df['per_capita_income'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
    "users_df['yearly_income'] = users_df['yearly_income'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
    "users_df['total_debt'] = users_df['total_debt'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
    "\n",
    "##transactions_df##\n",
    "transactions_df[\"date\"] = pd.to_datetime(transactions_df[\"date\"])\n",
    "#æµ®é»æ•¸è½‰æ•´æ•¸åŸå› ç¢ºå®šï¼Ÿ\n",
    "transactions_df['amount'] = transactions_df['amount'].replace(r'[\\$,]', '', regex=True).astype(float).astype(int)\n",
    "##è² æ•¸å–logèª¿æˆ1\n",
    "#transactions_df['amount'] = transactions_df['amount'].replace(r'[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "transactions_df[\"use_chip\"]=transactions_df[\"use_chip\"].astype(\"category\") \n",
    "\n",
    "transactions_df.loc[\n",
    "    transactions_df['merchant_city'].str.lower() == 'online',\n",
    "    'merchant_state'\n",
    "] = 'online'\n",
    "\n",
    "transactions_df.loc[\n",
    "    transactions_df['merchant_city'].str.lower() == 'online',\n",
    "    'zip'\n",
    "] = 20000 #åŸæœ¬æ˜¯-1\n",
    "## æˆ‘æ²’æœ‰å…¨éƒ¨æ”¹ï¼Œé€™æ¨£å®Œä¹‹å¾Œä»æœ‰89006ç­†Missingï¼Œå‰©ä¸‹éƒ½æ˜¯åœ¨åœ‹å¤–\n",
    "transactions_df['zip'] = transactions_df['zip'].fillna(10000) #åŸæœ¬æ˜¯-999\n",
    "transactions_df[\"zip\"]=transactions_df[\"zip\"].astype(\"int64\")\n",
    "\n",
    "transactions_df['errors'] = transactions_df['errors'].astype('category')\n",
    "transactions_df['errors'] = transactions_df['errors'].cat.add_categories('No_error').fillna('No_error')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cars one hot encoding\n",
    "##çµ±ä¸€é¡åˆ¥è®Šæ•¸è½‰dummy variable(è¦æ³¨æ„å…±ç·šæ€§å•é¡Œï¼Œæ‡‰åˆªæ‰å…¶ä¸­ä¹‹ä¸€)\n",
    "\n",
    "#card_type åŸå§‹ç¨®é¡ï¼šDebit_57%, Credit_33%, Debit(Prepaid)_9%\n",
    "#card_brand åŸå§‹ç¨®é¡ï¼šMasterCard_52%, Visa_38%, Amex_7%, Discovery_3%\n",
    "#has_chip åŸå§‹ç¨®é¡ï¼šYes_89%, No_11%\n",
    "#card_on_dark_web åŸå§‹ç¨®é¡ï¼šNo_0%\n",
    "cols_to_encode = ['card_type', 'card_brand', 'has_chip']\n",
    "cards_df[cols_to_encode] = cards_df[cols_to_encode].astype('category')\n",
    "dummies_cards = pd.get_dummies(\n",
    "    cards_df[cols_to_encode], \n",
    "    prefix=cols_to_encode, \n",
    "    dtype='uint8'\n",
    "    )\n",
    "cards_df = pd.concat([cards_df, dummies_cards], axis=1)\n",
    "\n",
    "#use_chip åŸå§‹ç¨®é¡ï¼šSwiped_52%, Chipe_36%, Online_12%\n",
    "dummies_use = pd.get_dummies(transactions_df['use_chip'], prefix='use_chip', dtype='uint8')\n",
    "transactions_df = pd.concat([transactions_df, dummies_use], axis=1)\n",
    "\n",
    "#gender åŸå§‹ç¨®é¡ï¼šFemale_51%, Male_49%\n",
    "dummies_gender = pd.get_dummies(users_df['gender'], prefix='gender', dtype='uint8')\n",
    "users_df = pd.concat([users_df, dummies_gender], axis=1)\n",
    "\n",
    "\n",
    "cards_df.drop(columns=[\"has_chip_NO\",\"has_chip\"], inplace=True)\n",
    "transactions_df.drop(columns=[\"use_chip\"], inplace=True)\n",
    "users_df.drop(columns=[\"gender_Female\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_è³‡æ–™æ•´ä½µæˆä¸€å¼µdataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02-1_è³‡æ–™æ•´ä½µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transactions_df.loc[transactions_df[\"transaction_id\"] == 10649266] #transaction_id vs id\n",
    "\n",
    "#åŸå§‹è³‡æ–™ç­†æ•¸ï¼š13305915\n",
    "### transactions_df+train_fraud_labels_df      left æœƒæœ‰4390952 missing values\n",
    "merged = pd.merge(transactions_df, train_fraud_labels_df, left_on=\"transaction_id\", right_on=\"transactions_id\", how=\"outer\")\n",
    "### transactions_df train_fraud_labels_df(8914963) + users_df å°éå»ä¸æœƒæœ‰missing values\n",
    "merged = pd.merge(merged,users_df , left_on=\"client_id\", right_on=\"client_id\", how=\"left\")\n",
    "### transactions_df train_fraud_labels_df users_df + cards_df å°éå»ä¸æœƒæœ‰missing values\n",
    "merged = pd.merge(merged,cards_df , left_on=\"card_id\", right_on=\"card_id\", how=\"left\")\n",
    "\n",
    "#åˆªæ‰é‡è¤‡çš„columns\n",
    "merged.drop(columns=[\"transactions_id\"], inplace=True)\n",
    "merged.drop(columns=[\"client_id_y\"], inplace=True)\n",
    "\n",
    "## åˆä½µå®Œä¹‹å¾Œæœ€å¾Œè™•ç†is_fraud(åŸæœƒæœ‰missing valueså•é¡Œ)\n",
    "merged[\"is_fraud\"] = merged[\"is_fraud\"].astype(str)\n",
    "merged.loc[merged['is_fraud'].str.lower() == 'no','is_fraud'] = '0'\n",
    "merged.loc[merged['is_fraud'].str.lower() == 'yes','is_fraud'] = '1'\n",
    "merged[\"is_fraud\"] = pd.to_numeric(merged[\"is_fraud\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "merged = add_missing_flags(merged, [\"is_fraud\"])\n",
    "\n",
    "#merged.to_csv(\"merged.csv\", index=False)\n",
    "\n",
    "# å…ˆåˆªé™¤ä¸éœ€è¦çš„DataFrameä»¥ç¯€çœè¨˜æ†¶é«”\n",
    "del transactions_df, users_df, cards_df, train_fraud_labels_df, cols_to_encode, dummies_cards, dummies_use, dummies_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_merged = merged.copy()\n",
    "#merged = backup_merged.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04_RFM features engineering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04-1_è³‡æ–™é€²è¡Œè®Šæ•¸è½‰æ›ä»¥æ±‚æ¨¡å‹é…é£¾æ›´ä½³è¡¨ç¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##æœ‰å‡ºäº‹å†è¶•å¿«å›å¾©åŸç‹€\n",
    "mask = (merged[\"date\"] >= \"2018-01-01 00:00:00\") & (merged[\"date\"] <= \"2020-12-31 23:59:59\")\n",
    "merged = merged[mask]\n",
    "#merged = backup_merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ç¢ºä¿æ—¥æœŸæ˜¯ datetime ä¸¦æ’åº\n",
    "merged['date'] = pd.to_datetime(merged['date'])\n",
    "merged = merged.sort_values(by=['client_id_x', 'date']).reset_index(drop=True)\n",
    "\n",
    "# --- RecencyInterval ---\n",
    "merged['RecencyInterval'] = merged.groupby('client_id_x')['date'].diff().dt.total_seconds().fillna(0)/60\n",
    "\n",
    "# --- TxnFrequency for multiple windows (å‘é‡åŒ–æ»‘å‹•çª—å£) ---\n",
    "window_days = [7, 30, 60, 90]\n",
    "for w in window_days:\n",
    "    merged[f'TxnFrequency_{w}d'] = 0\n",
    "\n",
    "def compute_freq_vectorized(dates, windows):\n",
    "    \"\"\"å‘é‡åŒ–è¨ˆç®—æ¯ç­†äº¤æ˜“åœ¨æ¯å€‹ window å…§çš„äº¤æ˜“æ•¸\"\"\"\n",
    "    n = len(dates)\n",
    "    dates_int = dates.values.astype('datetime64[D]').astype(int)\n",
    "    res = {w: np.zeros(n, dtype=int) for w in windows}\n",
    "    for w in windows:\n",
    "        left = 0\n",
    "        counts = np.zeros(n, dtype=int)\n",
    "        for right in range(n):\n",
    "            while dates_int[right] - dates_int[left] > w:\n",
    "                left += 1\n",
    "            counts[right] = right - left + 1\n",
    "        res[w] = counts\n",
    "    return res\n",
    "\n",
    "# åˆ†çµ„è¨ˆç®—\n",
    "for cid, g in merged.groupby('client_id_x', sort=False):\n",
    "    freq_dict = compute_freq_vectorized(g['date'], window_days)\n",
    "    for w in window_days:\n",
    "        merged.loc[g.index, f'TxnFrequency_{w}d'] = freq_dict[w]\n",
    "\n",
    "# --- AmtDelta ---\n",
    "merged['prev_amount'] = merged.groupby('client_id_x')['amount'].shift(1)\n",
    "merged['AmtDelta'] = merged['amount'] - merged['prev_amount']\n",
    "merged['AmtDelta'] = merged['AmtDelta'].fillna(0)\n",
    "merged.drop(columns='prev_amount', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# US region mapping\n",
    "us_region_map = {\n",
    "    'Northeast': ['NY','NJ','PA','MA','CT','RI','NH','VT','ME'],\n",
    "    'Midwest': ['IL','OH','MI','IN','WI','MN','IA','MO','ND','SD','NE','KS'],\n",
    "    'South': ['FL','GA','SC','NC','AL','MS','LA','TX','OK','TN','KY','VA','WV','AR','MD','DE','DC'],\n",
    "    'West': ['CA','WA','OR','NV','AZ','NM','CO','UT','ID','MT','WY','AK','HI'],\n",
    "}\n",
    "continent_map = {\n",
    "    'Europe': [ ... ],  # åŸæœ¬ continent_map['Europe'] å¯ç›´æ¥ä½¿ç”¨\n",
    "    'Online': ['online','AA']\n",
    "}\n",
    "\n",
    "us_region_lookup = {state: region for region, states in us_region_map.items() for state in states}\n",
    "\n",
    "# --- å‘é‡åŒ– location ç‰¹å¾µ ---\n",
    "merged['merchant_online'] = merged['merchant_state'].eq('online').astype('uint8')\n",
    "merged['merchant_us'] = merged['merchant_state'].isin(us_region_lookup.keys()).astype('uint8')\n",
    "merged['merchant_eu'] = merged['merchant_state'].isin(continent_map['Europe']).astype('uint8')\n",
    "merged['merchant_others'] = (~merged[['merchant_online','merchant_us','merchant_eu']].any(axis=1)).astype('uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- é¦–æ¬¡äº¤æ˜“æ¨™è¨˜ ---\n",
    "merged['FirstTxnInRegion'] = (~merged.duplicated(subset=['client_id_x', 'merchant_state'])).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged[[\"card_id\",\"card_number\"]]\n",
    "import numpy as np\n",
    "from scipy import stats \n",
    "\n",
    "# === (1) logè½‰æ› ===\n",
    "merged['amount'] = np.where(merged['amount'] < 0, 0, merged['amount'])  # è² æ•¸è®Š 0\n",
    "merged['amount'] = np.log(merged['amount'] + 1)  \n",
    "\n",
    "# === (3) å¹³æ–¹æ ¹è½‰æ› ===\n",
    "merged['credit_limit']=np.sqrt(merged['credit_limit'])\n",
    "merged['total_debt']=np.sqrt(merged['total_debt'])\n",
    "\n",
    "# === (3) ç«‹æ–¹æ ¹è½‰æ› ===\n",
    "merged['yearly_income']=np.cbrt(merged['yearly_income'])\n",
    "merged['per_capita_income']=np.cbrt(merged['per_capita_income'])\n",
    "\n",
    "## Box-Cox Transformation\n",
    "###merged['yearly_income'], fitted_lambda = stats.boxcox(merged['yearly_income'])\n",
    "\n",
    "# === (5) Yeoâ€“Johnson è½‰æ›ï¼ˆå¯è™•ç†è² å€¼ï¼‰ ===\n",
    "###merged['per_capita_income'], lambdaValue =stats.yeojohnson(merged['per_capita_income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04-2_åˆ†å‰²è¨“ç·´é›†åŠæ¸¬è©¦é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_fraud\n",
      "0    1367157\n",
      "1       2393\n",
      "Name: count, dtype: Int64\n",
      "is_fraud\n",
      "0    341792\n",
      "1       596\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# --- é¸å–æ•¸å€¼å‹è®Šæ•¸ ---\n",
    "num_cols = merged.select_dtypes(include=['int64', 'float64','uint8','datetime64[ns]']).columns\n",
    "df2 = merged[num_cols]\n",
    "\n",
    "# --- dropna ---\n",
    "df_cleaned = df2.dropna()\n",
    "del df2\n",
    "\n",
    "# --- é¿å…å…±ç·šæ€§ ---\n",
    "df_cleaned.drop(columns=[\"is_fraud_missing_flag\",\"card_type_Debit (Prepaid)\", \n",
    "                         \"card_brand_Discover\", \"use_chip_Online Transaction\"], inplace=True)\n",
    "\n",
    "# --- ç¢ºä¿ date æ¬„ä½åœ¨ df_cleaned ä¸­ ---\n",
    "if 'date' not in df_cleaned.columns:\n",
    "    df_cleaned['date'] = merged.loc[df_cleaned.index, 'date']\n",
    "\n",
    "# --- ä¾æ™‚é–“æ’åº ---\n",
    "df_sorted = df_cleaned.sort_values('date')\n",
    "\n",
    "# --- æ™‚é–“åºåˆ—åˆ‡åˆ†ï¼ˆå‰ 80% è¨“ç·´, å¾Œ 20% æ¸¬è©¦ï¼‰ ---\n",
    "split_index = int(len(df_sorted) * 0.8)\n",
    "train_df = df_sorted.iloc[:split_index].drop(columns=['date'])  # å¯é¸æ“‡ä¸Ÿæ‰ date\n",
    "test_df  = df_sorted.iloc[split_index:].drop(columns=['date'])\n",
    "\n",
    "# --- æª¢æŸ¥è©æ¬ºè³‡æ–™åˆ†å¸ƒ ---\n",
    "print(train_df['is_fraud'].value_counts(normalize=False))\n",
    "print(test_df['is_fraud'].value_counts(normalize=False))\n",
    "\n",
    "# --- æ¸…ç†ä¸ç”¨çš„è®Šæ•¸ ---\n",
    "del df_cleaned, df_sorted, merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. ç”¨ train_df è¨ˆç®— fraud rate\n",
    "# -----------------------------\n",
    "fraud_rate_train = (\n",
    "    train_df.groupby('mcc_code')['is_fraud'].mean()\n",
    ")\n",
    "\n",
    "# è¨­å®š threshold = 2%\n",
    "high_risk_MCC_list = fraud_rate_train[fraud_rate_train > 0.02].index.tolist()\n",
    "\n",
    "# -----------------------------\n",
    "# 2. åŠ å…¥ç‰¹å¾µåˆ° train_df / test_df\n",
    "# -----------------------------\n",
    "train_df['HighRiskMCC'] = train_df['mcc_code'].isin(high_risk_MCC_list).astype('uint8')\n",
    "test_df['HighRiskMCC']  = test_df['mcc_code'].isin(high_risk_MCC_list).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    'transaction_id',\n",
    "    'client_id_x',\n",
    "    'card_id',\n",
    "    'card_number',\n",
    "    'cvv'\n",
    "]\n",
    "\n",
    "train_df = train_df.drop(columns=cols_to_drop, errors='ignore')\n",
    "test_df  = test_df.drop(columns=cols_to_drop, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04-3(b1)_(ç•¥04-3(a))Assumption:Avoid Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##è™•ç†å…±ç·šæ€§\n",
    "train_df.drop(columns=[\"per_capita_income\"], inplace=True)\n",
    "train_df.drop(columns=[\"use_chip_Chip Transaction\",\"merchant_state_missing_flag\",\"zip_missing_flag\"], inplace=True)           \n",
    "train_df.drop(columns=[\"card_brand_Visa\" ,\"card_brand_Amex\",\"card_type_Credit\"], inplace=True)\n",
    "#å†é‡è·‘ä¸€æ¬¡VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(columns=[\"per_capita_income\"], inplace=True)\n",
    "test_df.drop(columns=[\"use_chip_Chip Transaction\",\"merchant_state_missing_flag\",\"zip_missing_flag\"], inplace=True)           \n",
    "test_df.drop(columns=[\"card_brand_Visa\" ,\"card_brand_Amex\",\"card_type_Credit\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(columns=[\"mcc_code\",\"errors_missing_flag\"], inplace=True)\n",
    "train_df.drop(columns=[\"mcc_code\",\"errors_missing_flag\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04-4 Elastic Net selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def fast_elasticnet_feature_selection(train_df, dep_var=\"is_fraud\", l1_ratio=0.5):\n",
    "\n",
    "    y = train_df[dep_var]\n",
    "    X = train_df.drop(columns=[dep_var])\n",
    "\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    X = X[numeric_cols]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    model = SGDClassifier(\n",
    "        loss=\"log_loss\",\n",
    "        penalty=\"elasticnet\",\n",
    "        alpha=0.0001,\n",
    "        l1_ratio=l1_ratio,\n",
    "        max_iter=20,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_scaled, y)\n",
    "\n",
    "    coef = model.coef_.ravel()\n",
    "    selected = [c for c, v in zip(numeric_cols, coef) if abs(v) > 1e-6]\n",
    "\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04-3 allä¸Ÿæ¨¡å‹å…§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score\n",
    "\n",
    "def fit_full_logit(train_df, test_df, dep_var=\"is_fraud\"):\n",
    "    # 1. split\n",
    "    X_train = train_df.drop(columns=[dep_var])\n",
    "    y_train = train_df[dep_var]\n",
    "\n",
    "    X_test = test_df.drop(columns=[dep_var])\n",
    "    y_test = test_df[dep_var]\n",
    "\n",
    "    # ğŸ¯ ç¢ºä¿ test æ¬„ä½é †åº = train æ¬„ä½é †åº\n",
    "    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "    # 2. æ¨™æº–åŒ–\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 3. Logistic Regression\n",
    "    model = LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=1000,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # 4. probabilities\n",
    "    train_pred = model.predict_proba(X_train_scaled)[:, 1]\n",
    "    test_pred = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # 5. ROC AUC\n",
    "    train_auc = roc_auc_score(y_train, train_pred)\n",
    "    test_auc = roc_auc_score(y_test, test_pred)\n",
    "\n",
    "    # 6. PR AUC\n",
    "    train_prauc = average_precision_score(y_train, train_pred)\n",
    "    test_prauc = average_precision_score(y_test, test_pred)\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"scaler\": scaler,\n",
    "        \"train_pred\": train_pred,\n",
    "        \"test_pred\": test_pred,\n",
    "        \"train_auc\": train_auc,\n",
    "        \"test_auc\": test_auc,\n",
    "        \"train_prauc\": train_prauc,\n",
    "        \"test_prauc\": test_prauc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['transaction_id', 'client_id_x', 'card_id', 'amount', 'merchant_id', 'zip', 'mcc_code', 'errors_missing_flag', 'use_chip_Swipe Transaction', 'current_age', 'retirement_age', 'latitude', 'longitude', 'yearly_income', 'total_debt', 'credit_score', 'num_credit_cards', 'gender_Male', 'card_number', 'cvv', 'num_cards_issued', 'credit_limit', 'card_type_Debit', 'card_brand_Mastercard', 'has_chip_YES']\n",
    "\n",
    "dep_var = \"is_fraud\"\n",
    "\n",
    "# â¬‡ ç¢ºä¿æ¨¡å‹åªåƒ selected features + label\n",
    "train_selected = train_df[selected_features + [dep_var]].copy()\n",
    "test_selected = test_df[selected_features + [dep_var]].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC: 0.9955355101224314\n",
      "Test AUC: 0.9980093519336537\n",
      "Train PR-AUC: 0.5045248555573588\n",
      "Test PR-AUC: 0.39802744296522374\n",
      "0.9955355101224314 0.9980093519336537 0.5045248555573588 0.39802744296522374\n"
     ]
    }
   ],
   "source": [
    "result = fit_full_logit(train_df, test_df, dep_var=\"is_fraud\")\n",
    "\n",
    "print(\"Train AUC:\", result[\"train_auc\"])\n",
    "print(\"Test AUC:\", result[\"test_auc\"])\n",
    "\n",
    "print(\"Train PR-AUC:\", result[\"train_prauc\"])\n",
    "print(\"Test PR-AUC:\", result[\"test_prauc\"])\n",
    "\n",
    "print(result[\"train_auc\"],result[\"test_auc\"],result[\"train_prauc\"],result[\"test_prauc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04-4(c)_Forward/Backward v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 0. å¥—ä»¶\n",
    "# =========================\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# =========================\n",
    "# 1. åˆ†å‰² X, y\n",
    "# =========================\n",
    "X_train = train_df.drop(columns=[\"is_fraud\"])\n",
    "y_train = train_df[\"is_fraud\"]\n",
    "\n",
    "X_test = test_df.drop(columns=[\"is_fraud\"])\n",
    "y_test = test_df[\"is_fraud\"]\n",
    "\n",
    "# =========================\n",
    "# 2. å°é½Šæ¬„ä½ (train ç‚ºä¸»)\n",
    "# =========================\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# =========================\n",
    "# 3. è™•ç†é¡åˆ¥ä¸å¹³è¡¡\n",
    "# =========================\n",
    "ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(\"scale_pos_weight =\", ratio)\n",
    "\n",
    "# =========================\n",
    "# 4. å»ºç«‹æ¨¡å‹\n",
    "# =========================\n",
    "model = XGBClassifier(\n",
    "    # ---- Core ----\n",
    "    n_estimators=2000,             # å¤šæ¨¹ + å° learning rate â†’ ä¸€èˆ¬æ¯”è¼ƒç©©\n",
    "    learning_rate=0.02,            # å†é™ä½ä¸€é»ï¼Œè®“ regularization æœ‰æ•ˆæœ\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "\n",
    "    # ---- Complexity control ----\n",
    "    max_depth=4,                   # 6 â†’ éæ·±ï¼Œfraud detection é€šå¸¸ 3â€“5 æœ€ç©©\n",
    "    min_child_weight=5,            # default=1 å¾ˆå®¹æ˜“ overfit\n",
    "    gamma=1,                       # è¦æ±‚ split éœ€æœ‰ gain â†’ æ¸›å°‘é›œè¨Š\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "\n",
    "    # ---- Regularization ----\n",
    "    reg_alpha=1,                   # L1ï¼Œå¹«åŠ©ç¨€ç–åŒ–\n",
    "    reg_lambda=2,                  # L2ï¼Œæ§åˆ¶ model variance\n",
    "\n",
    "    # ---- Imbalance ----\n",
    "    scale_pos_weight=ratio,        # ä½ åŸæœ¬çš„ä½œæ³•æ­£ç¢º\n",
    "\n",
    "    # ---- Infrastructure ----\n",
    "    tree_method='hist',\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5. è¨“ç·´æ¨¡å‹ï¼ˆearly stoppingï¼‰\n",
    "# =========================\n",
    "# æ³¨æ„ï¼šXGBoost 2.x ç”¨ callbacks å–ä»£æ—©æœŸçš„ early_stopping_rounds åƒæ•¸\n",
    "from xgboost import callback\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    #early_stopping_rounds=50,\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 6. é æ¸¬\n",
    "# =========================\n",
    "pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# =========================\n",
    "# 7. è¨ˆç®—è©•ä¼°æŒ‡æ¨™\n",
    "# =========================\n",
    "auc_score = roc_auc_score(y_test, pred_prob)\n",
    "prauc_score = average_precision_score(y_test, pred_prob)\n",
    "\n",
    "print(\"ROC AUC:\", auc_score)\n",
    "print(\"PR AUC:\", prauc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(X_train)[:, 1]\n",
    "auc_score = roc_auc_score(y_train, pred_prob)\n",
    "prauc_score = average_precision_score(y_train, pred_prob)\n",
    "\n",
    "print(\"ROC AUC:\", auc_score)\n",
    "print(\"PR AUC:\", prauc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 0. å¥—ä»¶\n",
    "# =========================\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# =========================\n",
    "# 1. åˆ†å‰² X, y\n",
    "# =========================\n",
    "X_train = train_df.drop(columns=[\"is_fraud\"])\n",
    "y_train = train_df[\"is_fraud\"]\n",
    "\n",
    "X_test = test_df.drop(columns=[\"is_fraud\"])\n",
    "y_test = test_df[\"is_fraud\"]\n",
    "\n",
    "# =========================\n",
    "# 2. å°é½Šæ¬„ä½ (train ç‚ºä¸»)\n",
    "# =========================\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# =========================\n",
    "# 3. è™•ç†é¡åˆ¥ä¸å¹³è¡¡\n",
    "# =========================\n",
    "ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(\"scale_pos_weight =\", ratio)\n",
    "\n",
    "# =========================\n",
    "# 4. å»ºç«‹æ¨¡å‹\n",
    "# =========================\n",
    "model = XGBClassifier(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.02,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='aucpr',  # PR-AUC å°ä¸å¹³è¡¡è³‡æ–™æ›´åˆç†\n",
    "    max_depth=3,           # æˆ– 3~4 è©¦æ¯”è¼ƒ\n",
    "    min_child_weight=3,    # æˆ– 3~5 è©¦æ¯”è¼ƒ\n",
    "    gamma=0.5,             # æˆ– 0.5~1\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=1,\n",
    "    reg_lambda=2,\n",
    "    scale_pos_weight=568,  # æ ¹æ“šæ­£è² æ¨£æœ¬æ¯”ä¾‹\n",
    "    tree_method='hist',\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5. è¨“ç·´æ¨¡å‹ï¼ˆearly stoppingï¼‰\n",
    "# =========================\n",
    "# æ³¨æ„ï¼šXGBoost 2.x ç”¨ callbacks å–ä»£æ—©æœŸçš„ early_stopping_rounds åƒæ•¸\n",
    "from xgboost import callback\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 6. é æ¸¬\n",
    "# =========================\n",
    "pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# =========================\n",
    "# 7. è¨ˆç®—è©•ä¼°æŒ‡æ¨™\n",
    "# =========================\n",
    "auc_score = roc_auc_score(y_test, pred_prob)\n",
    "prauc_score = average_precision_score(y_test, pred_prob)\n",
    "\n",
    "print(\"ROC AUC:\", auc_score)\n",
    "print(\"PR AUC:\", prauc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(X_train)[:, 1]\n",
    "auc_score = roc_auc_score(y_train, pred_prob)\n",
    "prauc_score = average_precision_score(y_train, pred_prob)\n",
    "\n",
    "print(\"ROC AUC:\", auc_score)\n",
    "print(\"PR AUC:\", prauc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# åˆå§‹åŒ–çµæœè¡¨\n",
    "result = pd.DataFrame(columns=[\"Model\", \"FeatureSet\", \"Train AUC\", \"Test AUC\", \"Train PR\", \"Test PR\"])\n",
    "\n",
    "# å‡½æ•¸ï¼šè¨“ç·´æ¨¡å‹ä¸¦è¨ˆç®—æŒ‡æ¨™\n",
    "def run_models(train_df, test_df, label_col=\"is_fraud\", feature_name=\"AllFeatures\"):\n",
    "    # ç‰¹å¾µè‡ªå‹•æŠ“é™¤äº† label ä¹‹å¤–çš„æ‰€æœ‰æ¬„ä½\n",
    "    feature_list = [c for c in train_df.columns if c != label_col]\n",
    "\n",
    "    X_train = train_df[feature_list]\n",
    "    y_train = train_df[label_col]\n",
    "\n",
    "    X_test = test_df[feature_list]\n",
    "    y_test = test_df[label_col]\n",
    "\n",
    "    # -------- XGBoost --------\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"logloss\",\n",
    "        tree_method=\"hist\",\n",
    "        enable_categorical=True,\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = xgb_model.predict_proba(X_train)[:,1]\n",
    "    test_pred  = xgb_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    result.loc[len(result)] = [\n",
    "        \"XGBoost\",\n",
    "        feature_name,\n",
    "        roc_auc_score(y_train, train_pred),\n",
    "        roc_auc_score(y_test, test_pred),\n",
    "        average_precision_score(y_train, train_pred),\n",
    "        average_precision_score(y_test, test_pred)\n",
    "    ]\n",
    "\n",
    "    # -------- LightGBM --------\n",
    "    lgb_model = lgb.LGBMClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8\n",
    "    )\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = lgb_model.predict_proba(X_train)[:,1]\n",
    "    test_pred  = lgb_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    result.loc[len(result)] = [\n",
    "        \"LightGBM\",\n",
    "        feature_name,\n",
    "        roc_auc_score(y_train, train_pred),\n",
    "        roc_auc_score(y_test, test_pred),\n",
    "        average_precision_score(y_train, train_pred),\n",
    "        average_precision_score(y_test, test_pred)\n",
    "    ]\n",
    "\n",
    "    # å°å‡ºçµæœ\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "# ç›´æ¥è·‘\n",
    "result = run_models(train_df, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# å»ºç«‹çµæœ DataFrame\n",
    "result = pd.DataFrame(columns=[\n",
    "    \"model\", \"feature_set\",\n",
    "    \"train_auc\", \"test_auc\",\n",
    "    \"train_pr\", \"test_pr\"\n",
    "])\n",
    "\n",
    "# å°å‡ºå®Œæ•´çµæœ\n",
    "print(result)\n",
    "\n",
    "# æˆ–è€…æ¼‚äº®ä¸€é»ï¼Œç”¨ DataFrame çš„ style\n",
    "display(result)\n",
    "\n",
    "# å¦‚æœåªæƒ³çœ‹æŸå¹¾æ¬„\n",
    "print(result[[\"model\", \"test_auc\", \"test_pr\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "import xgboost\n",
    "print(xgboost.__file__)\n",
    "print(xgboost.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 99_å…¶ä»–code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train positive rate:\", y_train.mean())\n",
    "print(\"Test positive rate:\", y_test.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "def ks_check(train_df, test_df):\n",
    "    diffs = {}\n",
    "    for col in train_df.columns:\n",
    "        if train_df[col].dtype != 'O':   # numeric only\n",
    "            stat, _ = ks_2samp(train_df[col], test_df[col])\n",
    "            diffs[col] = stat\n",
    "    return pd.Series(diffs).sort_values(ascending=False)\n",
    "\n",
    "ks_result = ks_check(X_train, X_test)\n",
    "print(ks_result.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "for col in X_train.columns:\n",
    "    stat, p = ks_2samp(train_df[col], test_df[col])\n",
    "    print(col, \"KS p-value:\", p)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
