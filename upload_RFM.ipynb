{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00_ 01åŒ¯å…¥è³‡æ–™ä¸¦02æ•´ç†æˆä¸€å¼µdataframe (è«‹ç›´æ¥åŸ·è¡Œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-1_import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#https://drive.google.com/drive/folders/18qV82fNY3IIWu3BRoGqm_LNgJzE8Akbr?usp=drive_link\n",
    "#base_dir = \"/Users/Andypon/10_äº¤å¤§ç ”ç©¶æ‰€/1141_01_æ©Ÿå™¨å­¸ç¿’èˆ‡é‡‘èç§‘æŠ€/data\"\n",
    "base_dir= '/Users/andyw.p.chen/Documents/Project/datasets'\n",
    "#base_dir=  \"c:\\Users\\user\\Downloads\\datasets\"\n",
    "\n",
    "def load_json_to_df(filename: str) -> pd.DataFrame:\n",
    "    file_path = os.path.join(base_dir, filename)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # å¦‚æœæ˜¯ { \"target\": {id: value, ...} }\n",
    "    if isinstance(data, dict) and len(data) == 1 and isinstance(next(iter(data.values())), dict):\n",
    "        key, inner = next(iter(data.items()))\n",
    "        return pd.DataFrame(list(inner.items()), columns=[\"id\", key])\n",
    "\n",
    "    # dict of scalar\n",
    "    if isinstance(data, dict):\n",
    "        return pd.DataFrame([{\"code\": k, \"desc\": v} for k, v in data.items()])\n",
    "\n",
    "    # list of dict\n",
    "    elif isinstance(data, list):\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported JSON structure in {filename}: {type(data)}\")\n",
    "\n",
    "\n",
    "def load_csv_to_df(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"è®€å– CSV ä¸¦è½‰ç‚º DataFrameã€‚\"\"\"\n",
    "    return pd.read_csv(os.path.join(base_dir, filename))\n",
    "\n",
    "# JSON è³‡æ–™\n",
    "##mcc_codes_df = load_json_to_df(\"mcc_codes.json\")\n",
    "train_fraud_labels_df = load_json_to_df(\"train_fraud_labels.json\")\n",
    "\n",
    "# CSV è³‡æ–™\n",
    "cards_df = load_csv_to_df(\"cards_data.csv\")\n",
    "transactions_df = load_csv_to_df(\"transactions_data.csv\")\n",
    "users_df = load_csv_to_df(\"users_data.csv\")\n",
    "\n",
    "# ç°¡å–®æª¢æŸ¥\n",
    "#print(mcc_codes_df.head())\n",
    "#print(train_fraud_labels_df.head())\n",
    "#print(cards_df.head())\n",
    "#print(transactions_df.head())\n",
    "#print(users_df.apthead())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-2_rename variable in each data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraud_labels_df = train_fraud_labels_df.rename(columns={'id': 'transactions_id'})\n",
    "train_fraud_labels_df = train_fraud_labels_df.rename(columns={'target': 'is_fraud'})\n",
    "\n",
    "cards_df = cards_df.rename(columns={'id':'card_id'})\n",
    "\n",
    "users_df = users_df.rename(columns={'id':'client_id'})\n",
    "\n",
    "transactions_df = transactions_df.rename(columns={'mcc': 'mcc_code'})\n",
    "transactions_df = transactions_df.rename(columns={'id': 'transaction_id'})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-3_è®Šæ•¸å‹æ…‹çµ±ä¸€åŠç¼ºå¤±å€¼è™•ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_flags(df: pd.DataFrame, cols: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    åœ¨ DataFrame ä¸­å°æŒ‡å®šæ¬„ä½å»ºç«‹ missing flag æ¬„ä½\n",
    "    flag=1 è¡¨ç¤ºç¼ºå¤±å€¼ï¼Œflag=0 è¡¨ç¤ºéç¼ºå¤±å€¼\n",
    "    \n",
    "    åƒæ•¸\n",
    "    ----\n",
    "    df : pd.DataFrame\n",
    "        è¼¸å…¥çš„è³‡æ–™æ¡†\n",
    "    cols : list\n",
    "        è¦æª¢æŸ¥çš„æ¬„ä½åç¨±æ¸…å–®\n",
    "    \n",
    "    å›å‚³\n",
    "    ----\n",
    "    pd.DataFrame : æ–°çš„è³‡æ–™æ¡† (å«æ–°å¢çš„ flag æ¬„ä½)\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        df[f\"{col}_missing_flag\"] = df[col].isna().astype(int)\n",
    "    return df\n",
    "\n",
    "transactions_df = add_missing_flags(transactions_df, [\"merchant_state\", \"zip\", \"errors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train_fraud_labels_df##\n",
    "train_fraud_labels_df[\"is_fraud\"]=train_fraud_labels_df[\"is_fraud\"].astype(\"category\") \n",
    "train_fraud_labels_df[\"transactions_id\"]=train_fraud_labels_df[\"transactions_id\"].astype(int) #åˆä½µè³‡æ–™éœ€è¦\n",
    "\n",
    "##cards_df##\n",
    "cards_df[\"card_brand\"]=cards_df[\"card_brand\"].astype(\"category\") \n",
    "cards_df[\"card_type\"]=cards_df[\"card_type\"].astype(\"category\")\n",
    "#####ä¸è¦loadé€™è¡Œ cards_df[\"expires\"]=pd.to_datetime(cards_df[\"expires\"], format=\"%m/%Y\")\n",
    "cards_df[\"expires\"] = pd.to_datetime(cards_df[\"expires\"], format=\"%m/%Y\").dt.to_period(\"M\")\n",
    "cards_df[\"has_chip\"]=cards_df[\"has_chip\"].astype(\"category\")\n",
    "\n",
    "cards_df['credit_limit'] = cards_df['credit_limit'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
    "#####ä¸è¦loadé€™è¡Œ cards_df[\"acct_open_date\"]=pd.to_datetime(cards_df[\"acct_open_date\"], format=\"%m/%Y\")\n",
    "cards_df[\"acct_open_date\"] = pd.to_datetime(cards_df[\"acct_open_date\"], format=\"%m/%Y\").dt.to_period(\"M\")\n",
    "#####ä¸è¦loadé€™è¡Œ cards_df[\"year_pin_last_changed\"]=pd.to_datetime(cards_df[\"year_pin_last_changed\"], format=\"%Y\")\n",
    "cards_df[\"year_pin_last_changed\"] = pd.to_datetime(cards_df[\"year_pin_last_changed\"], format=\"%Y\").dt.to_period(\"Y\")\n",
    "cards_df[\"card_on_dark_web\"]=cards_df[\"card_on_dark_web\"].astype(\"category\") \n",
    "\n",
    "##users_df##\n",
    "users_df[\"birth_year\"] = pd.to_datetime(users_df[\"birth_year\"], format=\"%Y\").dt.to_period(\"Y\")\n",
    "users_df[\"birth_month\"] = pd.to_datetime(users_df[\"birth_month\"], format=\"%m\").dt.to_period(\"M\")\n",
    "users_df[\"gender\"]=users_df[\"gender\"].astype(\"category\") \n",
    "users_df['per_capita_income'] = users_df['per_capita_income'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
    "users_df['yearly_income'] = users_df['yearly_income'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
    "users_df['total_debt'] = users_df['total_debt'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
    "\n",
    "##transactions_df##\n",
    "transactions_df[\"date\"] = pd.to_datetime(transactions_df[\"date\"])\n",
    "#æµ®é»æ•¸è½‰æ•´æ•¸åŸå› ç¢ºå®šï¼Ÿ\n",
    "transactions_df['amount'] = transactions_df['amount'].replace(r'[\\$,]', '', regex=True).astype(float).astype(int)\n",
    "##è² æ•¸å–logèª¿æˆ1\n",
    "#transactions_df['amount'] = transactions_df['amount'].replace(r'[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "transactions_df[\"use_chip\"]=transactions_df[\"use_chip\"].astype(\"category\") \n",
    "\n",
    "transactions_df.loc[\n",
    "    transactions_df['merchant_city'].str.lower() == 'online',\n",
    "    'merchant_state'\n",
    "] = 'online'\n",
    "\n",
    "transactions_df.loc[\n",
    "    transactions_df['merchant_city'].str.lower() == 'online',\n",
    "    'zip'\n",
    "] = 20000 #åŸæœ¬æ˜¯-1\n",
    "## æˆ‘æ²’æœ‰å…¨éƒ¨æ”¹ï¼Œé€™æ¨£å®Œä¹‹å¾Œä»æœ‰89006ç­†Missingï¼Œå‰©ä¸‹éƒ½æ˜¯åœ¨åœ‹å¤–\n",
    "transactions_df['zip'] = transactions_df['zip'].fillna(10000) #åŸæœ¬æ˜¯-999\n",
    "transactions_df[\"zip\"]=transactions_df[\"zip\"].astype(\"int64\")\n",
    "\n",
    "transactions_df['errors'] = transactions_df['errors'].astype('category')\n",
    "transactions_df['errors'] = transactions_df['errors'].cat.add_categories('No_error').fillna('No_error')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cars one hot encoding\n",
    "##çµ±ä¸€é¡åˆ¥è®Šæ•¸è½‰dummy variable(è¦æ³¨æ„å…±ç·šæ€§å•é¡Œï¼Œæ‡‰åˆªæ‰å…¶ä¸­ä¹‹ä¸€)\n",
    "\n",
    "#card_type åŸå§‹ç¨®é¡ï¼šDebit_57%, Credit_33%, Debit(Prepaid)_9%\n",
    "#card_brand åŸå§‹ç¨®é¡ï¼šMasterCard_52%, Visa_38%, Amex_7%, Discovery_3%\n",
    "#has_chip åŸå§‹ç¨®é¡ï¼šYes_89%, No_11%\n",
    "#card_on_dark_web åŸå§‹ç¨®é¡ï¼šNo_0%\n",
    "cols_to_encode = ['card_type', 'card_brand', 'has_chip']\n",
    "cards_df[cols_to_encode] = cards_df[cols_to_encode].astype('category')\n",
    "dummies_cards = pd.get_dummies(\n",
    "    cards_df[cols_to_encode], \n",
    "    prefix=cols_to_encode, \n",
    "    dtype='uint8'\n",
    "    )\n",
    "cards_df = pd.concat([cards_df, dummies_cards], axis=1)\n",
    "\n",
    "#use_chip åŸå§‹ç¨®é¡ï¼šSwiped_52%, Chipe_36%, Online_12%\n",
    "dummies_use = pd.get_dummies(transactions_df['use_chip'], prefix='use_chip', dtype='uint8')\n",
    "transactions_df = pd.concat([transactions_df, dummies_use], axis=1)\n",
    "\n",
    "#gender åŸå§‹ç¨®é¡ï¼šFemale_51%, Male_49%\n",
    "dummies_gender = pd.get_dummies(users_df['gender'], prefix='gender', dtype='uint8')\n",
    "users_df = pd.concat([users_df, dummies_gender], axis=1)\n",
    "\n",
    "\n",
    "cards_df.drop(columns=[\"has_chip_NO\",\"has_chip\"], inplace=True)\n",
    "transactions_df.drop(columns=[\"use_chip\"], inplace=True)\n",
    "users_df.drop(columns=[\"gender_Female\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_è³‡æ–™æ•´ä½µæˆä¸€å¼µdataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02-1_è³‡æ–™æ•´ä½µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transactions_df.loc[transactions_df[\"transaction_id\"] == 10649266] #transaction_id vs id\n",
    "\n",
    "#åŸå§‹è³‡æ–™ç­†æ•¸ï¼š13305915\n",
    "### transactions_df+train_fraud_labels_df      left æœƒæœ‰4390952 missing values\n",
    "merged = pd.merge(transactions_df, train_fraud_labels_df, left_on=\"transaction_id\", right_on=\"transactions_id\", how=\"outer\")\n",
    "### transactions_df train_fraud_labels_df(8914963) + users_df å°éå»ä¸æœƒæœ‰missing values\n",
    "merged = pd.merge(merged,users_df , left_on=\"client_id\", right_on=\"client_id\", how=\"left\")\n",
    "### transactions_df train_fraud_labels_df users_df + cards_df å°éå»ä¸æœƒæœ‰missing values\n",
    "merged = pd.merge(merged,cards_df , left_on=\"card_id\", right_on=\"card_id\", how=\"left\")\n",
    "\n",
    "#åˆªæ‰é‡è¤‡çš„columns\n",
    "merged.drop(columns=[\"transactions_id\"], inplace=True)\n",
    "merged.drop(columns=[\"client_id_y\"], inplace=True)\n",
    "\n",
    "## åˆä½µå®Œä¹‹å¾Œæœ€å¾Œè™•ç†is_fraud(åŸæœƒæœ‰missing valueså•é¡Œ)\n",
    "merged[\"is_fraud\"] = merged[\"is_fraud\"].astype(str)\n",
    "merged.loc[merged['is_fraud'].str.lower() == 'no','is_fraud'] = '0'\n",
    "merged.loc[merged['is_fraud'].str.lower() == 'yes','is_fraud'] = '1'\n",
    "merged[\"is_fraud\"] = pd.to_numeric(merged[\"is_fraud\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "merged = add_missing_flags(merged, [\"is_fraud\"])\n",
    "\n",
    "#merged.to_csv(\"merged.csv\", index=False)\n",
    "\n",
    "# å…ˆåˆªé™¤ä¸éœ€è¦çš„DataFrameä»¥ç¯€çœè¨˜æ†¶é«”\n",
    "del transactions_df, users_df, cards_df, train_fraud_labels_df, cols_to_encode, dummies_cards, dummies_use, dummies_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backup_merged = merged.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04_RFM + DK é‡é»å¾®èª¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged = backup_merged.copy() ##æœ‰å‡ºäº‹å†è¶•å¿«å›å¾©åŸç‹€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04_RFM features engineering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04-1_RFM features æ–°å¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ç¢ºä¿æ—¥æœŸæ˜¯ datetime ä¸¦æ’åº\n",
    "merged['date'] = pd.to_datetime(merged['date'])\n",
    "merged = merged.sort_values(by=['client_id_x', 'date']).reset_index(drop=True)\n",
    "\n",
    "# --- RecencyInterval ---\n",
    "merged['RecencyInterval'] = merged.groupby('client_id_x')['date'].diff().dt.total_seconds().fillna(0)/60\n",
    "\n",
    "# --- TxnFrequency for multiple windows (å‘é‡åŒ–æ»‘å‹•çª—å£) ---\n",
    "window_days = [7, 30, 60, 90]\n",
    "for w in window_days:\n",
    "    merged[f'TxnFrequency_{w}d'] = 0\n",
    "\n",
    "def compute_freq_vectorized(dates, windows):\n",
    "    \"\"\"å‘é‡åŒ–è¨ˆç®—æ¯ç­†äº¤æ˜“åœ¨æ¯å€‹ window å…§çš„äº¤æ˜“æ•¸\"\"\"\n",
    "    n = len(dates)\n",
    "    dates_int = dates.values.astype('datetime64[D]').astype(int)\n",
    "    res = {w: np.zeros(n, dtype=int) for w in windows}\n",
    "    for w in windows:\n",
    "        left = 0\n",
    "        counts = np.zeros(n, dtype=int)\n",
    "        for right in range(n):\n",
    "            while dates_int[right] - dates_int[left] > w:\n",
    "                left += 1\n",
    "            counts[right] = right - left + 1\n",
    "        res[w] = counts\n",
    "    return res\n",
    "\n",
    "# åˆ†çµ„è¨ˆç®—\n",
    "for cid, g in merged.groupby('client_id_x', sort=False):\n",
    "    freq_dict = compute_freq_vectorized(g['date'], window_days)\n",
    "    for w in window_days:\n",
    "        merged.loc[g.index, f'TxnFrequency_{w}d'] = freq_dict[w]\n",
    "\n",
    "# --- AmtDelta ---\n",
    "merged['prev_amount'] = merged.groupby('client_id_x')['amount'].shift(1)\n",
    "merged['AmtDelta'] = merged['amount'] - merged['prev_amount']\n",
    "merged['AmtDelta'] = merged['AmtDelta'].fillna(0)\n",
    "merged.drop(columns='prev_amount', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04-3_DK features æ–°å¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# US region mapping\n",
    "us_region_map = {\n",
    "    'Northeast': ['NY','NJ','PA','MA','CT','RI','NH','VT','ME'],\n",
    "    'Midwest': ['IL','OH','MI','IN','WI','MN','IA','MO','ND','SD','NE','KS'],\n",
    "    'South': ['FL','GA','SC','NC','AL','MS','LA','TX','OK','TN','KY','VA','WV','AR','MD','DE','DC'],\n",
    "    'West': ['CA','WA','OR','NV','AZ','NM','CO','UT','ID','MT','WY','AK','HI'],\n",
    "}\n",
    "continent_map = {\n",
    "    'Europe': [ ... ],  # åŸæœ¬ continent_map['Europe'] å¯ç›´æ¥ä½¿ç”¨\n",
    "    'Online': ['online','AA']\n",
    "}\n",
    "\n",
    "us_region_lookup = {state: region for region, states in us_region_map.items() for state in states}\n",
    "\n",
    "# --- å‘é‡åŒ– location ç‰¹å¾µ ---\n",
    "merged['merchant_online'] = merged['merchant_state'].eq('online').astype('uint8')\n",
    "merged['merchant_us'] = merged['merchant_state'].isin(us_region_lookup.keys()).astype('uint8')\n",
    "merged['merchant_eu'] = merged['merchant_state'].isin(continent_map['Europe']).astype('uint8')\n",
    "merged['merchant_others'] = (~merged[['merchant_online','merchant_us','merchant_eu']].any(axis=1)).astype('uint8')\n",
    "\n",
    "# --- é¦–æ¬¡äº¤æ˜“æ¨™è¨˜ ---\n",
    "merged['FirstTxnInRegion'] = (~merged.duplicated(subset=['client_id_x', 'merchant_state'])).astype('uint8')\n",
    "\n",
    "# DifferentState\n",
    "merged['prev_state']=(merged\n",
    "                     .groupby('client_id_x')['merchant_state']\n",
    "                     .shift(1))\n",
    "\n",
    "merged['DifferentState'] = (\n",
    "    (merged['merchant_state'] != merged['prev_state'])\n",
    "    & merged['prev_state'].notna()\n",
    ").astype(int)\n",
    "\n",
    "merged = merged.drop(columns=['prev_state'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04-3_è³‡æ–™é€²è¡Œè®Šæ•¸è½‰æ›ä»¥æ±‚æ¨¡å‹é…é£¾æ›´ä½³è¡¨ç¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged[[\"card_id\",\"card_number\"]]\n",
    "import numpy as np\n",
    "from scipy import stats \n",
    "\n",
    "# === (1) logè½‰æ› ===\n",
    "merged['amount'] = np.where(merged['amount'] < 0, 0, merged['amount'])  # è² æ•¸è®Š 0\n",
    "merged['amount'] = np.log(merged['amount'] + 1)  \n",
    "\n",
    "# === (3) å¹³æ–¹æ ¹è½‰æ› ===\n",
    "merged['credit_limit']=np.sqrt(merged['credit_limit'])\n",
    "merged['total_debt']=np.sqrt(merged['total_debt'])\n",
    "\n",
    "# === (3) ç«‹æ–¹æ ¹è½‰æ› ===\n",
    "merged['yearly_income']=np.cbrt(merged['yearly_income'])\n",
    "merged['per_capita_income']=np.cbrt(merged['per_capita_income'])\n",
    "\n",
    "## Box-Cox Transformation\n",
    "###merged['yearly_income'], fitted_lambda = stats.boxcox(merged['yearly_income'])\n",
    "\n",
    "# === (5) Yeoâ€“Johnson è½‰æ›ï¼ˆå¯è™•ç†è² å€¼ï¼‰ ===\n",
    "###merged['per_capita_income'], lambdaValue =stats.yeojohnson(merged['per_capita_income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04-4_åˆ†å‰²è¨“ç·´é›†åŠæ¸¬è©¦é›†ã€ä¸åŒblock ä¸¦å¾é€™è£¡æ‰è¨ˆç®— HighRiskMCC é¿å…è³‡æ–™æ´©æ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Block 0\n",
      "\n",
      "Processing Block 1\n",
      "\n",
      "Processing Block 2\n",
      "\n",
      "Processing Block 3\n",
      "\n",
      "Processing Block 4\n",
      "\n",
      "Processing Block 5\n",
      "\n",
      "Processing Block 6\n",
      "\n",
      "Processing Block 7\n",
      "\n",
      "Processing Block 8\n",
      "\n",
      "Processing Block 9\n",
      "\n",
      "Block 0\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    663110\n",
      "1      2113\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    165846\n",
      "1       460\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 1\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    690705\n",
      "1        37\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    172686\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 2\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    707413\n",
      "1       923\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    177085\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 3\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    725007\n",
      "1       836\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    180960\n",
      "1       501\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 4\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    731394\n",
      "1       664\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    183015\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 5\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    742735\n",
      "1      1444\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    185300\n",
      "1       745\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 6\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    744145\n",
      "1      2064\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    186169\n",
      "1       384\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 7\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    749827\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    187285\n",
      "1       172\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 8\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    746455\n",
      "1      1224\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    186515\n",
      "1       405\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 9\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    620778\n",
      "1      1093\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    155201\n",
      "1       267\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# --- é¸å–æ•¸å€¼å‹è®Šæ•¸ ---\n",
    "num_cols = merged.select_dtypes(include=['int64', 'float64','uint8','datetime64[ns]']).columns\n",
    "df2 = merged[num_cols]\n",
    "\n",
    "# --- dropna ---\n",
    "df_cleaned = df2.dropna()\n",
    "del df2\n",
    "\n",
    "# --- é¿å…å…±ç·šæ€§ ---\n",
    "df_cleaned.drop(columns=[\"is_fraud_missing_flag\",\"card_type_Debit (Prepaid)\", \n",
    "                         \"card_brand_Discover\", \"use_chip_Online Transaction\"], inplace=True)\n",
    "\n",
    "# --- ç¢ºä¿ date æ¬„ä½åœ¨ df_cleaned ä¸­ ---\n",
    "if 'date' not in df_cleaned.columns:\n",
    "    df_cleaned['date'] = merged.loc[df_cleaned.index, 'date']\n",
    "\n",
    "# --- ä¾æ™‚é–“æ’åº ---\n",
    "df_sorted = df_cleaned.sort_values('date')\n",
    "df_sorted['year'] = df_sorted['date'].dt.year\n",
    "\n",
    "# 2010â€“2011 â†’ block 0\n",
    "# 2012â€“2013 â†’ block 1\n",
    "# ...\n",
    "# 2018â€“2019 â†’ block 4ï¼ˆå¦‚æœä½ çœŸçš„æ˜¯ 2010â€“2019 å…± 10 å¹´ï¼Œæœƒæœ‰ 5 å€‹ blockï¼‰\n",
    "df_sorted['time_block'] = (df_sorted['year'] - 2010) // 1\n",
    "\n",
    "\n",
    "#å°æ¯å€‹æ™‚é–“blockåšåˆ‡å‰²\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    print(f\"\\nProcessing Block {block_id}\")\n",
    "\n",
    "    block_df = block_df.sort_values('date')\n",
    "    split_index = int(len(block_df) * 0.8)\n",
    "\n",
    "    train_block = block_df.iloc[:split_index].copy()\n",
    "    test_block  = block_df.iloc[split_index:].copy()\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1ï¸âƒ£ ç”¨ã€Œè©² block çš„ trainã€ç®— fraud rate\n",
    "    # -----------------------------\n",
    "    fraud_rate = (\n",
    "        train_block\n",
    "        .groupby('mcc_code')['is_fraud']\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    high_risk_mcc = fraud_rate[fraud_rate > 0.02].index\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2ï¸âƒ£ å¥—ç”¨åˆ°è©² block çš„ train / test\n",
    "    # -----------------------------\n",
    "    train_block['HighRiskMCC'] = train_block['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "    test_block['HighRiskMCC']  = test_block['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "\n",
    "    train_list.append(train_block)\n",
    "    test_list.append(test_block)\n",
    "\n",
    "\n",
    "train_df = pd.concat(train_list).drop(columns=['date', 'year', 'time_block'])\n",
    "test_df  = pd.concat(test_list).drop(columns=['date', 'year', 'time_block'])\n",
    "\n",
    "\n",
    "#æ¯”ä¾‹æª¢æŸ¥\n",
    "for block_id in sorted(df_sorted['time_block'].unique()):\n",
    "    print(f\"\\nBlock {block_id}\")\n",
    "    print(\"Train fraud count:\")\n",
    "    print(train_df.loc[df_sorted['time_block'] == block_id, 'is_fraud'].value_counts())\n",
    "    print(\"Test fraud count:\")\n",
    "    print(test_df.loc[df_sorted['time_block'] == block_id, 'is_fraud'].value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04-5_å®šç¾©ä¸åŒçš„features group æ–¹ä¾¿æ¨¡å‹é‹ç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "result = pd.DataFrame(columns=[\n",
    "    \"Model\", \"Features\", \n",
    "    \"Train AUC\", \"Test AUC\", \n",
    "    \"Train PR AUC\", \"Test PR AUC\"\n",
    "])\n",
    "\n",
    "'''\n",
    "\n",
    "# ALL features\n",
    "\n",
    "all_cols = ['transaction_id', 'date', 'client_id_x', 'card_id', 'amount',\n",
    "       'merchant_id', 'merchant_city', 'merchant_state', 'zip', 'mcc_code',\n",
    "       'errors', 'merchant_state_missing_flag', 'zip_missing_flag',\n",
    "       'errors_missing_flag', 'use_chip_Chip Transaction',\n",
    "       'use_chip_Online Transaction', 'use_chip_Swipe Transaction',\n",
    "       'current_age', 'retirement_age', 'birth_year', 'birth_month', 'gender',\n",
    "       'address', 'latitude', 'longitude', 'per_capita_income',\n",
    "       'yearly_income', 'total_debt', 'credit_score', 'num_credit_cards',\n",
    "       'gender_Male', 'card_brand', 'card_type', 'card_number', 'expires',\n",
    "       'cvv', 'num_cards_issued', 'credit_limit', 'acct_open_date',\n",
    "       'year_pin_last_changed', 'card_on_dark_web', 'card_type_Credit',\n",
    "       'card_type_Debit', 'card_type_Debit (Prepaid)', 'card_brand_Amex',\n",
    "       'card_brand_Discover', 'card_brand_Mastercard', 'card_brand_Visa',\n",
    "       'has_chip_YES', 'is_fraud_missing_flag']\n",
    "\n",
    "VIF_col = [\"is_fraud_missing_flag\",\"card_type_Debit (Prepaid)\", \n",
    "                         \"card_brand_Discover\", \"use_chip_Online Transaction\",'is_fraud_missing_flag','merchant_state_missing_flag', 'zip_missing_flag','card_on_dark_web']\n",
    "\n",
    "identifier = [\n",
    "    'transaction_id',\n",
    "    'client_id_x',\n",
    "    'card_id',\n",
    "    'card_number',\n",
    "    'cvv'\n",
    "]\n",
    "\n",
    "set_VIF = set(VIF_col)\n",
    "set_identifier =set(identifier)\n",
    "exclude_cols = set(VIF_col) | set(identifier)\n",
    "all_cols = [x for x in all_cols if x not in exclude_cols]\n",
    "\n",
    "\n",
    "# RFM features\n",
    "rfm_cols = [\n",
    "    'RecencyInterval', 'TxnFrequency_7d','TxnFrequency_30d',\n",
    "    'TxnFrequency_60d', 'TxnFrequency_90d','AmtDelta'\n",
    "]\n",
    "\n",
    "# DK features\n",
    "dk_cols = [\n",
    "    'merchant_online', 'merchant_us', 'merchant_eu', 'merchant_others',\n",
    "    'FirstTxnInRegion','HighRiskMCC','DifferentState'\n",
    "]\n",
    "\n",
    "# Grouping\n",
    "feature_groups = {\n",
    "    \"X_all\": all_cols,\n",
    "    \"X_rfm\": rfm_cols,\n",
    "    \"X_dk\": dk_cols,\n",
    "    \"X_all + X_rfm\": all_cols + rfm_cols,\n",
    "    \"X_all + X_dk\": all_cols + dk_cols,\n",
    "    \"X_rfm + X_dk\": rfm_cols + dk_cols,\n",
    "    \"X_all + X_rfm + X_dk\": all_cols + rfm_cols + dk_cols\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04-6_Assumption: Avoid Multicollinearityï¼ˆè€å¸«å»ºè­°æˆ‘å€‘å…ˆçœç•¥ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n##è™•ç†é«˜åº¦å…±ç·šæ€§è®Šæ•¸\\ntrain_df.drop(columns=[\"per_capita_income\"], inplace=True)\\ntrain_df.drop(columns=[\"use_chip_Chip Transaction\",\"merchant_state_missing_flag\",\"zip_missing_flag\"], inplace=True)           \\ntrain_df.drop(columns=[\"card_brand_Visa\" ,\"card_brand_Amex\",\"card_type_Credit\"], inplace=True)\\n\\ntest_df.drop(columns=[\"per_capita_income\"], inplace=True)\\ntest_df.drop(columns=[\"use_chip_Chip Transaction\",\"merchant_state_missing_flag\",\"zip_missing_flag\"], inplace=True)           \\ntest_df.drop(columns=[\"card_brand_Visa\" ,\"card_brand_Amex\",\"card_type_Credit\"], inplace=True)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "##è™•ç†é«˜åº¦å…±ç·šæ€§è®Šæ•¸\n",
    "train_df.drop(columns=[\"per_capita_income\"], inplace=True)\n",
    "train_df.drop(columns=[\"use_chip_Chip Transaction\",\"merchant_state_missing_flag\",\"zip_missing_flag\"], inplace=True)           \n",
    "train_df.drop(columns=[\"card_brand_Visa\" ,\"card_brand_Amex\",\"card_type_Credit\"], inplace=True)\n",
    "\n",
    "test_df.drop(columns=[\"per_capita_income\"], inplace=True)\n",
    "test_df.drop(columns=[\"use_chip_Chip Transaction\",\"merchant_state_missing_flag\",\"zip_missing_flag\"], inplace=True)           \n",
    "test_df.drop(columns=[\"card_brand_Visa\" ,\"card_brand_Amex\",\"card_type_Credit\"], inplace=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05_Features Selection éƒ¨åˆ†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05-1_Stepwise selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 0 (Year: 2010)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 25)... âœ… Selected 11 feats | Test AUC: 0.9517\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 4 feats | Test AUC: 0.7408\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 4 feats | Test AUC: 0.9654\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 31)... âœ… Selected 15 feats | Test AUC: 0.9628\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 31)... âœ… Selected 13 feats | Test AUC: 0.9089\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 7 feats | Test AUC: 0.9295\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 37)... âœ… Selected 16 feats | Test AUC: 0.9784\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 1 (Year: 2011)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 25)... âœ… Selected 2 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 1 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 2 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 31)... âœ… Selected 7 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 31)... âœ… Selected 3 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 5 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 37)... âœ… Selected 7 feats | Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 2 (Year: 2012)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 25)... âœ… Selected 6 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 4 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 1 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 31)... âœ… Selected 8 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 31)... âœ… Selected 7 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 4 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 37)... âœ… Selected 14 feats | Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 3 (Year: 2013)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 25)... âœ… Selected 10 feats | Test AUC: 0.8856\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 5 feats | Test AUC: 0.7592\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 3 feats | Test AUC: 0.8517\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 31)... âœ… Selected 14 feats | Test AUC: 0.9268\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 31)... âœ… Selected 14 feats | Test AUC: 0.8801\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 8 feats | Test AUC: 0.9083\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 37)... âœ… Selected 16 feats | Test AUC: 0.9175\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 4 (Year: 2014)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 25)... âœ… Selected 14 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 4 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 3 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 31)... âœ… Selected 16 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 31)... âœ… Selected 14 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 6 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 37)... âœ… Selected 18 feats | Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 5 (Year: 2015)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 25)... âœ… Selected 14 feats | Test AUC: 0.906\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 5 feats | Test AUC: 0.7445\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 2 feats | Test AUC: 0.8461\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 31)... âœ… Selected 19 feats | Test AUC: 0.9228\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 31)... âœ… Selected 14 feats | Test AUC: 0.8944\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 7 feats | Test AUC: 0.8956\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 37)... âœ… Selected 23 feats | Test AUC: 0.9157\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 6 (Year: 2016)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 25)... âœ… Selected 12 feats | Test AUC: 0.9178\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 4 feats | Test AUC: 0.7314\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 2 feats | Test AUC: 0.8589\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 31)... âœ… Selected 14 feats | Test AUC: 0.9397\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 31)... âœ… Selected 15 feats | Test AUC: 0.9075\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 6 feats | Test AUC: 0.9192\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 37)... âœ… Selected 14 feats | Test AUC: 0.9323\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 7 (Year: 2017)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 25)... âš ï¸ Skipped: Train set has only 1 class (value: 0)\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âš ï¸ Skipped: Train set has only 1 class (value: 0)\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âš ï¸ Skipped: Train set has only 1 class (value: 0)\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 31)... âš ï¸ Skipped: Train set has only 1 class (value: 0)\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 31)... âš ï¸ Skipped: Train set has only 1 class (value: 0)\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âš ï¸ Skipped: Train set has only 1 class (value: 0)\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 37)... âš ï¸ Skipped: Train set has only 1 class (value: 0)\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 8 (Year: 2018)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 25)... âœ… Selected 14 feats | Test AUC: 0.9031\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 5 feats | Test AUC: 0.7371\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 3 feats | Test AUC: 0.9158\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 31)... âœ… Selected 18 feats | Test AUC: 0.925\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 31)... âœ… Selected 14 feats | Test AUC: 0.908\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 7 feats | Test AUC: 0.8452\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 37)... âœ… Selected 14 feats | Test AUC: 0.9262\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 9 (Year: 2019)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 25)... âœ… Selected 15 feats | Test AUC: 0.9607\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 4 feats | Test AUC: 0.7204\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 2 feats | Test AUC: 0.7503\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 31)... âœ… Selected 18 feats | Test AUC: 0.9691\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 31)... âœ… Selected 17 feats | Test AUC: 0.9747\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 7 feats | Test AUC: 0.8865\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 37)... âœ… Selected 21 feats | Test AUC: 0.9758\n",
      "\n",
      "ğŸ‰ Stepwise Selection Completed!\n",
      "è®Šæ•¸çµæœå·²å„²å­˜æ–¼ 'stepwise_feature_storage' å­—å…¸ä¸­ã€‚\n",
      "\n",
      "=== Stepwise Logistic Regression è®Šæ•¸ç¯©é¸æˆæ•ˆè¡¨ ===\n",
      "Year                      2010                                        2011                                        2012                                        2013                                        2014                                        2015                                        2016                                        2017                                        2018                                        2019                                  \n",
      "                     Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC\n",
      "Feature Group                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "X_all                   0.9533   0.9517       0.0548      0.0550    0.9418      NaN       0.0022         NaN    0.8425      NaN       0.0134         NaN    0.9203   0.8856       0.0396      0.0508    0.9158      NaN       0.0345         NaN    0.9198   0.9060       0.0719      0.0848    0.9183   0.9178       0.0565      0.0454       NaN      NaN          NaN         NaN    0.9708   0.9031       0.0825      0.0873    0.9673   0.9607       0.0887      0.0779\n",
      "X_all + X_dk            0.9001   0.9089       0.0415      0.0506    0.9437      NaN       0.0057         NaN    0.8313      NaN       0.0146         NaN    0.9085   0.8801       0.0646      0.0773    0.9068      NaN       0.0526         NaN    0.9092   0.8944       0.1100      0.1292    0.9097   0.9075       0.0692      0.0651       NaN      NaN          NaN         NaN    0.9742   0.9080       0.1655      0.1612    0.9835   0.9747       0.2043      0.1474\n",
      "X_all + X_rfm           0.9610   0.9628       0.0813      0.1236    0.9618      NaN       0.0078         NaN    0.8883      NaN       0.0273         NaN    0.9418   0.9268       0.1004      0.1321    0.9288      NaN       0.1108         NaN    0.9379   0.9228       0.1219      0.1669    0.9325   0.9397       0.0928      0.0613       NaN      NaN          NaN         NaN    0.9775   0.9250       0.1142      0.1098    0.9732   0.9691       0.1071      0.0911\n",
      "X_all + X_rfm + X_dk    0.9748   0.9784       0.1285      0.1999    0.9585      NaN       0.0179         NaN    0.8844      NaN       0.0315         NaN    0.9360   0.9175       0.1343      0.1940    0.9247      NaN       0.1597         NaN    0.9305   0.9157       0.1613      0.2220    0.9271   0.9323       0.1397      0.1053       NaN      NaN          NaN         NaN    0.9993   0.9262       0.7196      0.5932    0.9786   0.9758       0.2280      0.1712\n",
      "X_dk                    0.9612   0.9654       0.0565      0.0584    0.9285      NaN       0.0008         NaN    0.8200      NaN       0.0069         NaN    0.8606   0.8517       0.0129      0.0296    0.8576      NaN       0.0101         NaN    0.8533   0.8461       0.0184      0.0333    0.8551   0.8589       0.0221      0.0174       NaN      NaN          NaN         NaN    0.9435   0.9158       0.0473      0.0338    0.7623   0.7503       0.0114      0.0108\n",
      "X_rfm                   0.6917   0.7408       0.0084      0.0272    0.5822      NaN       0.0005         NaN    0.7197      NaN       0.0040         NaN    0.7740   0.7592       0.0065      0.0146    0.7456      NaN       0.0058         NaN    0.7475   0.7445       0.0099      0.0181    0.7114   0.7314       0.0091      0.0104       NaN      NaN          NaN         NaN    0.7465   0.7371       0.0061      0.0083    0.7026   0.7204       0.0051      0.0047\n",
      "X_rfm + X_dk            0.9363   0.9295       0.0764      0.1830    0.9535      NaN       0.0053         NaN    0.8862      NaN       0.0275         NaN    0.9230   0.9083       0.0759      0.1623    0.9141      NaN       0.0846         NaN    0.9118   0.8956       0.0997      0.1574    0.9102   0.9192       0.0941      0.0733       NaN      NaN          NaN         NaN    0.8609   0.8452       0.0255      0.0255    0.8879   0.8865       0.0305      0.0319\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import warnings\n",
    "\n",
    "# å¿½ç•¥ statsmodels å¯èƒ½ç”¢ç”Ÿçš„è¿­ä»£è­¦å‘Šï¼Œä¿æŒè¼¸å‡ºä¹¾æ·¨\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ===========================================================\n",
    "# 1. æ ¸å¿ƒå‡½æ•¸ï¼šåš´è¬¹ç‰ˆ Stepwise (Forward + Backward)\n",
    "# ===========================================================\n",
    "\n",
    "def check_data_validity(y_data, stage=\"Train\"):\n",
    "    \"\"\"æª¢æŸ¥è³‡æ–™æ˜¯å¦è¶³å¤ é€²è¡Œ Logistic Regression\"\"\"\n",
    "    if len(y_data) == 0:\n",
    "        return False, f\"{stage} set is empty\"\n",
    "    if y_data.nunique() < 2:\n",
    "        val = y_data.iloc[0] if len(y_data) > 0 else \"None\"\n",
    "        return False, f\"{stage} set has only 1 class (value: {val})\"\n",
    "    return True, \"\"\n",
    "\n",
    "def run_stepwise_logit(train_df, test_df, feature_cols, dep_var=\"is_fraud\", \n",
    "                       threshold_in=0.01, threshold_out=0.05, max_iter=50):\n",
    "    \"\"\"\n",
    "    Stepwise Selection based on P-values (Forward Selection + Backward Elimination)\n",
    "    \"\"\"\n",
    "    # --- 1. æº–å‚™æ•¸æ“š ---\n",
    "    X_train = train_df[feature_cols].fillna(0)\n",
    "    y_train = train_df[dep_var]\n",
    "    X_test  = test_df[feature_cols].fillna(0)\n",
    "    y_test  = test_df[dep_var]\n",
    "\n",
    "    # --- 2. é˜²å´©æ½°æª¢æŸ¥ (Edge Case Handling) ---\n",
    "    is_valid_train, msg_train = check_data_validity(y_train, \"Train\")\n",
    "    if not is_valid_train:\n",
    "        return {\"status\": \"skip\", \"message\": msg_train}\n",
    "    \n",
    "    # æ¸¬è©¦é›†è‹¥ç„¡æ•ˆï¼Œæ¨¡å‹ä»å¯è¨“ç·´ï¼Œåªæ˜¯ç„¡æ³•ç®— Test AUC\n",
    "    is_valid_test, _ = check_data_validity(y_test, \"Test\")\n",
    "\n",
    "    # --- 3. æ¨™æº–åŒ– (Standardization) ---\n",
    "    # Logistic å°è®Šæ•¸å°ºåº¦æ¥µå…¶æ•æ„Ÿï¼ŒStepwise å‰å‹™å¿…æ¨™æº–åŒ–\n",
    "    try:\n",
    "        scaler = StandardScaler()\n",
    "        X_train_std = pd.DataFrame(scaler.fit_transform(X_train), columns=feature_cols, index=train_df.index)\n",
    "        X_test_std  = pd.DataFrame(scaler.transform(X_test), columns=feature_cols, index=test_df.index)\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": f\"Scaling failed: {str(e)}\"}\n",
    "\n",
    "    # --- 4. è¿­ä»£ç¯©é¸ ---\n",
    "    included = []\n",
    "    candidates = list(feature_cols)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        changed = False\n",
    "        \n",
    "        # ====== Forward Step: å˜—è©¦åŠ å…¥ä¸€å€‹æœ€å¥½çš„è®Šæ•¸ ======\n",
    "        best_pval = 1.0\n",
    "        best_feature = None\n",
    "        \n",
    "        for candidate in candidates:\n",
    "            try:\n",
    "                # æš«æ™‚åŠ å…¥å€™é¸è®Šæ•¸\n",
    "                current_vars = included + [candidate]\n",
    "                X_const = sm.add_constant(X_train_std[current_vars])\n",
    "                \n",
    "                # è¨“ç·´ (disp=0 ä¸å°å‡º log)\n",
    "                model = sm.Logit(y_train, X_const).fit(disp=0, method='newton')\n",
    "                \n",
    "                # å–å¾—è©²è®Šæ•¸çš„ p-value\n",
    "                pval = model.pvalues[candidate]\n",
    "                \n",
    "                if pval < best_pval:\n",
    "                    best_pval = pval\n",
    "                    best_feature = candidate\n",
    "            except:\n",
    "                # è‹¥ç™¼ç”Ÿ Singular Matrix (çŸ©é™£å¥‡ç•°) æˆ–æ”¶æ–‚å¤±æ•—ï¼Œè·³éè©²è®Šæ•¸\n",
    "                continue\n",
    "        \n",
    "        # è‹¥ P-value å°æ–¼é–€æª»å‰‡åŠ å…¥\n",
    "        if best_feature is not None and best_pval < threshold_in:\n",
    "            included.append(best_feature)\n",
    "            candidates.remove(best_feature)\n",
    "            changed = True\n",
    "            # print(f\"    + Add: {best_feature} (p={best_pval:.4f})\")\n",
    "\n",
    "        # ====== Backward Step: å˜—è©¦ç§»é™¤ä¸€å€‹æœ€å·®çš„è®Šæ•¸ ======\n",
    "        if included:\n",
    "            try:\n",
    "                X_const = sm.add_constant(X_train_std[included])\n",
    "                model = sm.Logit(y_train, X_const).fit(disp=0)\n",
    "                \n",
    "                # æ‰¾å‡º p-value æœ€å¤§çš„è®Šæ•¸ (æ’é™¤ const)\n",
    "                pvalues = model.pvalues.drop('const', errors='ignore')\n",
    "                if not pvalues.empty:\n",
    "                    worst_pval = pvalues.max()\n",
    "                    worst_feature = pvalues.idxmax()\n",
    "                    \n",
    "                    # è‹¥ P-value å¤§æ–¼é–€æª»å‰‡ç§»é™¤\n",
    "                    if worst_pval > threshold_out:\n",
    "                        included.remove(worst_feature)\n",
    "                        candidates.append(worst_feature)\n",
    "                        changed = True\n",
    "                        # print(f\"    - Drop: {worst_feature} (p={worst_pval:.4f})\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if not changed:\n",
    "            break\n",
    "\n",
    "    # --- 5. æœ€çµ‚çµæœå›å‚³ ---\n",
    "    if not included:\n",
    "        return {\"status\": \"skip\", \"message\": \"No variables selected (all insignificant)\"}\n",
    "\n",
    "    # è¨ˆç®—ç•¶ä¸‹ Stepwise æ¨¡å‹çš„ Metrics (ä¾›åƒè€ƒ)\n",
    "    try:\n",
    "        X_train_final = sm.add_constant(X_train_std[included])\n",
    "        final_model = sm.Logit(y_train, X_train_final).fit(disp=0)\n",
    "        \n",
    "        train_prob = final_model.predict(X_train_final)\n",
    "        train_auc = roc_auc_score(y_train, train_prob)\n",
    "        train_pr  = average_precision_score(y_train, train_prob)\n",
    "        \n",
    "        test_auc = np.nan\n",
    "        test_pr = np.nan\n",
    "        \n",
    "        if is_valid_test:\n",
    "            try:\n",
    "                X_test_final = sm.add_constant(X_test_std[included])\n",
    "                test_prob = final_model.predict(X_test_final)\n",
    "                test_auc = roc_auc_score(y_test, test_prob)\n",
    "                test_pr  = average_precision_score(y_test, test_prob)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"selected_features\": included,  # <--- é‡é»ï¼šé¸å‡ºçš„è®Šæ•¸åˆ—è¡¨\n",
    "            \"metrics\": {\n",
    "                \"Train AUC\": round(train_auc, 4),\n",
    "                \"Test AUC\": round(test_auc, 4) if not np.isnan(test_auc) else np.nan,\n",
    "                \"Train PR-AUC\": round(train_pr, 4),\n",
    "                \"Test PR-AUC\": round(test_pr, 4) if not np.isnan(test_pr) else np.nan,\n",
    "                \"Num Features\": len(included)\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# 2. è¨­å®šèˆ‡ç‰¹å¾µç¾¤çµ„\n",
    "# ===========================================================\n",
    "\n",
    "# ç¢ºä¿ df_sorted å­˜åœ¨\n",
    "if 'df_sorted' not in locals():\n",
    "    raise ValueError(\"âš ï¸ Error: 'df_sorted' æœªå®šç¾©ï¼Œè«‹å…ˆè¼‰å…¥æ‚¨çš„è³‡æ–™ã€‚\")\n",
    "\n",
    "# å®šç¾©è¦æ’é™¤çš„æ¬„ä½\n",
    "identifier = ['transaction_id', 'client_id_x', 'card_id', 'card_number', 'cvv']\n",
    "exclude_cols = set(identifier) | {'is_fraud', 'date', 'year', 'time_block', 'HighRiskMCC'}\n",
    "\n",
    "def clean_cols(cols):\n",
    "    \"\"\"éæ¿¾æ‰ ID èˆ‡ Target ç­‰ä¸æ‡‰æ”¾å…¥æ¨¡å‹çš„æ¬„ä½\"\"\"\n",
    "    return [c for c in cols if c not in exclude_cols]\n",
    "\n",
    "# å®šç¾©æ‚¨çš„ Feature Groups\n",
    "# (å‡è¨­ all_cols, rfm_cols, dk_cols è®Šæ•¸å·²å­˜åœ¨æ–¼æ‚¨çš„ç’°å¢ƒä¸­)\n",
    "feature_groups = {\n",
    "    \"X_all\": clean_cols(all_cols),\n",
    "    \"X_rfm\": clean_cols(rfm_cols),\n",
    "    \"X_dk\": clean_cols(dk_cols),\n",
    "    \"X_all + X_rfm\": clean_cols(all_cols + rfm_cols),\n",
    "    \"X_all + X_dk\": clean_cols(all_cols + dk_cols),\n",
    "    \"X_rfm + X_dk\": clean_cols(rfm_cols + dk_cols),\n",
    "    \"X_all + X_rfm + X_dk\": clean_cols(all_cols + rfm_cols + dk_cols)\n",
    "}\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# 3. ä¸»åŸ·è¡Œè¿´åœˆ (å„²å­˜è®Šæ•¸ + ç”¢å‡ºåˆæ­¥å ±è¡¨)\n",
    "# ===========================================================\n",
    "\n",
    "# â˜… é€™æ˜¯æœ€é‡è¦çš„å„²å­˜å®¹å™¨ï¼š[Block ID][Group Name] -> [è®Šæ•¸åˆ—è¡¨]\n",
    "stepwise_feature_storage = {} \n",
    "stepwise_report_list = []\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    \n",
    "    current_year = 2010 + block_id\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ§© Stepwise Selection for Block {block_id} (Year: {current_year})\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # --- 1. æ™‚é–“åºåˆ—åˆ‡åˆ† (Temporal Split) ---\n",
    "    block_df = block_df.sort_values('date')\n",
    "    split_index = int(len(block_df) * 0.8)\n",
    "    \n",
    "    train_raw = block_df.iloc[:split_index].copy()\n",
    "    test_raw  = block_df.iloc[split_index:].copy()\n",
    "\n",
    "    # --- 2. ç‰¹å¾µå·¥ç¨‹ (Anti-Leakage) ---\n",
    "    # å¿…é ˆåœ¨åˆ‡åˆ†å¾Œæ‰åš Risk è¨ˆç®—\n",
    "    try:\n",
    "        fraud_rate = train_raw.groupby('mcc_code')['is_fraud'].mean()\n",
    "        high_risk_mcc = fraud_rate[fraud_rate > 0.02].index\n",
    "        train_raw['HighRiskMCC'] = train_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "        test_raw['HighRiskMCC']  = test_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "    except:\n",
    "        pass # è‹¥ train ç©ºäº†æœƒè¢«å¾Œé¢çš„ check æ“‹ä¸‹ï¼Œé€™è£¡å¿½ç•¥\n",
    "\n",
    "    # åˆå§‹åŒ–è©²å¹´ä»½çš„å„²å­˜ç©ºé–“\n",
    "    stepwise_feature_storage[block_id] = {}\n",
    "\n",
    "    # --- 3. é‡å°æ¯å€‹ Group è·‘ Stepwise ---\n",
    "    for group_name, feature_list in feature_groups.items():\n",
    "        \n",
    "        # ç¢ºä¿ç‰¹å¾µå­˜åœ¨\n",
    "        valid_features = [f for f in feature_list if f in train_raw.columns]\n",
    "        if not valid_features:\n",
    "            continue\n",
    "            \n",
    "        print(f\"   ğŸ”¸ Group: {group_name} (Pool: {len(valid_features)})...\", end=\" \")\n",
    "\n",
    "        # åŸ·è¡Œ Stepwise\n",
    "        res = run_stepwise_logit(\n",
    "            train_raw, \n",
    "            test_raw, \n",
    "            feature_cols=valid_features,\n",
    "            threshold_in=0.01,   # é¡¯è‘—æ‰å…¥é¸\n",
    "            threshold_out=0.05   # ä¸é¡¯è‘—å°±è¸¢é™¤\n",
    "        )\n",
    "\n",
    "        # è™•ç†çµæœ\n",
    "        if res[\"status\"] == \"success\":\n",
    "            m = res[\"metrics\"]\n",
    "            selected_feats = res[\"selected_features\"]\n",
    "            \n",
    "            print(f\"âœ… Selected {len(selected_feats)} feats | Test AUC: {m['Test AUC']}\")\n",
    "            \n",
    "            # (A) å­˜è®Šæ•¸ (çµ¦å¾ŒçºŒæ¨¡å‹ç”¨)\n",
    "            stepwise_feature_storage[block_id][group_name] = selected_feats\n",
    "            \n",
    "            # (B) å­˜å ±è¡¨æ•¸æ“š\n",
    "            row = {\n",
    "                \"Year\": current_year,\n",
    "                \"Feature Group\": group_name,\n",
    "                \"Train AUC\": m[\"Train AUC\"], \"Test AUC\": m[\"Test AUC\"],\n",
    "                \"Train PR-AUC\": m[\"Train PR-AUC\"], \"Test PR-AUC\": m[\"Test PR-AUC\"],\n",
    "                \"Num Features\": m[\"Num Features\"]\n",
    "            }\n",
    "            stepwise_report_list.append(row)\n",
    "            \n",
    "        elif res[\"status\"] == \"skip\":\n",
    "            print(f\"âš ï¸ Skipped: {res['message']}\")\n",
    "            stepwise_feature_storage[block_id][group_name] = [] # å­˜ç©º list\n",
    "            # å­˜ NaN å ±è¡¨\n",
    "            row = {\n",
    "                \"Year\": current_year, \"Feature Group\": group_name,\n",
    "                \"Train AUC\": np.nan, \"Test AUC\": np.nan,\n",
    "                \"Train PR-AUC\": np.nan, \"Test PR-AUC\": np.nan,\n",
    "                \"Num Features\": 0\n",
    "            }\n",
    "            stepwise_report_list.append(row)\n",
    "            \n",
    "        else:\n",
    "            print(f\"âŒ Error: {res['message']}\")\n",
    "            stepwise_feature_storage[block_id][group_name] = []\n",
    "\n",
    "print(\"\\nğŸ‰ Stepwise Selection Completed!\")\n",
    "print(f\"è®Šæ•¸çµæœå·²å„²å­˜æ–¼ 'stepwise_feature_storage' å­—å…¸ä¸­ã€‚\")\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# 4. é¡¯ç¤º Stepwise åˆæ­¥çµæœå ±è¡¨\n",
    "# ===========================================================\n",
    "if stepwise_report_list:\n",
    "    df_sw_raw = pd.DataFrame(stepwise_report_list)\n",
    "    \n",
    "    # è½‰ç½®è¡¨æ ¼ (Pivot) ä»¥ç¬¦åˆæ‚¨ç¿’æ…£çš„æ ¼å¼\n",
    "    target_metrics = [\"Train AUC\", \"Test AUC\", \"Train PR-AUC\", \"Test PR-AUC\"]\n",
    "    df_sw_pivot = df_sw_raw.pivot(index=\"Feature Group\", columns=\"Year\", values=target_metrics)\n",
    "    \n",
    "    # èª¿æ•´æ¬„ä½é †åº\n",
    "    df_sw_pivot.columns = df_sw_pivot.columns.swaplevel(0, 1)\n",
    "    unique_years = sorted(df_sw_raw[\"Year\"].unique())\n",
    "    ordered_columns = [(y, m) for y in unique_years for m in target_metrics]\n",
    "    \n",
    "    df_sw_final = df_sw_pivot.reindex(columns=ordered_columns)\n",
    "    \n",
    "    print(\"\\n=== Stepwise Logistic Regression è®Šæ•¸ç¯©é¸æˆæ•ˆè¡¨ ===\")\n",
    "    print(df_sw_final.to_string())\n",
    "else:\n",
    "    print(\"No data to report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stepwiseè®Šæ•¸é¸å– çµæœ\n",
    "\n",
    "import pickle\n",
    "\n",
    "# 1. å„²å­˜ (Save)\n",
    "with open('stepwise_feature_storage.pkl', 'wb') as f:\n",
    "    pickle.dump(stepwise_feature_storage, f)\n",
    "\n",
    "print(\"âœ… å·²æˆåŠŸå„²å­˜ç‚º stepwise_feature_storage.pkl\")\n",
    "\n",
    "# ==========================================\n",
    "# ä¸‹æ¬¡è¦ç”¨æ™‚ï¼ŒåŸ·è¡Œé€™æ®µè®€å– (Load)\n",
    "# ==========================================\n",
    "# with open('stepwise_feature_storage.pkl', 'rb') as f:\n",
    "#     stepwise_feature_storage = pickle.load(f)\n",
    "# print(\"âœ… å·²è®€å–è®Šæ•¸è¨­å®š\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05-2_Elast Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05-3_SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06_Modeling (LR, XGB and LGBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06-1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import copy\n",
    "\n",
    "# ===========================================================\n",
    "# 1. Full Logistic Regression è¨“ç·´å‡½æ•¸\n",
    "# ===========================================================\n",
    "def fit_full_logit(train_df, test_df, feature_cols, dep_var=\"is_fraud\"):\n",
    "    \"\"\"\n",
    "    é‡å°çµ¦å®šçš„ç‰¹å¾µåˆ—è¡¨é€²è¡Œå…¨è®Šæ•¸ Logistic Regression (L2 Penalty)\n",
    "    \"\"\"\n",
    "    # æº–å‚™ X å’Œ y\n",
    "    X_train = train_df[feature_cols]\n",
    "    y_train = train_df[dep_var]\n",
    "\n",
    "    X_test = test_df[feature_cols]\n",
    "    y_test = test_df[dep_var]\n",
    "\n",
    "    # è™•ç†ç¼ºå¤±å€¼ (Sklearn ä¸æ¥å— NaN)\n",
    "    # ç°¡å–®ç­–ç•¥ï¼šå¡«è£œ 0 æˆ–åˆªé™¤ (é€™é‚Šå‡è¨­ä½ å‰é¢çš„è³‡æ–™æ¸…æ´—å·²ç¶“è™•ç†å®Œ NaNï¼Œè‹¥æœ‰æ®˜ç•™å»ºè­° fillna)\n",
    "    X_train = X_train.fillna(0)\n",
    "    X_test = X_test.fillna(0)\n",
    "\n",
    "    # 1. æ¨™æº–åŒ– (Standardization) - éå¸¸é‡è¦ï¼\n",
    "    # å¿…é ˆç”¨ Train çš„æ•¸æ“šä¾† fitï¼Œç„¶å¾Œ transform åˆ° Train å’Œ Test\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 2. è¨“ç·´æ¨¡å‹ (ä½¿ç”¨ L2 Regularization é˜²æ­¢éæ“¬åˆ)\n",
    "    model = LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=2000,  # å¢åŠ è¿­ä»£æ¬¡æ•¸é¿å…æ”¶æ–‚å¤±æ•—\n",
    "        n_jobs=-1,      # å¹³è¡Œé‹ç®—\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # 3. é æ¸¬æ©Ÿç‡\n",
    "        train_pred_prob = model.predict_proba(X_train_scaled)[:, 1]\n",
    "        test_pred_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "        # 4. è¨ˆç®—æŒ‡æ¨™\n",
    "        train_auc = roc_auc_score(y_train, train_pred_prob)\n",
    "        test_auc = roc_auc_score(y_test, test_pred_prob)\n",
    "        \n",
    "        train_prauc = average_precision_score(y_train, train_pred_prob)\n",
    "        test_prauc = average_precision_score(y_test, test_pred_prob)\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"model\": model,\n",
    "            \"scaler\": scaler,\n",
    "            \"metrics\": {\n",
    "                \"Train AUC\": round(train_auc, 4),\n",
    "                \"Test AUC\": round(test_auc, 4),\n",
    "                \"Train PR-AUC\": round(train_prauc, 4),\n",
    "                \"Test PR-AUC\": round(test_prauc, 4)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# 2. æº–å‚™ Feature Groups (ç¢ºä¿ç„¡ç›®æ¨™è®Šæ•¸èˆ‡ID)\n",
    "# ===========================================================\n",
    "# ç¢ºä¿ all_cols, rfm_cols, dk_cols å·²ç¶“å®šç¾©\n",
    "identifier = ['transaction_id', 'client_id_x', 'card_id', 'card_number', 'cvv']\n",
    "exclude_cols = set(identifier) | {'is_fraud', 'date', 'year', 'time_block'}\n",
    "\n",
    "# é€™è£¡å‡è¨­ä½ çš„ cols åˆ—è¡¨å·²ç¶“å­˜åœ¨ï¼Œåšæœ€å¾Œä¸€æ¬¡æ¸…æ´—ç¢ºä¿å®‰å…¨\n",
    "# å¦‚æœä½ ä¹‹å‰çš„ all_cols å·²ç¶“æ¸…ä¹¾æ·¨äº†ï¼Œé€™è£¡åªæ˜¯é›™é‡ä¿éšª\n",
    "def clean_cols(cols):\n",
    "    return [c for c in cols if c not in exclude_cols]\n",
    "\n",
    "feature_groups = {\n",
    "    \"X_all\": clean_cols(all_cols),\n",
    "    \"X_rfm\": clean_cols(rfm_cols),\n",
    "    \"X_dk\": clean_cols(dk_cols),\n",
    "    \"X_all + X_rfm\": clean_cols(all_cols + rfm_cols),\n",
    "    \"X_all + X_dk\": clean_cols(all_cols + dk_cols),\n",
    "    \"X_rfm + X_dk\": clean_cols(rfm_cols + dk_cols),\n",
    "    \"X_all + X_rfm + X_dk\": clean_cols(all_cols + rfm_cols + dk_cols)\n",
    "}\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# 3. ä¸»è¿´åœˆ (Block + Feature Groups)\n",
    "# ===========================================================\n",
    "full_logit_results = {}\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ğŸš€ Running Full Logit for Block {block_id} (Year: {2010 + block_id*2})\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # --- è³‡æ–™åˆ‡åˆ† (Split) ---\n",
    "    block_df = block_df.sort_values('date')\n",
    "    split_index = int(len(block_df) * 0.8)\n",
    "    \n",
    "    train_raw = block_df.iloc[:split_index].copy()\n",
    "    test_raw  = block_df.iloc[split_index:].copy()\n",
    "\n",
    "    # --- é‡ç®— HighRiskMCC (Anti-Leakage) ---\n",
    "    fraud_rate = train_raw.groupby('mcc_code')['is_fraud'].mean()\n",
    "    high_risk_mcc = fraud_rate[fraud_rate > 0.02].index\n",
    "    \n",
    "    train_raw['HighRiskMCC'] = train_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "    test_raw['HighRiskMCC']  = test_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "\n",
    "    # åˆå§‹åŒ–çµæœå­˜æ”¾\n",
    "    full_logit_results[block_id] = {}\n",
    "\n",
    "    # --- é‡å°æ¯å€‹ Feature Group è·‘æ¨¡å‹ ---\n",
    "    for group_name, feature_list in feature_groups.items():\n",
    "        \n",
    "        # ç¢ºä¿ç‰¹å¾µå­˜åœ¨æ–¼ DataFrame\n",
    "        valid_features = [f for f in feature_list if f in train_raw.columns]\n",
    "        \n",
    "        # ç°¡å–®æª¢æŸ¥ï¼šè‹¥ç‰¹å¾µå°‘æ–¼ 1 å€‹å°±è·³é\n",
    "        if not valid_features:\n",
    "            print(f\"   âš ï¸ Group: {group_name} - No valid features found. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"   ğŸ”¹ Group: {group_name} ({len(valid_features)} features)...\", end=\" \")\n",
    "\n",
    "        # åŸ·è¡Œ Full Logistic Regression\n",
    "        res = fit_full_logit(\n",
    "            train_raw, \n",
    "            test_raw, \n",
    "            feature_cols=valid_features, \n",
    "            dep_var=\"is_fraud\"\n",
    "        )\n",
    "\n",
    "        if res[\"status\"] == \"success\":\n",
    "            metrics = res[\"metrics\"]\n",
    "            print(f\"âœ… Done.\")\n",
    "            print(f\"      Train AUC: {metrics['Train AUC']} | Test AUC: {metrics['Test AUC']}\")\n",
    "            print(f\"      Train PR : {metrics['Train PR-AUC']} | Test PR : {metrics['Test PR-AUC']}\")\n",
    "            \n",
    "            # å„²å­˜çµæœ\n",
    "            full_logit_results[block_id][group_name] = metrics\n",
    "        else:\n",
    "            print(f\"âŒ Error: {res['message']}\")\n",
    "            full_logit_results[block_id][group_name] = {\"error\": res['message']}\n",
    "\n",
    "print(\"\\nğŸ‰ All Full Logistic Regression models completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Traing AUC ç¸¾æ•ˆçŸ©é™£ (æ•¸å€¼è¶Šé«˜è¶Šå¥½) ===\n",
      "Year                    2010    2011    2012    2013    2014    2015    2016  \\\n",
      "Feature Group                                                                  \n",
      "X_all                 0.9534  0.9675  0.8455  0.9233  0.9153  0.9198  0.9169   \n",
      "X_all + X_dk          0.9767  0.9797  0.8389  0.9118  0.9068  0.9135  0.9171   \n",
      "X_all + X_rfm         0.9599  0.9696  0.8888  0.9417  0.9281  0.9377  0.9329   \n",
      "X_all + X_rfm + X_dk  0.9798  0.9843  0.8904  0.9442  0.9152  0.9370  0.9313   \n",
      "X_dk                  0.9716  0.9631  0.8086  0.8760  0.8708  0.8684  0.8722   \n",
      "X_rfm                 0.6884  0.7059  0.7156  0.7735  0.7351  0.7469  0.7122   \n",
      "X_rfm + X_dk          0.9778  0.9743  0.8904  0.9315  0.9214  0.9179  0.9150   \n",
      "\n",
      "Year                    2018    2019  \n",
      "Feature Group                         \n",
      "X_all                 0.9799  0.9780  \n",
      "X_all + X_dk          0.9992  0.9991  \n",
      "X_all + X_rfm         0.9821  0.9806  \n",
      "X_all + X_rfm + X_dk  0.9994  0.9992  \n",
      "X_dk                  0.9987  0.9986  \n",
      "X_rfm                 0.7378  0.6992  \n",
      "X_rfm + X_dk          0.9991  0.9990  \n",
      "\n",
      "=== Test AUC ç¸¾æ•ˆçŸ©é™£ (æ•¸å€¼è¶Šé«˜è¶Šå¥½) ===\n",
      "Year                    2010  2011  2012    2013  2014    2015    2016  \\\n",
      "Feature Group                                                            \n",
      "X_all                 0.9517   NaN   NaN  0.8888   NaN  0.9051  0.9187   \n",
      "X_all + X_dk          0.9773   NaN   NaN  0.8791   NaN  0.9005  0.9136   \n",
      "X_all + X_rfm         0.9617   NaN   NaN  0.9216   NaN  0.9248  0.9401   \n",
      "X_all + X_rfm + X_dk  0.9815   NaN   NaN  0.9241   NaN  0.9242  0.9358   \n",
      "X_dk                  0.9736   NaN   NaN  0.8624   NaN  0.8624  0.8718   \n",
      "X_rfm                 0.7442   NaN   NaN  0.7569   NaN  0.7450  0.7321   \n",
      "X_rfm + X_dk          0.9807   NaN   NaN  0.9187   NaN  0.9029  0.9253   \n",
      "\n",
      "Year                    2018    2019  \n",
      "Feature Group                         \n",
      "X_all                 0.8625  0.9663  \n",
      "X_all + X_dk          0.8844  0.9987  \n",
      "X_all + X_rfm         0.8765  0.9726  \n",
      "X_all + X_rfm + X_dk  0.8811  0.9989  \n",
      "X_dk                  0.8773  0.9987  \n",
      "X_rfm                 0.7232  0.7151  \n",
      "X_rfm + X_dk          0.8410  0.9991  \n",
      "\n",
      "=== Traing PR-AUC ç¸¾æ•ˆçŸ©é™£ (æ•¸å€¼è¶Šé«˜è¶Šå¥½) ===\n",
      "Year                    2010    2011    2012    2013    2014    2015    2016  \\\n",
      "Feature Group                                                                  \n",
      "X_all                 0.0572  0.0025  0.0137  0.0390  0.0273  0.0664  0.0583   \n",
      "X_all + X_dk          0.1600  0.0306  0.0504  0.0984  0.0871  0.1516  0.1263   \n",
      "X_all + X_rfm         0.0851  0.0048  0.0283  0.1040  0.0631  0.1265  0.0973   \n",
      "X_all + X_rfm + X_dk  0.2039  0.0387  0.0782  0.1693  0.1209  0.2258  0.1890   \n",
      "X_dk                  0.1047  0.0279  0.0413  0.0612  0.0506  0.1043  0.0592   \n",
      "X_rfm                 0.0098  0.0005  0.0040  0.0065  0.0060  0.0100  0.0092   \n",
      "X_rfm + X_dk          0.1357  0.0376  0.0708  0.1369  0.1213  0.1797  0.1265   \n",
      "\n",
      "Year                    2018    2019  \n",
      "Feature Group                         \n",
      "X_all                 0.0973  0.1021  \n",
      "X_all + X_dk          0.6903  0.6695  \n",
      "X_all + X_rfm         0.1327  0.1200  \n",
      "X_all + X_rfm + X_dk  0.7514  0.7355  \n",
      "X_dk                  0.4696  0.4762  \n",
      "X_rfm                 0.0058  0.0051  \n",
      "X_rfm + X_dk          0.6366  0.6323  \n",
      "\n",
      "=== Test PR-AUC ç¸¾æ•ˆçŸ©é™£ (æ•¸å€¼è¶Šé«˜è¶Šå¥½) ===\n",
      "Year                    2010  2011  2012    2013  2014    2015    2016  \\\n",
      "Feature Group                                                            \n",
      "X_all                 0.0524   0.0   0.0  0.0401   0.0  0.0890  0.0518   \n",
      "X_all + X_dk          0.1842   0.0   0.0  0.1195   0.0  0.1755  0.1360   \n",
      "X_all + X_rfm         0.1219   0.0   0.0  0.1241   0.0  0.1728  0.0693   \n",
      "X_all + X_rfm + X_dk  0.2456   0.0   0.0  0.2311   0.0  0.2693  0.1817   \n",
      "X_dk                  0.1060   0.0   0.0  0.0956   0.0  0.1276  0.0439   \n",
      "X_rfm                 0.0260   0.0   0.0  0.0144   0.0  0.0176  0.0107   \n",
      "X_rfm + X_dk          0.2014   0.0   0.0  0.2195   0.0  0.2564  0.1114   \n",
      "\n",
      "Year                    2018    2019  \n",
      "Feature Group                         \n",
      "X_all                 0.1000  0.0848  \n",
      "X_all + X_dk          0.5339  0.5675  \n",
      "X_all + X_rfm         0.1209  0.0903  \n",
      "X_all + X_rfm + X_dk  0.5886  0.6368  \n",
      "X_dk                  0.4291  0.4819  \n",
      "X_rfm                 0.0077  0.0045  \n",
      "X_rfm + X_dk          0.5191  0.6342  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==========================================\n",
    "# 1. å°‡å·¢ç‹€å­—å…¸è½‰ç‚º DataFrame\n",
    "# ==========================================\n",
    "data_list = []\n",
    "\n",
    "for block_id, groups in full_logit_results.items():\n",
    "    for group_name, metrics in groups.items():\n",
    "        # æ’é™¤ç™¼ç”ŸéŒ¯èª¤çš„çµ„åˆ¥\n",
    "        if \"error\" in metrics:\n",
    "            continue\n",
    "            \n",
    "        row = {\n",
    "            \"Block\": block_id,\n",
    "            \"Year\": f\"{2010 + block_id}\",\n",
    "            \"Feature Group\": group_name,\n",
    "            \"Train AUC\": metrics.get(\"Train AUC\"),\n",
    "            \"Test AUC\": metrics.get(\"Test AUC\"),\n",
    "            \"Train PR-AUC\": metrics.get(\"Train PR-AUC\"),\n",
    "            \"Test PR-AUC\": metrics.get(\"Test PR-AUC\")\n",
    "        }\n",
    "        data_list.append(row)\n",
    "\n",
    "df_results = pd.DataFrame(data_list)\n",
    "\n",
    "# èª¿æ•´æ¬„ä½é †åº\n",
    "cols = [\"Block\", \"Year\", \"Feature Group\", \"Train AUC\", \"Test AUC\", \"Train PR-AUC\", \"Test PR-AUC\"]\n",
    "df_results = df_results[cols]\n",
    "\n",
    "# é¡¯ç¤ºå‰å¹¾ç­†\n",
    "#print(\"=== è©³ç´°çµæœç¸½è¡¨ (å‰ 5 ç­†) ===\")\n",
    "#print(df_results.head())\n",
    "\n",
    "# ==========================================\n",
    "# 2. è£½ä½œ Test AUC æ¯”è¼ƒçŸ©é™£ (Pivot Table)\n",
    "# ==========================================\n",
    "# é€™æ˜¯æœ€ç›´è§€çš„è¡¨æ ¼ï¼šæ©«è»¸æ˜¯æ™‚é–“ï¼Œç¸±è»¸æ˜¯ç‰¹å¾µç¾¤çµ„ï¼Œæ•¸å€¼æ˜¯ Test AUC\n",
    "train_auc = df_results.pivot(index=\"Feature Group\", columns=\"Year\", values=\"Train AUC\")\n",
    "test_auc = df_results.pivot(index=\"Feature Group\", columns=\"Year\", values=\"Test AUC\")\n",
    "train_prauc = df_results.pivot(index=\"Feature Group\", columns=\"Year\", values=\"Train PR-AUC\")\n",
    "test_prauc = df_results.pivot(index=\"Feature Group\", columns=\"Year\", values=\"Test PR-AUC\")\n",
    "\n",
    "\n",
    "print(\"\\n=== Traing AUC ç¸¾æ•ˆçŸ©é™£ (æ•¸å€¼è¶Šé«˜è¶Šå¥½) ===\")\n",
    "print(train_auc)\n",
    "print(\"\\n=== Test AUC ç¸¾æ•ˆçŸ©é™£ (æ•¸å€¼è¶Šé«˜è¶Šå¥½) ===\")\n",
    "print(test_auc)\n",
    "print(\"\\n=== Traing PR-AUC ç¸¾æ•ˆçŸ©é™£ (æ•¸å€¼è¶Šé«˜è¶Šå¥½) ===\")\n",
    "print(train_prauc)\n",
    "print(\"\\n=== Test PR-AUC ç¸¾æ•ˆçŸ©é™£ (æ•¸å€¼è¶Šé«˜è¶Šå¥½) ===\")\n",
    "print(test_prauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æ•´åˆçµæœç¸½è¡¨ ===\n",
      "Year                      2010                                        2011                                        2012                                        2013                                        2014                                        2015                                        2016                                        2018                                        2019                                  \n",
      "                     Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC\n",
      "Feature Group                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "X_all                   0.9534   0.9517       0.0572      0.0524    0.9675      NaN       0.0025         0.0    0.8455      NaN       0.0137         0.0    0.9233   0.8888       0.0390      0.0401    0.9153      NaN       0.0273         0.0    0.9198   0.9051       0.0664      0.0890    0.9169   0.9187       0.0583      0.0518    0.9799   0.8625       0.0973      0.1000    0.9780   0.9663       0.1021      0.0848\n",
      "X_all + X_dk            0.9767   0.9773       0.1600      0.1842    0.9797      NaN       0.0306         0.0    0.8389      NaN       0.0504         0.0    0.9118   0.8791       0.0984      0.1195    0.9068      NaN       0.0871         0.0    0.9135   0.9005       0.1516      0.1755    0.9171   0.9136       0.1263      0.1360    0.9992   0.8844       0.6903      0.5339    0.9991   0.9987       0.6695      0.5675\n",
      "X_all + X_rfm           0.9599   0.9617       0.0851      0.1219    0.9696      NaN       0.0048         0.0    0.8888      NaN       0.0283         0.0    0.9417   0.9216       0.1040      0.1241    0.9281      NaN       0.0631         0.0    0.9377   0.9248       0.1265      0.1728    0.9329   0.9401       0.0973      0.0693    0.9821   0.8765       0.1327      0.1209    0.9806   0.9726       0.1200      0.0903\n",
      "X_all + X_rfm + X_dk    0.9798   0.9815       0.2039      0.2456    0.9843      NaN       0.0387         0.0    0.8904      NaN       0.0782         0.0    0.9442   0.9241       0.1693      0.2311    0.9152      NaN       0.1209         0.0    0.9370   0.9242       0.2258      0.2693    0.9313   0.9358       0.1890      0.1817    0.9994   0.8811       0.7514      0.5886    0.9992   0.9989       0.7355      0.6368\n",
      "X_dk                    0.9716   0.9736       0.1047      0.1060    0.9631      NaN       0.0279         0.0    0.8086      NaN       0.0413         0.0    0.8760   0.8624       0.0612      0.0956    0.8708      NaN       0.0506         0.0    0.8684   0.8624       0.1043      0.1276    0.8722   0.8718       0.0592      0.0439    0.9987   0.8773       0.4696      0.4291    0.9986   0.9987       0.4762      0.4819\n",
      "X_rfm                   0.6884   0.7442       0.0098      0.0260    0.7059      NaN       0.0005         0.0    0.7156      NaN       0.0040         0.0    0.7735   0.7569       0.0065      0.0144    0.7351      NaN       0.0060         0.0    0.7469   0.7450       0.0100      0.0176    0.7122   0.7321       0.0092      0.0107    0.7378   0.7232       0.0058      0.0077    0.6992   0.7151       0.0051      0.0045\n",
      "X_rfm + X_dk            0.9778   0.9807       0.1357      0.2014    0.9743      NaN       0.0376         0.0    0.8904      NaN       0.0708         0.0    0.9315   0.9187       0.1369      0.2195    0.9214      NaN       0.1213         0.0    0.9179   0.9029       0.1797      0.2564    0.9150   0.9253       0.1265      0.1114    0.9991   0.8410       0.6366      0.5191    0.9990   0.9991       0.6323      0.6342\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 2. è£½ä½œæ•´åˆå¤§è¡¨ (Hierarchical Columns)\n",
    "# ==========================================\n",
    "\n",
    "# 1. è¨­å®šè¦è½‰ç½®çš„æ‰€æœ‰æŒ‡æ¨™\n",
    "metrics = [\"Train AUC\", \"Test AUC\", \"Train PR-AUC\", \"Test PR-AUC\"]\n",
    "\n",
    "# 2. ä½¿ç”¨ pivot ä¸€æ¬¡è™•ç†å¤šå€‹ values\n",
    "# é€™æœƒç”¢ç”Ÿä¸€å€‹ MultiIndexï¼Œç¬¬ä¸€å±¤æ˜¯æŒ‡æ¨™ (Metric)ï¼Œç¬¬äºŒå±¤æ˜¯å¹´ä»½ (Year)\n",
    "df_pivot = df_results.pivot(index=\"Feature Group\", columns=\"Year\", values=metrics)\n",
    "\n",
    "# 3. äº¤æ›æ¬„ä½å±¤ç´šï¼šå°‡ã€Œå¹´ä»½ã€ç§»åˆ°æœ€ä¸Šå±¤ï¼ŒæŒ‡æ¨™ç§»åˆ°ç¬¬äºŒå±¤\n",
    "df_pivot.columns = df_pivot.columns.swaplevel(0, 1)\n",
    "\n",
    "# 4. (é¸æ“‡æ€§) æ’åºæ¬„ä½\n",
    "# å¦‚æœç›´æ¥ sort_indexï¼Œæ¬„ä½æœƒä¾ç…§å­—æ¯æ’åº (Test æœƒè·‘å» Train å‰é¢)\n",
    "# ç‚ºäº†è·Ÿä½ çš„æˆªåœ–ä¸€æ¨£ (Train -> Test)ï¼Œæˆ‘å€‘éœ€è¦è‡ªå®šç¾©æ’åº\n",
    "unique_years = sorted(df_results[\"Year\"].unique())\n",
    "ordered_columns = []\n",
    "\n",
    "for year in unique_years:\n",
    "    for metric in metrics:\n",
    "        # å»ºç«‹ (Year, Metric) çš„ tuple åˆ—è¡¨\n",
    "        ordered_columns.append((year, metric))\n",
    "\n",
    "# æ ¹æ“šæˆ‘å€‘æƒ³è¦çš„é †åºé‡æ–°ç´¢å¼•\n",
    "df_final = df_pivot.reindex(columns=ordered_columns)\n",
    "\n",
    "print(\"=== æ•´åˆçµæœç¸½è¡¨ ===\")\n",
    "# å¦‚æœä½ åœ¨ Jupyter Notebookï¼Œç›´æ¥è¼¸å…¥ df_final å³å¯çœ‹åˆ°æ¼‚äº®è¡¨æ ¼\n",
    "# å¦‚æœæ˜¯ç´”æ–‡å­—ä»‹é¢ï¼Œç”¨ to_string() æ¯”è¼ƒæ¸…æ¥š\n",
    "print(df_final.to_string())\n",
    "\n",
    "# ç°¡å–®çš„åŒ¯å‡º csv æª¢æŸ¥ (é€šå¸¸ Excel æ‰“é–‹å°±æœƒæœ‰é›™å±¤æ¨™é ­)\n",
    "df_final.to_csv(\"logit_results_wide.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 0 (Year: 2010)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 11 features)... âœ… Test AUC: 0.9514\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 features)... âœ… Test AUC: 0.7362\n",
      "   ğŸ”¹ Group: X_dk (Using 4 features)... âœ… Test AUC: 0.9654\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 15 features)... âœ… Test AUC: 0.962\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 13 features)... âœ… Test AUC: 0.9082\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 7 features)... âœ… Test AUC: 0.9289\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 16 features)... âœ… Test AUC: 0.9781\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 1 (Year: 2011)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 2 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm (Using 1 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_dk (Using 2 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 7 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 3 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 5 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 7 features)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 2 (Year: 2012)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 6 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_dk (Using 1 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 8 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 7 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 4 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 14 features)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 3 (Year: 2013)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 10 features)... âœ… Test AUC: 0.883\n",
      "   ğŸ”¹ Group: X_rfm (Using 5 features)... âœ… Test AUC: 0.7536\n",
      "   ğŸ”¹ Group: X_dk (Using 3 features)... âœ… Test AUC: 0.8517\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 14 features)... âœ… Test AUC: 0.923\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 14 features)... âœ… Test AUC: 0.8761\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 8 features)... âœ… Test AUC: 0.9143\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 16 features)... âœ… Test AUC: 0.9147\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 4 (Year: 2014)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 14 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_dk (Using 3 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 16 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 14 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 6 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 18 features)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 5 (Year: 2015)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 14 features)... âœ… Test AUC: 0.906\n",
      "   ğŸ”¹ Group: X_rfm (Using 5 features)... âœ… Test AUC: 0.7449\n",
      "   ğŸ”¹ Group: X_dk (Using 2 features)... âœ… Test AUC: 0.8461\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 19 features)... âœ… Test AUC: 0.9229\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 14 features)... âœ… Test AUC: 0.8931\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 7 features)... âœ… Test AUC: 0.8954\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 23 features)... âœ… Test AUC: 0.9182\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 6 (Year: 2016)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 12 features)... âœ… Test AUC: 0.9176\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 features)... âœ… Test AUC: 0.7342\n",
      "   ğŸ”¹ Group: X_dk (Using 2 features)... âœ… Test AUC: 0.8589\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 14 features)... âœ… Test AUC: 0.9399\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 15 features)... âœ… Test AUC: 0.9096\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 6 features)... âœ… Test AUC: 0.9208\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 14 features)... âœ… Test AUC: 0.9323\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 7 (Year: 2017)\n",
      "============================================================\n",
      "   âš ï¸ Group: X_all - Skipped (No Stepwise features)\n",
      "   âš ï¸ Group: X_rfm - Skipped (No Stepwise features)\n",
      "   âš ï¸ Group: X_dk - Skipped (No Stepwise features)\n",
      "   âš ï¸ Group: X_all + X_rfm - Skipped (No Stepwise features)\n",
      "   âš ï¸ Group: X_all + X_dk - Skipped (No Stepwise features)\n",
      "   âš ï¸ Group: X_rfm + X_dk - Skipped (No Stepwise features)\n",
      "   âš ï¸ Group: X_all + X_rfm + X_dk - Skipped (No Stepwise features)\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 8 (Year: 2018)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 14 features)... âœ… Test AUC: 0.9004\n",
      "   ğŸ”¹ Group: X_rfm (Using 5 features)... âœ… Test AUC: 0.7217\n",
      "   ğŸ”¹ Group: X_dk (Using 3 features)... âœ… Test AUC: 0.9158\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 18 features)... âœ… Test AUC: 0.9161\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 14 features)... âœ… Test AUC: 0.9051\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 7 features)... âœ… Test AUC: 0.8341\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 14 features)... âœ… Test AUC: 0.9497\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 9 (Year: 2019)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 15 features)... âœ… Test AUC: 0.9594\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 features)... âœ… Test AUC: 0.7191\n",
      "   ğŸ”¹ Group: X_dk (Using 2 features)... âœ… Test AUC: 0.7503\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 18 features)... âœ… Test AUC: 0.9677\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 17 features)... âœ… Test AUC: 0.9746\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 7 features)... âœ… Test AUC: 0.8867\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 21 features)... âœ… Test AUC: 0.9743\n",
      "\n",
      "ğŸ‰ All Logistic Regression (Stepwise) models completed!\n",
      "\n",
      "=== Logistic Regression Performance (Using Stepwise Selected Features) ===\n",
      "Year                      2010                                        2011                                        2012                                        2013                                        2014                                        2015                                        2016                                        2017                                        2018                                        2019                                  \n",
      "                     Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC\n",
      "Feature Group                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "X_all                   0.9535   0.9514       0.0536      0.0525    0.9418      NaN       0.0022         NaN    0.8426      NaN       0.0133         NaN    0.9207   0.8830       0.0350      0.0417    0.9158      NaN       0.0283         NaN    0.9204   0.9060       0.0659      0.0823    0.9183   0.9176       0.0565      0.0461       NaN      NaN          NaN         NaN    0.9703   0.9004       0.0832      0.0885    0.9651   0.9594       0.0924      0.0783\n",
      "X_all + X_dk            0.8994   0.9082       0.0421      0.0512    0.9475      NaN       0.0057         NaN    0.8312      NaN       0.0151         NaN    0.9070   0.8761       0.0560      0.0644    0.9049      NaN       0.0487         NaN    0.9079   0.8931       0.1098      0.1287    0.9120   0.9096       0.0804      0.0821       NaN      NaN          NaN         NaN    0.9733   0.9051       0.1682      0.1636    0.9834   0.9746       0.2046      0.1484\n",
      "X_all + X_rfm           0.9600   0.9620       0.0789      0.1269    0.9524      NaN       0.0072         NaN    0.8856      NaN       0.0256         NaN    0.9410   0.9230       0.1010      0.1215    0.9283      NaN       0.0732         NaN    0.9372   0.9229       0.1273      0.1622    0.9323   0.9399       0.0892      0.0651       NaN      NaN          NaN         NaN    0.9758   0.9161       0.1172      0.1084    0.9727   0.9677       0.1070      0.0851\n",
      "X_all + X_rfm + X_dk    0.9740   0.9781       0.1347      0.2050    0.9524      NaN       0.0207         NaN    0.8814      NaN       0.0319         NaN    0.9344   0.9147       0.1403      0.1877    0.9241      NaN       0.1544         NaN    0.9319   0.9182       0.1661      0.2265    0.9263   0.9323       0.1343      0.1141       NaN      NaN          NaN         NaN    0.9993   0.9497       0.7164      0.5932    0.9770   0.9743       0.2286      0.1681\n",
      "X_dk                    0.9612   0.9654       0.0565      0.0584    0.9285      NaN       0.0008         NaN    0.8200      NaN       0.0069         NaN    0.8606   0.8517       0.0129      0.0296    0.8576      NaN       0.0101         NaN    0.8533   0.8461       0.0184      0.0333    0.8551   0.8589       0.0221      0.0174       NaN      NaN          NaN         NaN    0.9435   0.9158       0.0473      0.0338    0.7623   0.7503       0.0114      0.0108\n",
      "X_rfm                   0.6898   0.7362       0.0097      0.0262    0.5822      NaN       0.0005         NaN    0.7159      NaN       0.0040         NaN    0.7727   0.7536       0.0065      0.0150    0.7437      NaN       0.0057         NaN    0.7473   0.7449       0.0100      0.0176    0.7117   0.7342       0.0093      0.0116       NaN      NaN          NaN         NaN    0.7359   0.7217       0.0059      0.0077    0.7029   0.7191       0.0052      0.0048\n",
      "X_rfm + X_dk            0.9367   0.9289       0.0772      0.1778    0.9427      NaN       0.0055         NaN    0.8855      NaN       0.0278         NaN    0.9249   0.9143       0.0771      0.1602    0.9137      NaN       0.0831         NaN    0.9112   0.8954       0.0979      0.1577    0.9092   0.9208       0.0940      0.0760       NaN      NaN          NaN         NaN    0.8527   0.8341       0.0253      0.0239    0.8883   0.8867       0.0304      0.0320\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# ===========================================================\n",
    "# 0. è¼”åŠ©æª¢æŸ¥å‡½æ•¸ (è·Ÿä¹‹å‰ä¸€æ¨£)\n",
    "# ===========================================================\n",
    "def check_data_validity(y_data, stage=\"Train\"):\n",
    "    if len(y_data) == 0:\n",
    "        return False, f\"{stage} set is empty\"\n",
    "    if y_data.nunique() < 2:\n",
    "        val = y_data.iloc[0] if len(y_data) > 0 else \"None\"\n",
    "        return False, f\"{stage} set has only 1 class (value: {val})\"\n",
    "    return True, \"\"\n",
    "\n",
    "# ===========================================================\n",
    "# 1. å¢å¼·ç‰ˆ Logistic Regression è¨“ç·´å‡½æ•¸ (å«é˜²å‘†)\n",
    "# ===========================================================\n",
    "def fit_stepwise_logit(train_df, test_df, feature_cols, dep_var=\"is_fraud\"):\n",
    "    \"\"\"\n",
    "    é‡å° Stepwise ç¯©é¸å¾Œçš„è®Šæ•¸è·‘ Logistic Regression\n",
    "    \"\"\"\n",
    "    X_train = train_df[feature_cols]\n",
    "    y_train = train_df[dep_var]\n",
    "    X_test  = test_df[feature_cols]\n",
    "    y_test  = test_df[dep_var]\n",
    "\n",
    "    # --- 1. é˜²å´©æ½°æª¢æŸ¥ ---\n",
    "    is_valid_train, msg_train = check_data_validity(y_train, \"Train\")\n",
    "    if not is_valid_train:\n",
    "        return {\"status\": \"skip\", \"message\": msg_train}\n",
    "\n",
    "    is_valid_test, _ = check_data_validity(y_test, \"Test\")\n",
    "\n",
    "    # --- 2. ç¼ºå¤±å€¼è™•ç† ---\n",
    "    # é›–ç„¶ Stepwise éšæ®µå¯èƒ½è™•ç†éï¼Œä½†é˜²è¬ä¸€\n",
    "    X_train = X_train.fillna(0)\n",
    "    X_test  = X_test.fillna(0)\n",
    "\n",
    "    # --- 3. æ¨™æº–åŒ– (Logistic Regression å¿…å‚™) ---\n",
    "    try:\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled  = scaler.transform(X_test)\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": f\"Scaling error: {str(e)}\"}\n",
    "\n",
    "    # --- 4. è¨“ç·´æ¨¡å‹ ---\n",
    "    model = LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=2000,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # --- 5. è¨ˆç®—æŒ‡æ¨™ ---\n",
    "        train_prob = model.predict_proba(X_train_scaled)[:, 1]\n",
    "        train_auc  = roc_auc_score(y_train, train_prob)\n",
    "        train_pr   = average_precision_score(y_train, train_prob)\n",
    "        \n",
    "        test_auc = np.nan\n",
    "        test_pr  = np.nan\n",
    "        \n",
    "        if is_valid_test:\n",
    "            try:\n",
    "                test_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "                test_auc  = roc_auc_score(y_test, test_prob)\n",
    "                test_pr   = average_precision_score(y_test, test_prob)\n",
    "            except:\n",
    "                pass # ä¿æŒ NaN\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"model\": model,\n",
    "            \"metrics\": {\n",
    "                \"Train AUC\": round(train_auc, 4),\n",
    "                \"Test AUC\": round(test_auc, 4) if not np.isnan(test_auc) else np.nan,\n",
    "                \"Train PR-AUC\": round(train_pr, 4),\n",
    "                \"Test PR-AUC\": round(test_pr, 4) if not np.isnan(test_pr) else np.nan\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "# ===========================================================\n",
    "# 2. ä¸»è¿´åœˆ (Stepwise Storage -> Logistic Regression)\n",
    "# ===========================================================\n",
    "\n",
    "# ç¢ºä¿å¿…è¦è®Šæ•¸å­˜åœ¨\n",
    "if 'stepwise_feature_storage' not in locals():\n",
    "    raise ValueError(\"âš ï¸ è«‹å…ˆåŸ·è¡Œ Stepwise ç¯©é¸ï¼Œå–å¾— stepwise_feature_storageï¼\")\n",
    "\n",
    "logit_stepwise_results = []\n",
    "\n",
    "# é€™è£¡æˆ‘å€‘éœ€è¦ group names ä¾†éæ­·å­—å…¸\n",
    "group_names = feature_groups.keys()\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    \n",
    "    current_year = 2010 + block_id\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ“Š Running Logit (Stepwise Feats) for Block {block_id} (Year: {current_year})\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # --- è³‡æ–™åˆ‡åˆ† (Split) ---\n",
    "    block_df = block_df.sort_values('date')\n",
    "    split_index = int(len(block_df) * 0.8)\n",
    "    \n",
    "    train_raw = block_df.iloc[:split_index].copy()\n",
    "    test_raw  = block_df.iloc[split_index:].copy()\n",
    "\n",
    "    # --- ç‰¹å¾µå·¥ç¨‹ (Anti-Leakage) ---\n",
    "    # å¿…é ˆåšï¼å› ç‚º Stepwise é¸å‡ºçš„è®Šæ•¸è£¡å¯èƒ½åŒ…å« HighRiskMCC\n",
    "    try:\n",
    "        fraud_rate = train_raw.groupby('mcc_code')['is_fraud'].mean()\n",
    "        high_risk_mcc = fraud_rate[fraud_rate > 0.02].index\n",
    "        train_raw['HighRiskMCC'] = train_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "        test_raw['HighRiskMCC']  = test_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # --- è®€å–è©²å¹´ä»½ Stepwise çµæœ ---\n",
    "    block_feats_dict = stepwise_feature_storage.get(block_id, {})\n",
    "\n",
    "    # --- é‡å°æ¯å€‹ Group è·‘æ¨¡å‹ ---\n",
    "    for group_name in group_names:\n",
    "        \n",
    "        # â˜… é—œéµï¼šå¾å­—å…¸å–å‡ºã€Œè©²å¹´ä»½ã€è©²ç¾¤çµ„ã€è¢« Stepwise é¸ä¸­çš„è®Šæ•¸\n",
    "        my_features = block_feats_dict.get(group_name, [])\n",
    "        \n",
    "        # æƒ…æ³ A: Stepwise æ²’é¸å‡ºä»»ä½•è®Šæ•¸ (æˆ–ç©ºé›†åˆ)\n",
    "        if not my_features:\n",
    "            print(f\"   âš ï¸ Group: {group_name} - Skipped (No Stepwise features)\")\n",
    "            logit_stepwise_results.append({\n",
    "                \"Year\": current_year, \"Feature Group\": group_name,\n",
    "                \"Train AUC\": np.nan, \"Test AUC\": np.nan,\n",
    "                \"Train PR-AUC\": np.nan, \"Test PR-AUC\": np.nan,\n",
    "                \"Num Features\": 0\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        print(f\"   ğŸ”¹ Group: {group_name} (Using {len(my_features)} features)...\", end=\" \")\n",
    "\n",
    "        # æƒ…æ³ B: åŸ·è¡Œ Logistic Regression\n",
    "        res = fit_stepwise_logit(\n",
    "            train_raw, \n",
    "            test_raw, \n",
    "            feature_cols=my_features, # <--- ä½¿ç”¨ Stepwise é¸å‡ºçš„è®Šæ•¸\n",
    "            dep_var=\"is_fraud\"\n",
    "        )\n",
    "\n",
    "        if res[\"status\"] == \"success\":\n",
    "            m = res[\"metrics\"]\n",
    "            print(f\"âœ… Test AUC: {m.get('Test AUC', np.nan)}\")\n",
    "            \n",
    "            logit_stepwise_results.append({\n",
    "                \"Year\": current_year,\n",
    "                \"Feature Group\": group_name,\n",
    "                \"Train AUC\": m.get(\"Train AUC\"),\n",
    "                \"Test AUC\": m.get(\"Test AUC\"),\n",
    "                \"Train PR-AUC\": m.get(\"Train PR-AUC\"),\n",
    "                \"Test PR-AUC\": m.get(\"Test PR-AUC\"),\n",
    "                \"Num Features\": len(my_features)\n",
    "            })\n",
    "            \n",
    "        elif res[\"status\"] == \"skip\":\n",
    "            print(f\"âš ï¸ Skipped: {res['message']}\")\n",
    "            logit_stepwise_results.append({\n",
    "                \"Year\": current_year, \"Feature Group\": group_name,\n",
    "                \"Train AUC\": np.nan, \"Test AUC\": np.nan,\n",
    "                \"Train PR-AUC\": np.nan, \"Test PR-AUC\": np.nan,\n",
    "                \"Num Features\": len(my_features)\n",
    "            })\n",
    "            \n",
    "        else:\n",
    "            print(f\"âŒ Error: {res['message']}\")\n",
    "\n",
    "print(\"\\nğŸ‰ All Logistic Regression (Stepwise) models completed!\")\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# 3. ç”¢å‡ºå ±è¡¨\n",
    "# ===========================================================\n",
    "if logit_stepwise_results:\n",
    "    df_logit_raw = pd.DataFrame(logit_stepwise_results)\n",
    "    \n",
    "    # Pivot è½‰ç½®\n",
    "    target_metrics = [\"Train AUC\", \"Test AUC\", \"Train PR-AUC\", \"Test PR-AUC\"]\n",
    "    df_logit_pivot = df_logit_raw.pivot(index=\"Feature Group\", columns=\"Year\", values=target_metrics)\n",
    "    \n",
    "    # èª¿æ•´æ¬„ä½é †åº\n",
    "    df_logit_pivot.columns = df_logit_pivot.columns.swaplevel(0, 1)\n",
    "    unique_years = sorted(df_logit_raw[\"Year\"].unique())\n",
    "    ordered_columns = [(y, m) for y in unique_years for m in target_metrics]\n",
    "    \n",
    "    df_logit_final = df_logit_pivot.reindex(columns=ordered_columns)\n",
    "    \n",
    "    print(\"\\n=== Logistic Regression Performance (Using Stepwise Selected Features) ===\")\n",
    "    print(df_logit_final.to_string())\n",
    "else:\n",
    "    print(\"No results generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logit_final.to_csv(\"LR_step.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06-2 XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import copy\n",
    "\n",
    "# ===========================================================\n",
    "# 1. å®šç¾©å–®æ¬¡ XGBoost è¨“ç·´å‡½æ•¸\n",
    "# ===========================================================\n",
    "def run_xgb_single(train_df, test_df, feature_cols, dep_var=\"is_fraud\"):\n",
    "    \"\"\"\n",
    "    é‡å°çµ¦å®šçš„ Train/Test å’Œç‰¹å¾µåˆ—è¡¨è¨“ç·´ XGBoost\n",
    "    \"\"\"\n",
    "    X_train = train_df[feature_cols]\n",
    "    y_train = train_df[dep_var]\n",
    "    X_test = test_df[feature_cols]\n",
    "    y_test = test_df[dep_var]\n",
    "\n",
    "    # åˆå§‹åŒ– XGBoost\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"auc\", # æ”¹ç”¨ AUC ä½œç‚ºè©•ä¼°æŒ‡æ¨™é€šå¸¸æ¯”è¼ƒç›´è§€ï¼Œlogloss ä¹Ÿå¯ä»¥\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\", # åŠ é€Ÿè¨“ç·´\n",
    "        n_jobs=-1,\n",
    "        early_stopping_rounds=50 # å¦‚æœ 50 è¼ªå…§é©—è­‰é›† AUC æ²’æå‡å°±åœæ­¢\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # è¨“ç·´æ¨¡å‹\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            verbose=False # é—œé–‰è©³ç´°è¨“ç·´éç¨‹è¼¸å‡ºï¼Œé¿å…æ´—ç‰ˆ\n",
    "        )\n",
    "\n",
    "        # é æ¸¬æ©Ÿç‡\n",
    "        train_pred = model.predict_proba(X_train)[:, 1]\n",
    "        test_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # è¨ˆç®—æŒ‡æ¨™\n",
    "        train_roc = roc_auc_score(y_train, train_pred)\n",
    "        test_roc = roc_auc_score(y_test, test_pred)\n",
    "        train_pr = average_precision_score(y_train, train_pred)\n",
    "        test_pr = average_precision_score(y_test, test_pred)\n",
    "\n",
    "        # å–å¾—æœ€ä½³è¿­ä»£æ¬¡æ•¸ (å¦‚æœè§¸ç™¼æ—©åœ)\n",
    "        best_iter = model.best_iteration if hasattr(model, 'best_iteration') else 300\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"model\": model,\n",
    "            \"metrics\": {\n",
    "                \"Train AUC\": round(train_roc, 4),\n",
    "                \"Test AUC\": round(test_roc, 4),\n",
    "                \"Train PR-AUC\": round(train_pr, 4),\n",
    "                \"Test PR-AUC\": round(test_pr, 4),\n",
    "                \"Best Iteration\": best_iter\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# 2. æº–å‚™ Feature Groups (ç¢ºä¿ç„¡ç›®æ¨™è®Šæ•¸èˆ‡ID)\n",
    "# ===========================================================\n",
    "# å‡è¨­ identifier, all_cols, rfm_cols, dk_cols å·²ç¶“å®šç¾©å¥½\n",
    "identifier = ['transaction_id', 'client_id_x', 'card_id', 'card_number', 'cvv']\n",
    "exclude_cols = set(identifier) | {'is_fraud', 'date', 'year', 'time_block'}\n",
    "\n",
    "def clean_cols(cols):\n",
    "    return [c for c in cols if c not in exclude_cols]\n",
    "\n",
    "feature_groups = {\n",
    "    \"X_all\": clean_cols(all_cols),\n",
    "    \"X_rfm\": clean_cols(rfm_cols),\n",
    "    \"X_dk\": clean_cols(dk_cols),\n",
    "    \"X_all + X_rfm\": clean_cols(all_cols + rfm_cols),\n",
    "    \"X_all + X_dk\": clean_cols(all_cols + dk_cols),\n",
    "    \"X_rfm + X_dk\": clean_cols(rfm_cols + dk_cols),\n",
    "    \"X_all + X_rfm + X_dk\": clean_cols(all_cols + rfm_cols + dk_cols)\n",
    "}\n",
    "\n",
    "# ===========================================================\n",
    "# 3. ä¸»è¿´åœˆ (Block + Feature Groups)\n",
    "# ===========================================================\n",
    "xgb_results = {}\n",
    "\n",
    "# ç¢ºä¿ df_sorted å­˜åœ¨\n",
    "if 'df_sorted' not in locals():\n",
    "    raise ValueError(\"df_sorted is not defined. Please ensure your DataFrame is prepared.\")\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸš€ Running XGBoost for Block {block_id} (Year: {2010 + block_id})\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # --- è³‡æ–™åˆ‡åˆ† (Split) ---\n",
    "    block_df = block_df.sort_values('date')\n",
    "    split_index = int(len(block_df) * 0.8)\n",
    "    \n",
    "    train_raw = block_df.iloc[:split_index].copy()\n",
    "    test_raw  = block_df.iloc[split_index:].copy()\n",
    "\n",
    "    # --- é‡ç®— HighRiskMCC (Anti-Leakage) ---\n",
    "    fraud_rate = train_raw.groupby('mcc_code')['is_fraud'].mean()\n",
    "    high_risk_mcc = fraud_rate[fraud_rate > 0.02].index\n",
    "    \n",
    "    train_raw['HighRiskMCC'] = train_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "    test_raw['HighRiskMCC']  = test_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "\n",
    "    # åˆå§‹åŒ–çµæœå­˜æ”¾\n",
    "    xgb_results[block_id] = {}\n",
    "\n",
    "    # --- é‡å°æ¯å€‹ Feature Group è·‘æ¨¡å‹ ---\n",
    "    for group_name, feature_list in feature_groups.items():\n",
    "        \n",
    "        # ç¢ºä¿ç‰¹å¾µå­˜åœ¨æ–¼ DataFrame\n",
    "        valid_features = [f for f in feature_list if f in train_raw.columns]\n",
    "        \n",
    "        # ç°¡å–®æª¢æŸ¥\n",
    "        if not valid_features:\n",
    "            print(f\"   âš ï¸ Group: {group_name} - No valid features found. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"   ğŸ”¹ Group: {group_name} ({len(valid_features)} features)...\", end=\" \")\n",
    "\n",
    "        # åŸ·è¡Œ XGBoost\n",
    "        res = run_xgb_single(\n",
    "            train_raw, \n",
    "            test_raw, \n",
    "            feature_cols=valid_features, \n",
    "            dep_var=\"is_fraud\"\n",
    "        )\n",
    "\n",
    "        if res[\"status\"] == \"success\":\n",
    "            metrics = res[\"metrics\"]\n",
    "            print(f\"âœ… Done (Best Iter: {metrics['Best Iteration']})\")\n",
    "            print(f\"      Train AUC: {metrics['Train AUC']} | Test AUC: {metrics['Test AUC']}\")\n",
    "            print(f\"      Train PR : {metrics['Train PR-AUC']} | Test PR : {metrics['Test PR-AUC']}\")\n",
    "            \n",
    "            xgb_results[block_id][group_name] = metrics\n",
    "        else:\n",
    "            print(f\"âŒ Error: {res['message']}\")\n",
    "            xgb_results[block_id][group_name] = {\"error\": res['message']}\n",
    "\n",
    "print(\"\\nğŸ‰ All XGBoost models completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBoost æ•´åˆçµæœç¸½è¡¨ ===\n",
      "Year                      2010                                        2011                                        2012                                        2013                                        2014                                        2015                                        2016                                        2018                                        2019                                  \n",
      "                     Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC\n",
      "Feature Group                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "X_all                   0.9999   0.9988       0.9812      0.9059    0.9651      NaN       0.0008         0.0    0.9063      NaN       0.0441         0.0    0.9976   0.9860       0.8313      0.7811    0.9862      NaN       0.0910         0.0    0.9993   0.9656       0.9433      0.7540    0.9986   0.9813       0.9217      0.8072    0.9991   0.8931       0.7067      0.4815    1.0000   0.9991       0.9972      0.7053\n",
      "X_all + X_dk            0.9998   0.9992       0.9767      0.9240    0.9738      NaN       0.0010         0.0    0.9282      NaN       0.0755         0.0    0.9921   0.9903       0.7956      0.8028    0.9831      NaN       0.0666         0.0    0.9985   0.9759       0.9226      0.7692    0.9989   0.9835       0.9347      0.8035    0.9994   0.9596       0.7598      0.5528    1.0000   0.9993       0.9955      0.7516\n",
      "X_all + X_rfm           0.9999   0.9992       0.9866      0.9253    0.9651      NaN       0.0008         0.0    0.9092      NaN       0.0296         0.0    0.9974   0.9913       0.8475      0.7863    0.9794      NaN       0.0500         0.0    0.9997   0.9779       0.9755      0.7672    0.9993   0.9865       0.9431      0.8180    0.9996   0.8981       0.8677      0.5292    1.0000   0.9990       0.9998      0.6685\n",
      "X_all + X_rfm + X_dk    1.0000   0.9994       0.9951      0.9417    0.9596      NaN       0.0011         0.0    0.9233      NaN       0.0652         0.0    0.9995   0.9921       0.9443      0.7994    0.9813      NaN       0.0559         0.0    0.9996   0.9811       0.9670      0.7808    0.9994   0.9884       0.9548      0.8305    1.0000   0.9496       0.9826      0.6408    1.0000   0.9995       1.0000      0.8030\n",
      "X_dk                    0.9749   0.9766       0.1461      0.1537    0.9608      NaN       0.0008         0.0    0.8692      NaN       0.0090         0.0    0.9301   0.9325       0.0617      0.0973    0.9334      NaN       0.0100         0.0    0.9217   0.9122       0.1048      0.1287    0.9106   0.9185       0.0597      0.0443    0.9987   0.9772       0.4695      0.4338    0.9986   0.9987       0.4775      0.4836\n",
      "X_rfm                   0.8944   0.8317       0.0907      0.0350    0.8901      NaN       0.0003         0.0    0.7340      NaN       0.0041         0.0    0.8778   0.8072       0.0321      0.0179    0.7887      NaN       0.0045         0.0    0.8997   0.8035       0.0684      0.0224    0.8580   0.8353       0.0446      0.0157    0.8576   0.7570       0.0401      0.0092    0.8661   0.7044       0.0287      0.0044\n",
      "X_rfm + X_dk            0.9925   0.9907       0.5279      0.4573    0.9613      NaN       0.0007         0.0    0.8987      NaN       0.0227         0.0    0.9794   0.9664       0.3400      0.2960    0.9323      NaN       0.0228         0.0    0.9823   0.9496       0.4383      0.3391    0.9761   0.9617       0.3899      0.2178    0.9997   0.9862       0.8497      0.5627    0.9999   0.9991       0.9406      0.6433\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. å°‡ XGBoost çµæœè½‰æ›ç‚º DataFrame\n",
    "# ==========================================\n",
    "xgb_data_list = []\n",
    "\n",
    "for block_id, groups in xgb_results.items():\n",
    "    # æ ¹æ“šä½ çš„ code é‚è¼¯ï¼šYear = 2010 + block_id\n",
    "    current_year = 2010 + block_id \n",
    "    \n",
    "    for group_name, metrics in groups.items():\n",
    "        # æ’é™¤ç™¼ç”ŸéŒ¯èª¤çš„çµ„åˆ¥\n",
    "        if \"error\" in metrics:\n",
    "            continue\n",
    "            \n",
    "        row = {\n",
    "            \"Year\": current_year,\n",
    "            \"Feature Group\": group_name,\n",
    "            \"Train AUC\": metrics.get(\"Train AUC\"),\n",
    "            \"Test AUC\": metrics.get(\"Test AUC\"),\n",
    "            \"Train PR-AUC\": metrics.get(\"Train PR-AUC\"),\n",
    "            \"Test PR-AUC\": metrics.get(\"Test PR-AUC\"),\n",
    "            \"Best Iteration\": metrics.get(\"Best Iteration\") # XGBoost ç‰¹æœ‰çš„è³‡è¨Š\n",
    "        }\n",
    "        xgb_data_list.append(row)\n",
    "\n",
    "df_xgb_raw = pd.DataFrame(xgb_data_list)\n",
    "\n",
    "# ==========================================\n",
    "# 5. è£½ä½œæ•´åˆå¤§è¡¨ (Hierarchical Columns)\n",
    "# ==========================================\n",
    "\n",
    "# è¨­å®šè¦å‘ˆç¾çš„æŒ‡æ¨™ (å¯ä»¥è‡ªç”±å¢æ¸›ï¼Œä¾‹å¦‚åŠ å…¥ Best Iteration)\n",
    "target_metrics = [\"Train AUC\", \"Test AUC\", \"Train PR-AUC\", \"Test PR-AUC\"]\n",
    "\n",
    "# 1. ä½¿ç”¨ pivot è½‰ç½®\n",
    "# index: åˆ— (Feature Group)\n",
    "# columns: æ¬„ (Year)\n",
    "# values: å€¼ (æ‰€æœ‰æŒ‡æ¨™)\n",
    "df_xgb_pivot = df_xgb_raw.pivot(index=\"Feature Group\", columns=\"Year\", values=target_metrics)\n",
    "\n",
    "# 2. äº¤æ›æ¬„ä½å±¤ç´šï¼šå°‡ã€Œå¹´ä»½ã€ç§»åˆ°æœ€ä¸Šå±¤ (Level 0)ï¼ŒæŒ‡æ¨™ç§»åˆ°ç¬¬äºŒå±¤ (Level 1)\n",
    "df_xgb_pivot.columns = df_xgb_pivot.columns.swaplevel(0, 1)\n",
    "\n",
    "# 3. é‡æ–°æ’åºæ¬„ä½\n",
    "# æˆ‘å€‘å¸Œæœ›å¹´ä»½å¾å°åˆ°å¤§ï¼Œä¸”æ¯å€‹å¹´ä»½å…§çš„æŒ‡æ¨™é †åºå›ºå®š (Train -> Test)\n",
    "unique_years = sorted(df_xgb_raw[\"Year\"].unique())\n",
    "ordered_columns = []\n",
    "\n",
    "for year in unique_years:\n",
    "    for metric in target_metrics:\n",
    "        ordered_columns.append((year, metric))\n",
    "\n",
    "# å¼·åˆ¶å¥—ç”¨æ’åº\n",
    "df_xgb_final = df_xgb_pivot.reindex(columns=ordered_columns)\n",
    "\n",
    "print(\"\\n=== XGBoost æ•´åˆçµæœç¸½è¡¨ ===\")\n",
    "# å¦‚æœä½ åœ¨ Jupyter/Colabï¼Œç›´æ¥è¼¸å…¥ df_xgb_final å³å¯\n",
    "# é€™è£¡ç”¨ to_string ç¢ºä¿ç´”æ–‡å­—ä»‹é¢ä¹Ÿèƒ½çœ‹æ¸…æ¥š\n",
    "print(df_xgb_final.to_string())\n",
    "\n",
    "# ==========================================\n",
    "# 6. (é¸ç”¨) è¦–è¦ºåŒ–æ¨£å¼ - é‡å° Jupyter Notebook\n",
    "# ==========================================\n",
    "def highlight_xgb(val):\n",
    "    if pd.isna(val): return ''\n",
    "    # æ ¹æ“šç¶“é©—ï¼ŒXGBoost çš„ Train AUC å¾ˆå®¹æ˜“æ¥è¿‘ 1ï¼Œæ‰€ä»¥æ¨™æº–å¯ä»¥è¨­é«˜ä¸€é»\n",
    "    if val > 0.95: return 'background-color: #d4edda; color: green; font-weight: bold' # æ¥µå¥½ (ç¶ )\n",
    "    if val < 0.70: return 'background-color: #f8d7da; color: red'   # è¡¨ç¾å·® (ç´…)\n",
    "    return ''\n",
    "\n",
    "# é¡¯ç¤ºå¸¶æœ‰é¡è‰²çš„è¡¨æ ¼\n",
    "# df_xgb_final.style.applymap(highlight_xgb).format(\"{:.4f}\")\n",
    "df_xgb_final.to_csv(\"XGB_results_wide.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 0 (Year: 2010)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 11 features)... âœ… Test AUC: 0.9989\n",
      "   ğŸ”¥ Group: X_rfm (Using 4 features)... âœ… Test AUC: 0.8148\n",
      "   ğŸ”¥ Group: X_dk (Using 4 features)... âœ… Test AUC: 0.969\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 15 features)... âœ… Test AUC: 0.9992\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 13 features)... âœ… Test AUC: 0.9989\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 7 features)... âœ… Test AUC: 0.9758\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 16 features)... âœ… Test AUC: 0.9971\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 1 (Year: 2011)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 2 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_rfm (Using 1 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_dk (Using 2 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 7 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 3 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 5 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 7 features)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 2 (Year: 2012)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 6 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_rfm (Using 4 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_dk (Using 1 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 8 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 7 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 4 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 14 features)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 3 (Year: 2013)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 10 features)... âœ… Test AUC: 0.939\n",
      "   ğŸ”¥ Group: X_rfm (Using 5 features)... âœ… Test AUC: 0.8051\n",
      "   ğŸ”¥ Group: X_dk (Using 3 features)... âœ… Test AUC: 0.9256\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 14 features)... âœ… Test AUC: 0.9641\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 14 features)... âœ… Test AUC: 0.9794\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 8 features)... âœ… Test AUC: 0.9646\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 16 features)... âœ… Test AUC: 0.9789\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 4 (Year: 2014)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 14 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_rfm (Using 4 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_dk (Using 3 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 16 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 14 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 6 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 18 features)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 5 (Year: 2015)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 14 features)... âœ… Test AUC: 0.9736\n",
      "   ğŸ”¥ Group: X_rfm (Using 5 features)... âœ… Test AUC: 0.8021\n",
      "   ğŸ”¥ Group: X_dk (Using 2 features)... âœ… Test AUC: 0.8772\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 19 features)... âœ… Test AUC: 0.9753\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 14 features)... âœ… Test AUC: 0.9797\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 7 features)... âœ… Test AUC: 0.9466\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 23 features)... âœ… Test AUC: 0.9781\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 6 (Year: 2016)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 12 features)... âœ… Test AUC: 0.9804\n",
      "   ğŸ”¥ Group: X_rfm (Using 4 features)... âœ… Test AUC: 0.8385\n",
      "   ğŸ”¥ Group: X_dk (Using 2 features)... âœ… Test AUC: 0.8878\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 14 features)... âœ… Test AUC: 0.9867\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 15 features)... âœ… Test AUC: 0.9849\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 6 features)... âœ… Test AUC: 0.9586\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 14 features)... âœ… Test AUC: 0.9856\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 7 (Year: 2017)\n",
      "============================================================\n",
      "   âš ï¸ Group: X_all - Skipped (No features selected by Stepwise)\n",
      "   âš ï¸ Group: X_rfm - Skipped (No features selected by Stepwise)\n",
      "   âš ï¸ Group: X_dk - Skipped (No features selected by Stepwise)\n",
      "   âš ï¸ Group: X_all + X_rfm - Skipped (No features selected by Stepwise)\n",
      "   âš ï¸ Group: X_all + X_dk - Skipped (No features selected by Stepwise)\n",
      "   âš ï¸ Group: X_rfm + X_dk - Skipped (No features selected by Stepwise)\n",
      "   âš ï¸ Group: X_all + X_rfm + X_dk - Skipped (No features selected by Stepwise)\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 8 (Year: 2018)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 14 features)... âœ… Test AUC: 0.8986\n",
      "   ğŸ”¥ Group: X_rfm (Using 5 features)... âœ… Test AUC: 0.7576\n",
      "   ğŸ”¥ Group: X_dk (Using 3 features)... âœ… Test AUC: 0.9376\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 18 features)... âœ… Test AUC: 0.9051\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 14 features)... âœ… Test AUC: 0.8829\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 7 features)... âœ… Test AUC: 0.8532\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 14 features)... âœ… Test AUC: 0.9159\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 9 (Year: 2019)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 15 features)... âœ… Test AUC: 0.999\n",
      "   ğŸ”¥ Group: X_rfm (Using 4 features)... âœ… Test AUC: 0.7001\n",
      "   ğŸ”¥ Group: X_dk (Using 2 features)... âœ… Test AUC: 0.7503\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 18 features)... âœ… Test AUC: 0.9991\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 17 features)... âœ… Test AUC: 0.9992\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 7 features)... âœ… Test AUC: 0.8814\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 21 features)... âœ… Test AUC: 0.9993\n",
      "\n",
      "ğŸ‰ All XGBoost models completed!\n",
      "\n",
      "=== XGBoost Performance (Using Stepwise Selected Features) ===\n",
      "Year                      2010                                        2011                                        2012                                        2013                                        2014                                        2015                                        2016                                        2017                                        2018                                        2019                                  \n",
      "                     Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC\n",
      "Feature Group                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "X_all                   0.9999   0.9989       0.9810      0.9145    0.8415      NaN       0.0003         0.0    0.9300      NaN       0.0260         0.0    0.9970   0.9390       0.8037      0.2985    0.9517      NaN       0.0337         0.0    0.9982   0.9736       0.9223      0.7827    0.9973   0.9804       0.8985      0.8169       NaN      NaN          NaN         NaN    0.9988   0.8986       0.6592      0.4387    0.9999   0.9990       0.9771      0.7060\n",
      "X_all + X_dk            0.9999   0.9989       0.9824      0.8994    0.8480      NaN       0.0003         0.0    0.8510      NaN       0.0093         0.0    0.9998   0.9794       0.9614      0.7443    0.9755      NaN       0.0602         0.0    0.9988   0.9797       0.9352      0.8008    0.9980   0.9849       0.9187      0.8250       NaN      NaN          NaN         NaN    0.9994   0.8829       0.7977      0.5656    1.0000   0.9992       0.9874      0.7041\n",
      "X_all + X_rfm           0.9999   0.9992       0.9897      0.9256    0.8686      NaN       0.0003         0.0    0.8450      NaN       0.0103         0.0    0.9964   0.9641       0.7812      0.3927    0.8223      NaN       0.0076         0.0    0.9985   0.9753       0.9020      0.6885    0.9983   0.9867       0.9085      0.8357       NaN      NaN          NaN         NaN    0.9999   0.9051       0.9532      0.5938    1.0000   0.9991       0.9993      0.6819\n",
      "X_all + X_rfm + X_dk    0.9997   0.9971       0.9446      0.7072    0.9121      NaN       0.0004         0.0    0.9300      NaN       0.0782         0.0    0.9982   0.9789       0.8567      0.4625    0.9406      NaN       0.0334         0.0    0.9994   0.9781       0.9417      0.7272    0.9977   0.9856       0.8997      0.8319       NaN      NaN          NaN         NaN    0.9994   0.9159       0.7323      0.5542    1.0000   0.9993       0.9992      0.7388\n",
      "X_dk                    0.9660   0.9690       0.0720      0.0751    0.5920      NaN       0.0001         0.0    0.8200      NaN       0.0069         0.0    0.9223   0.9256       0.0132      0.0304    0.6333      NaN       0.0019         0.0    0.8805   0.8772       0.0103      0.0210    0.8775   0.8878       0.0149      0.0116       NaN      NaN          NaN         NaN    0.9435   0.9376       0.0473      0.0340    0.7623   0.7503       0.0114      0.0108\n",
      "X_rfm                   0.8717   0.8148       0.0606      0.0213    0.8802      NaN       0.0003         0.0    0.7550      NaN       0.0044         0.0    0.9136   0.8051       0.0657      0.0175    0.8031      NaN       0.0063         0.0    0.9080   0.8021       0.0785      0.0227    0.8537   0.8385       0.0392      0.0157       NaN      NaN          NaN         NaN    0.8553   0.7576       0.0356      0.0101    0.8527   0.7001       0.0241      0.0041\n",
      "X_rfm + X_dk            0.9864   0.9758       0.3975      0.3246    0.9298      NaN       0.0005         0.0    0.8883      NaN       0.0181         0.0    0.9792   0.9646       0.3000      0.2342    0.9229      NaN       0.0229         0.0    0.9770   0.9466       0.3313      0.2753    0.9699   0.9586       0.2942      0.1703       NaN      NaN          NaN         NaN    0.9205   0.8532       0.0769      0.0284    0.9238   0.8814       0.0615      0.0363\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# 4. è‡ªå‹•åŒ–åŸ·è¡Œï¼šStepwise Features -> XGBoost\n",
    "# ===========================================================\n",
    "\n",
    "# ç”¨ä¾†å­˜æœ€çµ‚ XGBoost çš„çµæœ\n",
    "xgb_stepwise_results = []\n",
    "\n",
    "# ç¢ºä¿ df_sorted å­˜åœ¨\n",
    "if 'df_sorted' not in locals():\n",
    "    raise ValueError(\"âš ï¸ Error: 'df_sorted' æœªå®šç¾©\")\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    \n",
    "    current_year = 2010 + block_id\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block {block_id} (Year: {current_year})\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # --- 1. è³‡æ–™åˆ‡åˆ† (å¿…é ˆèˆ‡ Stepwise éšæ®µå®Œå…¨ä¸€è‡´) ---\n",
    "    block_df = block_df.sort_values('date')\n",
    "    split_index = int(len(block_df) * 0.8)\n",
    "    \n",
    "    train_raw = block_df.iloc[:split_index].copy()\n",
    "    test_raw  = block_df.iloc[split_index:].copy()\n",
    "\n",
    "    # --- 2. ç‰¹å¾µå·¥ç¨‹ (Anti-Leakage) ---\n",
    "    try:\n",
    "        fraud_rate = train_raw.groupby('mcc_code')['is_fraud'].mean()\n",
    "        high_risk_mcc = fraud_rate[fraud_rate > 0.02].index\n",
    "        train_raw['HighRiskMCC'] = train_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "        test_raw['HighRiskMCC']  = test_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "    except:\n",
    "        pass # è‹¥è³‡æ–™ç‚ºç©ºï¼Œå¾Œé¢æœƒè¢«æª¢æŸ¥æ“‹ä¸‹\n",
    "\n",
    "    # --- 3. å–å‡ºè©²å¹´ä»½ Stepwise é¸å‡ºçš„ç‰¹å¾µå­—å…¸ ---\n",
    "    # å¦‚æœè©²å¹´ä»½å®Œå…¨æ²’è·‘ Stepwise (ä¾‹å¦‚å ±éŒ¯)ï¼Œçµ¦ä¸€å€‹ç©ºå­—å…¸\n",
    "    block_feats_dict = stepwise_feature_storage.get(block_id, {})\n",
    "\n",
    "    # --- 4. é‡å°æ¯å€‹ Group è·‘ XGBoost ---\n",
    "    for group_name in feature_groups.keys():\n",
    "        \n",
    "        # å¾å­—å…¸ä¸­å–å‡ºã€Œè©²å¹´ä»½ã€è©²ç¾¤çµ„ã€ç¯©é¸å¾Œçš„è®Šæ•¸åˆ—è¡¨\n",
    "        my_features = block_feats_dict.get(group_name, [])\n",
    "        \n",
    "        # æª¢æŸ¥ 1: æ˜¯å¦æœ‰è®Šæ•¸è¢«é¸å‡º\n",
    "        if not my_features:\n",
    "            print(f\"   âš ï¸ Group: {group_name} - Skipped (No features selected by Stepwise)\")\n",
    "            # å­˜å…¥ NaN ä»¥ä¾¿å ±è¡¨å°é½Š\n",
    "            xgb_stepwise_results.append({\n",
    "                \"Year\": current_year,\n",
    "                \"Feature Group\": group_name,\n",
    "                \"Train AUC\": np.nan, \"Test AUC\": np.nan,\n",
    "                \"Train PR-AUC\": np.nan, \"Test PR-AUC\": np.nan,\n",
    "                \"Num Features\": 0\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        print(f\"   ğŸ”¥ Group: {group_name} (Using {len(my_features)} features)...\", end=\" \")\n",
    "\n",
    "        # æª¢æŸ¥ 2: åŸ·è¡Œ XGBoost\n",
    "        # æ³¨æ„ï¼šé€™è£¡å‚³å…¥çš„æ˜¯ my_features (Stepwise ç¯©é¸å¾Œçš„çµæœ)\n",
    "        res = run_xgb_single(\n",
    "            train_raw, \n",
    "            test_raw, \n",
    "            feature_cols=my_features, # <--- é—œéµåœ¨é€™è£¡\n",
    "            dep_var=\"is_fraud\"\n",
    "        )\n",
    "\n",
    "        if res[\"status\"] == \"success\":\n",
    "            m = res[\"metrics\"]\n",
    "            print(f\"âœ… Test AUC: {m.get('Test AUC', np.nan)}\")\n",
    "            \n",
    "            xgb_stepwise_results.append({\n",
    "                \"Year\": current_year,\n",
    "                \"Feature Group\": group_name,\n",
    "                \"Train AUC\": m.get(\"Train AUC\"),\n",
    "                \"Test AUC\": m.get(\"Test AUC\"),\n",
    "                \"Train PR-AUC\": m.get(\"Train PR-AUC\"),\n",
    "                \"Test PR-AUC\": m.get(\"Test PR-AUC\"),\n",
    "                \"Num Features\": len(my_features)\n",
    "            })\n",
    "            \n",
    "        elif res[\"status\"] == \"skip\":\n",
    "            print(f\"âš ï¸ Skipped: {res['message']}\")\n",
    "            xgb_stepwise_results.append({\n",
    "                \"Year\": current_year, \"Feature Group\": group_name,\n",
    "                \"Train AUC\": np.nan, \"Test AUC\": np.nan,\n",
    "                \"Train PR-AUC\": np.nan, \"Test PR-AUC\": np.nan,\n",
    "                \"Num Features\": len(my_features)\n",
    "            })\n",
    "            \n",
    "        else:\n",
    "            print(f\"âŒ Error: {res['message']}\")\n",
    "            # è¦–æƒ…æ³æ±ºå®šæ˜¯å¦ç´€éŒ„ Error\n",
    "\n",
    "print(\"\\nğŸ‰ All XGBoost models completed!\")\n",
    "\n",
    "# ===========================================================\n",
    "# 5. ç”¢å‡º XGBoost (Stepwise Features) æœ€çµ‚å ±è¡¨\n",
    "# ===========================================================\n",
    "if xgb_stepwise_results:\n",
    "    df_xgb_raw = pd.DataFrame(xgb_stepwise_results)\n",
    "    \n",
    "    # è¨­å®šæŒ‡æ¨™\n",
    "    target_metrics = [\"Train AUC\", \"Test AUC\", \"Train PR-AUC\", \"Test PR-AUC\"]\n",
    "    \n",
    "    # è½‰ç½®è¡¨æ ¼ (Pivot)\n",
    "    df_xgb_pivot = df_xgb_raw.pivot(index=\"Feature Group\", columns=\"Year\", values=target_metrics)\n",
    "    \n",
    "    # èª¿æ•´æ¬„ä½å±¤ç´š (Year åœ¨ä¸Š)\n",
    "    df_xgb_pivot.columns = df_xgb_pivot.columns.swaplevel(0, 1)\n",
    "    \n",
    "    # æ’åºæ¬„ä½\n",
    "    unique_years = sorted(df_xgb_raw[\"Year\"].unique())\n",
    "    ordered_columns = [(y, m) for y in unique_years for m in target_metrics]\n",
    "    df_xgb_final = df_xgb_pivot.reindex(columns=ordered_columns)\n",
    "    \n",
    "    print(\"\\n=== XGBoost Performance (Using Stepwise Selected Features) ===\")\n",
    "    print(df_xgb_final.to_string())\n",
    "else:\n",
    "    print(\"No results to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06-3 Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# --- è¼”åŠ©æª¢æŸ¥å‡½æ•¸ (é˜²æ­¢å´©æ½°) ---\n",
    "def check_data_validity(y_data, stage=\"Train\"):\n",
    "    if len(y_data) == 0:\n",
    "        return False, f\"{stage} set is empty\"\n",
    "    if y_data.nunique() < 2:\n",
    "        val = y_data.iloc[0] if len(y_data) > 0 else \"None\"\n",
    "        return False, f\"{stage} set has only 1 class (value: {val})\"\n",
    "    return True, \"\"\n",
    "\n",
    "# ===========================================================\n",
    "# 1. ä¿®æ”¹å¾Œçš„ LightGBM è¨“ç·´å‡½æ•¸ (å«é˜²å‘†æ©Ÿåˆ¶)\n",
    "# ===========================================================\n",
    "def run_lgbm_single(train_df, test_df, feature_cols, dep_var=\"is_fraud\"):\n",
    "    \"\"\"\n",
    "    é‡å° Stepwise ç¯©é¸å¾Œçš„ç‰¹å¾µè¨“ç·´ LightGBMï¼Œä¸¦è™•ç†é‚Šç•Œæƒ…æ³ (Edge Cases)\n",
    "    \"\"\"\n",
    "    X_train = train_df[feature_cols]\n",
    "    y_train = train_df[dep_var]\n",
    "    X_test  = test_df[feature_cols]\n",
    "    y_test  = test_df[dep_var]\n",
    "\n",
    "    # --- 1. é˜²å´©æ½°æª¢æŸ¥ (é‡è¦ä¿®æ”¹) ---\n",
    "    # æª¢æŸ¥ Train: è‹¥ç„¡æ•ˆ (å¦‚å…¨ç‚º0)ï¼Œæ¨¡å‹ç„¡æ³•å­¸ç¿’ï¼Œç›´æ¥è·³é\n",
    "    is_valid_train, msg_train = check_data_validity(y_train, \"Train\")\n",
    "    if not is_valid_train:\n",
    "        return {\"status\": \"skip\", \"message\": msg_train}\n",
    "\n",
    "    # æª¢æŸ¥ Test: è‹¥ç„¡æ•ˆ (åªæœ‰ä¸€é¡)ï¼Œæ¨¡å‹ä»å¯è·‘ï¼Œä½† Test Metrics æœƒæ˜¯ NaN\n",
    "    is_valid_test, _ = check_data_validity(y_test, \"Test\")\n",
    "\n",
    "    # --- 2. è™•ç†é¡åˆ¥ä¸å¹³è¡¡ ---\n",
    "    pos = y_train.sum()\n",
    "    neg = len(y_train) - pos\n",
    "    # é˜²å‘†: é›–ç„¶å‰é¢å·²ç¶“æª¢æŸ¥é validityï¼Œä½†ç‚ºäº†ä¿éšªèµ·è¦‹\n",
    "    spw = neg / pos if pos > 0 else 1\n",
    "\n",
    "    # --- 3. åˆå§‹åŒ–æ¨¡å‹ ---\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.02,\n",
    "        max_bin=128,\n",
    "        scale_pos_weight=spw,\n",
    "        min_split_gain=1.0,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=5,\n",
    "        min_child_samples=20,\n",
    "        max_depth=4,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # --- 4. è¨“ç·´æ¨¡å‹ ---\n",
    "        # ç­–ç•¥ï¼šå¦‚æœæ¸¬è©¦é›†ç„¡æ•ˆï¼Œæˆ‘å€‘ç”¨è¨“ç·´é›†å……ç•¶ eval_set é˜²æ­¢å ±éŒ¯ï¼Œ\n",
    "        # ä½†é€™æ™‚ early_stopping çš„æ„ç¾©ä¸å¤§ï¼Œä¸éç‚ºäº†ä»£ç¢¼ä¸€è‡´æ€§æˆ‘å€‘ä¿ç•™ã€‚\n",
    "        \n",
    "        if is_valid_test:\n",
    "            eval_set = [(X_test, y_test)]\n",
    "        else:\n",
    "            eval_set = [(X_train, y_train)]\n",
    "\n",
    "        callbacks = [lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "        \n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=eval_set,\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        # --- 5. è¨ˆç®—æŒ‡æ¨™ ---\n",
    "        # Train éƒ¨åˆ† (é€šå¸¸ä¸æœƒæœ‰å•é¡Œ)\n",
    "        train_pred = model.predict_proba(X_train)[:, 1]\n",
    "        train_auc = roc_auc_score(y_train, train_pred)\n",
    "        train_pr  = average_precision_score(y_train, train_pred)\n",
    "\n",
    "        # Test éƒ¨åˆ† (é—œéµä¿®æ”¹ï¼šè™•ç† NaN)\n",
    "        test_auc = np.nan\n",
    "        test_pr = np.nan\n",
    "\n",
    "        if is_valid_test:\n",
    "            try:\n",
    "                test_pred = model.predict_proba(X_test)[:, 1]\n",
    "                test_auc = roc_auc_score(y_test, test_pred)\n",
    "                test_pr = average_precision_score(y_test, test_pred)\n",
    "            except ValueError:\n",
    "                # è¬ä¸€ç™¼ç”Ÿé æ¸¬å€¼å…¨ç‚ºåŒä¸€é¡åˆ¥ç­‰æ¥µç«¯æƒ…æ³\n",
    "                pass \n",
    "\n",
    "        best_iter = model.best_iteration_ if model.best_iteration_ else 500\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"metrics\": {\n",
    "                \"Train AUC\": round(train_auc, 4),\n",
    "                \"Test AUC\": round(test_auc, 4) if not np.isnan(test_auc) else np.nan,\n",
    "                \"Train PR-AUC\": round(train_pr, 4),\n",
    "                \"Test PR-AUC\": round(test_pr, 4) if not np.isnan(test_pr) else np.nan,\n",
    "                \"Best Iteration\": best_iter\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "# ===========================================================\n",
    "# 2. ä¸»è¿´åœˆ (ä¿®æ­£ HighRiskMCC åŠ å…¥æ–¹å¼ & Skip è™•ç†)\n",
    "# ===========================================================\n",
    "\n",
    "# ... (å‰é¢çš„ feature_groups å®šç¾©éƒ½ä¸ç”¨å‹•) ...\n",
    "\n",
    "lgbm_results = {}\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸš€ Running LightGBM for Block {block_id} (Year: {2010 + block_id})\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # --- è³‡æ–™åˆ‡åˆ† ---\n",
    "    block_df = block_df.sort_values('date')\n",
    "    split_index = int(len(block_df) * 0.8)\n",
    "    \n",
    "    train_raw = block_df.iloc[:split_index].copy()\n",
    "    test_raw  = block_df.iloc[split_index:].copy()\n",
    "\n",
    "    # --- é‡ç®— HighRiskMCC (Anti-Leakage) ---\n",
    "    # é€™æ˜¯å‹•æ…‹ç”Ÿæˆçš„ç‰¹å¾µ\n",
    "    fraud_rate = train_raw.groupby('mcc_code')['is_fraud'].mean()\n",
    "    high_risk_mcc = fraud_rate[fraud_rate > 0.02].index\n",
    "    \n",
    "    train_raw['HighRiskMCC'] = train_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "    test_raw['HighRiskMCC']  = test_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "\n",
    "    lgbm_results[block_id] = {}\n",
    "\n",
    "    for group_name, feature_list in feature_groups.items():\n",
    "        \n",
    "        # 1. å…ˆéæ¿¾åŸæœ¬å­˜åœ¨çš„ç‰¹å¾µ\n",
    "        valid_features = [f for f in feature_list if f in train_raw.columns]\n",
    "        \n",
    "        # â˜…â˜…â˜… ä¿®æ­£é» 1: ç¢ºä¿å‹•æ…‹ç‰¹å¾µ HighRiskMCC è¢«åŠ å…¥ â˜…â˜…â˜…\n",
    "        # å¦‚æœä½ å¸Œæœ›æ¯å€‹æ¨¡å‹éƒ½åŒ…å«é€™å€‹å¼·ç‰¹å¾µï¼Œè«‹åœ¨é€™è£¡æ‰‹å‹• append\n",
    "        if 'HighRiskMCC' not in valid_features:\n",
    "            valid_features.append('HighRiskMCC')\n",
    "\n",
    "        if not valid_features:\n",
    "            continue\n",
    "            \n",
    "        print(f\"   ğŸ”¹ Group: {group_name} ({len(valid_features)} features)...\", end=\" \")\n",
    "\n",
    "        # åŸ·è¡Œ LightGBM\n",
    "        res = run_lgbm_single(\n",
    "            train_raw, \n",
    "            test_raw, \n",
    "            feature_cols=valid_features, \n",
    "            dep_var=\"is_fraud\"\n",
    "        )\n",
    "\n",
    "        # â˜…â˜…â˜… ä¿®æ­£é» 2: å„ªé›…åœ°è™•ç† Skip ç‹€æ…‹ â˜…â˜…â˜…\n",
    "        if res[\"status\"] == \"success\":\n",
    "            metrics = res[\"metrics\"]\n",
    "            print(f\"âœ… Done (Best Iter: {metrics['Best Iteration']})\")\n",
    "            lgbm_results[block_id][group_name] = metrics\n",
    "            \n",
    "        elif res[\"status\"] == \"skip\":\n",
    "            # é‡åˆ°è³‡æ–™ä¸è¶³ (ä¾‹å¦‚è©²å¹´ç„¡è©æ¬º)ï¼Œé¡¯ç¤ºé»ƒè‰²è­¦å‘Šä½†ä¸å ±éŒ¯\n",
    "            print(f\"âš ï¸ Skipped: {res['message']}\")\n",
    "            lgbm_results[block_id][group_name] = {\"skipped\": True, \"reason\": res['message']}\n",
    "            \n",
    "        else:\n",
    "            # çœŸæ­£çš„ç¨‹å¼éŒ¯èª¤æ‰é¡¯ç¤º Error\n",
    "            print(f\"âŒ Error: {res['message']}\")\n",
    "            lgbm_results[block_id][group_name] = {\"error\": res['message']}\n",
    "\n",
    "print(\"\\nğŸ‰ All LightGBM models completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LightGBM æ•´åˆçµæœç¸½è¡¨ ===\n",
      "Year                      2010                                        2011                                        2012                                        2013                                        2014                                        2015                                        2016                                        2018                                        2019                                  \n",
      "                     Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC\n",
      "Feature Group                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "X_all                   0.9918   0.9886       0.3143      0.2495    0.9293      NaN       0.0004         0.0    0.7974      NaN       0.0048         0.0    0.9982   0.9152       0.3343      0.2649    0.8289      NaN       0.0035         0.0    0.9937   0.9657       0.6202      0.5234    0.9396   0.9372       0.0425      0.0306    0.9994   0.9101       0.7508      0.4925    0.9999   0.9989       0.9685      0.6586\n",
      "X_all + X_dk            0.9885   0.9888       0.1303      0.1200    0.9756      NaN       0.0011         0.0    0.8918      NaN       0.0169         0.0    0.9912   0.9560       0.3529      0.4635    0.9488      NaN       0.0148         0.0    0.9924   0.9680       0.5210      0.4889    0.9483   0.9467       0.1770      0.1981    0.9992   0.9187       0.5861      0.4602    0.9995   0.9989       0.8005      0.6393\n",
      "X_all + X_rfm           0.9823   0.9806       0.0954      0.0766    0.9722      NaN       0.0010         0.0    0.8960      NaN       0.0159         0.0    0.9995   0.9806       0.6015      0.5898    0.9717      NaN       0.0164         0.0    0.9967   0.9687       0.6269      0.5330    0.9436   0.9447       0.0505      0.0368    0.9989   0.9182       0.5458      0.4125    0.9999   0.9990       0.9555      0.6651\n",
      "X_all + X_rfm + X_dk    0.9704   0.9720       0.0560      0.0514    0.9789      NaN       0.0013         0.0    0.8856      NaN       0.0099         0.0    0.8032   0.7299       0.0605      0.1213    0.9665      NaN       0.0169         0.0    0.9974   0.9708       0.6916      0.5671    0.9522   0.9546       0.1773      0.1986    0.9995   0.9304       0.7558      0.5824    0.9999   0.9992       0.9409      0.6964\n",
      "X_dk                    0.9704   0.9728       0.0692      0.0771    0.9188      NaN       0.0004         0.0    0.8626      NaN       0.0074         0.0    0.9224   0.9240       0.0130      0.0295    0.9189      NaN       0.0061         0.0    0.9188   0.9095       0.0279      0.0522    0.9104   0.9184       0.0387      0.0301    0.9987   0.9793       0.4708      0.4389    0.9986   0.9987       0.4763      0.4861\n",
      "X_rfm                   0.7454   0.7273       0.0081      0.0069    0.6629      NaN       0.0001         0.0    0.6968      NaN       0.0026         0.0    0.9003   0.7613       0.0149      0.0130    0.7744      NaN       0.0027         0.0    0.7873   0.7334       0.0067      0.0105    0.7711   0.7997       0.0088      0.0073    0.8579   0.7358       0.0124      0.0083    0.6844   0.6493       0.0032      0.0028\n",
      "X_rfm + X_dk            0.9631   0.9661       0.0437      0.0422    0.9638      NaN       0.0007         0.0    0.8880      NaN       0.0107         0.0    0.9730   0.9150       0.1412      0.2163    0.9486      NaN       0.0110         0.0    0.9736   0.9324       0.2271      0.2964    0.9299   0.9354       0.0368      0.0294    0.9993   0.9353       0.6508      0.4970    0.9995   0.9990       0.7461      0.6204\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. è£½ä½œ LightGBM æ•´åˆå ±è¡¨\n",
    "# ==========================================\n",
    "lgbm_data_list = []\n",
    "\n",
    "for block_id, groups in lgbm_results.items():\n",
    "    current_year = 2010 + block_id \n",
    "    \n",
    "    for group_name, metrics in groups.items():\n",
    "        if \"error\" in metrics:\n",
    "            continue\n",
    "            \n",
    "        row = {\n",
    "            \"Year\": current_year,\n",
    "            \"Feature Group\": group_name,\n",
    "            \"Train AUC\": metrics.get(\"Train AUC\"),\n",
    "            \"Test AUC\": metrics.get(\"Test AUC\"),\n",
    "            \"Train PR-AUC\": metrics.get(\"Train PR-AUC\"),\n",
    "            \"Test PR-AUC\": metrics.get(\"Test PR-AUC\")\n",
    "        }\n",
    "        lgbm_data_list.append(row)\n",
    "\n",
    "df_lgbm_raw = pd.DataFrame(lgbm_data_list)\n",
    "\n",
    "# --- è½‰ç½®èˆ‡éšå±¤åŒ– ---\n",
    "target_metrics = [\"Train AUC\", \"Test AUC\", \"Train PR-AUC\", \"Test PR-AUC\"]\n",
    "\n",
    "# 1. Pivot: Index=Feature Group, Cols=Year\n",
    "df_lgbm_pivot = df_lgbm_raw.pivot(index=\"Feature Group\", columns=\"Year\", values=target_metrics)\n",
    "\n",
    "# 2. Swaplevel: è®“å¹´ä»½åœ¨æœ€ä¸Šå±¤\n",
    "df_lgbm_pivot.columns = df_lgbm_pivot.columns.swaplevel(0, 1)\n",
    "\n",
    "# 3. Reindex: å¼·åˆ¶æ’åº (å¹´ä»½å°->å¤§, æŒ‡æ¨™ Train->Test)\n",
    "unique_years = sorted(df_lgbm_raw[\"Year\"].unique())\n",
    "ordered_columns = []\n",
    "for year in unique_years:\n",
    "    for metric in target_metrics:\n",
    "        ordered_columns.append((year, metric))\n",
    "\n",
    "df_lgbm_final = df_lgbm_pivot.reindex(columns=ordered_columns)\n",
    "\n",
    "print(\"\\n=== LightGBM æ•´åˆçµæœç¸½è¡¨ ===\")\n",
    "print(df_lgbm_final.to_string())\n",
    "\n",
    "# å¦‚æœæ‚¨åœ¨ Jupyter Notebookï¼Œå¯ä»¥ç”¨é€™è¡Œé¡¯ç¤ºæ¼‚äº®çš„ HTML è¡¨æ ¼\n",
    "# df_lgbm_final.style.format(\"{:.4f}\").background_gradient(cmap='Blues', subset=pd.IndexSlice[:, (slice(None), 'Test AUC')])\n",
    "df_lgbm_final.to_csv(\"lgbm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 0 (Year: 2010)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 11 feats)... âœ… Test AUC: 0.9814\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 feats)... âœ… Test AUC: 0.735\n",
      "   ğŸ”¹ Group: X_dk (Using 4 feats)... âœ… Test AUC: 0.9515\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 15 feats)... âœ… Test AUC: 0.9894\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 13 feats)... âœ… Test AUC: 0.984\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 7 feats)... âœ… Test AUC: 0.7709\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 16 feats)... âœ… Test AUC: 0.9719\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 1 (Year: 2011)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 2 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm (Using 1 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_dk (Using 2 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 7 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 3 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 5 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 7 feats)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 2 (Year: 2012)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 6 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_dk (Using 1 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 8 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 7 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 4 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 14 feats)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 3 (Year: 2013)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 10 feats)... âœ… Test AUC: 0.8953\n",
      "   ğŸ”¹ Group: X_rfm (Using 5 feats)... âœ… Test AUC: 0.7635\n",
      "   ğŸ”¹ Group: X_dk (Using 3 feats)... âœ… Test AUC: 0.8393\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 14 feats)... âœ… Test AUC: 0.6813\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 14 feats)... âœ… Test AUC: 0.9224\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 8 feats)... âœ… Test AUC: 0.7029\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 16 feats)... âœ… Test AUC: 0.9009\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 4 (Year: 2014)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 14 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_dk (Using 3 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 16 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 14 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 6 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 18 feats)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 5 (Year: 2015)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 14 feats)... âœ… Test AUC: 0.9544\n",
      "   ğŸ”¹ Group: X_rfm (Using 5 feats)... âœ… Test AUC: 0.7344\n",
      "   ğŸ”¹ Group: X_dk (Using 2 feats)... âœ… Test AUC: 0.9018\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 19 feats)... âœ… Test AUC: 0.9742\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 14 feats)... âœ… Test AUC: 0.9628\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 7 feats)... âœ… Test AUC: 0.9344\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 23 feats)... âœ… Test AUC: 0.9552\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 6 (Year: 2016)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 12 feats)... âœ… Test AUC: 0.9082\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 feats)... âœ… Test AUC: 0.7997\n",
      "   ğŸ”¹ Group: X_dk (Using 2 feats)... âœ… Test AUC: 0.9094\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 14 feats)... âœ… Test AUC: 0.941\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 15 feats)... âœ… Test AUC: 0.9514\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 6 feats)... âœ… Test AUC: 0.9301\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 14 feats)... âœ… Test AUC: 0.9129\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 7 (Year: 2017)\n",
      "============================================================\n",
      "   âš ï¸ Group: X_all - Skipped (No features from Stepwise)\n",
      "   âš ï¸ Group: X_rfm - Skipped (No features from Stepwise)\n",
      "   âš ï¸ Group: X_dk - Skipped (No features from Stepwise)\n",
      "   âš ï¸ Group: X_all + X_rfm - Skipped (No features from Stepwise)\n",
      "   âš ï¸ Group: X_all + X_dk - Skipped (No features from Stepwise)\n",
      "   âš ï¸ Group: X_rfm + X_dk - Skipped (No features from Stepwise)\n",
      "   âš ï¸ Group: X_all + X_rfm + X_dk - Skipped (No features from Stepwise)\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 8 (Year: 2018)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 14 feats)... âœ… Test AUC: 0.9023\n",
      "   ğŸ”¹ Group: X_rfm (Using 5 feats)... âœ… Test AUC: 0.7391\n",
      "   ğŸ”¹ Group: X_dk (Using 3 feats)... âœ… Test AUC: 0.9186\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 18 feats)... âœ… Test AUC: 0.9308\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 14 feats)... âœ… Test AUC: 0.9365\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 7 feats)... âœ… Test AUC: 0.8275\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 14 feats)... âœ… Test AUC: 0.9378\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 9 (Year: 2019)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 15 feats)... âœ… Test AUC: 0.9987\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 feats)... âœ… Test AUC: 0.6007\n",
      "   ğŸ”¹ Group: X_dk (Using 2 feats)... âœ… Test AUC: 0.7503\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 18 feats)... âœ… Test AUC: 0.9987\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 17 feats)... âœ… Test AUC: 0.999\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 7 feats)... âœ… Test AUC: 0.87\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 21 feats)... âœ… Test AUC: 0.9989\n",
      "\n",
      "ğŸ‰ All LightGBM models (Stepwise) completed!\n",
      "\n",
      "=== LightGBM Performance (Using Stepwise Selected Features) ===\n",
      "Year                      2010                                        2011                                        2012                                        2013                                        2014                                        2015                                        2016                                        2017                                        2018                                        2019                                  \n",
      "                     Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC\n",
      "Feature Group                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "X_all                   0.9828   0.9814       0.0960      0.0773    0.9060      NaN       0.0004         NaN    0.9771      NaN       0.4003         NaN    0.9617   0.8953       0.0557      0.0770    0.9710      NaN       0.0245         NaN    0.9911   0.9544       0.4141      0.3926    0.8995   0.9082       0.0214      0.0195       NaN      NaN          NaN         NaN    0.9993   0.9023       0.7287      0.5106    0.9999   0.9987       0.9539      0.5791\n",
      "X_all + X_dk            0.9845   0.9840       0.1000      0.0825    0.4990      NaN       0.0001         NaN    0.9744      NaN       0.3236         NaN    0.9473   0.9224       0.0192      0.0428    0.9780      NaN       0.0302         NaN    0.9934   0.9628       0.5436      0.4857    0.9490   0.9514       0.1681      0.1914       NaN      NaN          NaN         NaN    0.9995   0.9365       0.7698      0.5616    0.9998   0.9990       0.8875      0.6399\n",
      "X_all + X_rfm           0.9898   0.9894       0.1513      0.1370    0.9962      NaN       0.0067         NaN    0.9847      NaN       0.2887         NaN    0.7926   0.6813       0.0205      0.0322    0.9472      NaN       0.0123         NaN    0.9957   0.9742       0.5886      0.5547    0.9402   0.9410       0.0424      0.0306       NaN      NaN          NaN         NaN    0.9994   0.9308       0.7534      0.5193    0.9999   0.9987       0.9361      0.6257\n",
      "X_all + X_rfm + X_dk    0.9716   0.9719       0.0562      0.0506    0.9986      NaN       0.0178         NaN    0.9911      NaN       0.5343         NaN    0.9782   0.9009       0.0710      0.0900    0.9606      NaN       0.0131         NaN    0.9960   0.9552       0.6534      0.5434    0.9094   0.9129       0.0240      0.0202       NaN      NaN          NaN         NaN    0.9995   0.9378       0.7738      0.5871    1.0000   0.9989       0.9762      0.7041\n",
      "X_dk                    0.9530   0.9515       0.0439      0.0409    0.9187      NaN       0.0004         NaN    0.8200      NaN       0.0069         NaN    0.8306   0.8393       0.0043      0.0114    0.8016      NaN       0.0028         NaN    0.9107   0.9018       0.0188      0.0343    0.8984   0.9094       0.0227      0.0179       NaN      NaN          NaN         NaN    0.9360   0.9186       0.0127      0.0158    0.7623   0.7503       0.0114      0.0108\n",
      "X_rfm                   0.7421   0.7350       0.0081      0.0069    0.6495      NaN       0.0001         NaN    0.8594      NaN       0.0092         NaN    0.8959   0.7635       0.0150      0.0142    0.9113      NaN       0.0099         NaN    0.7871   0.7344       0.0067      0.0105    0.7711   0.7997       0.0088      0.0073       NaN      NaN          NaN         NaN    0.8461   0.7391       0.0131      0.0080    0.6958   0.6007       0.0038      0.0028\n",
      "X_rfm + X_dk            0.7703   0.7709       0.0103      0.0081    0.9922      NaN       0.0033         NaN    0.9366      NaN       0.0363         NaN    0.7598   0.7029       0.0246      0.0441    0.9517      NaN       0.0114         NaN    0.9731   0.9344       0.1600      0.1829    0.9246   0.9301       0.0284      0.0222       NaN      NaN          NaN         NaN    0.9173   0.8275       0.0420      0.0275    0.9190   0.8700       0.0470      0.0285\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# 2. è‡ªå‹•åŒ–åŸ·è¡Œï¼šStepwise Features -> LightGBM\n",
    "# ===========================================================\n",
    "\n",
    "lgbm_stepwise_results = []\n",
    "\n",
    "# æª¢æŸ¥å¿…è¦è®Šæ•¸\n",
    "if 'df_sorted' not in locals():\n",
    "    raise ValueError(\"âš ï¸ Error: 'df_sorted' æœªå®šç¾©\")\n",
    "if 'stepwise_feature_storage' not in locals():\n",
    "    raise ValueError(\"âš ï¸ Error: 'stepwise_feature_storage' æœªå®šç¾©ï¼Œè«‹å…ˆåŸ·è¡Œ Stepwise æ­¥é©Ÿã€‚\")\n",
    "\n",
    "# é€™è£¡æˆ‘å€‘ä»éœ€è¦ feature_groups çš„ key (ä¾‹å¦‚ \"X_all\", \"X_rfm\") ä¾†è·‘è¿´åœˆ\n",
    "group_names = feature_groups.keys()\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    \n",
    "    current_year = 2010 + block_id\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸš€ Running LightGBM (Stepwise Feats) for Block {block_id} (Year: {current_year})\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # --- 1. è³‡æ–™åˆ‡åˆ† (Split) - ä¿æŒä¸€è‡´ ---\n",
    "    block_df = block_df.sort_values('date')\n",
    "    split_index = int(len(block_df) * 0.8)\n",
    "    \n",
    "    train_raw = block_df.iloc[:split_index].copy()\n",
    "    test_raw  = block_df.iloc[split_index:].copy()\n",
    "\n",
    "    # --- 2. ç‰¹å¾µå·¥ç¨‹ (Anti-Leakage) ---\n",
    "    try:\n",
    "        fraud_rate = train_raw.groupby('mcc_code')['is_fraud'].mean()\n",
    "        high_risk_mcc = fraud_rate[fraud_rate > 0.02].index\n",
    "        train_raw['HighRiskMCC'] = train_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "        test_raw['HighRiskMCC']  = test_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "    except:\n",
    "        pass # è‹¥è³‡æ–™ç‚ºç©ºï¼Œç¨å¾Œæœƒè¢« skip\n",
    "\n",
    "    # --- 3. è®€å–è©²å¹´ä»½çš„ Stepwise è®Šæ•¸å­—å…¸ ---\n",
    "    # å¦‚æœè©²å¹´ä»½å®Œå…¨æ²’è·‘å‡ºçµæœ (ä¾‹å¦‚è³‡æ–™å¤ªå°‘å ±éŒ¯)ï¼Œçµ¦ç©ºå­—å…¸\n",
    "    block_feats_dict = stepwise_feature_storage.get(block_id, {})\n",
    "\n",
    "    # --- 4. é‡å°æ¯å€‹ Group åŸ·è¡Œ ---\n",
    "    for group_name in group_names:\n",
    "        \n",
    "        # â˜… é—œéµï¼šå¾å­—å…¸å–å‡º Stepwise ç¯©é¸å¾Œçš„è®Šæ•¸\n",
    "        my_features = block_feats_dict.get(group_name, [])\n",
    "        \n",
    "        # æƒ…æ³ A: Stepwise æ²’é¸å‡ºä»»ä½•è®Šæ•¸ (æˆ–è©²çµ„è³‡æ–™æœ‰å•é¡Œ)\n",
    "        if not my_features:\n",
    "            print(f\"   âš ï¸ Group: {group_name} - Skipped (No features from Stepwise)\")\n",
    "            lgbm_stepwise_results.append({\n",
    "                \"Year\": current_year, \"Feature Group\": group_name,\n",
    "                \"Train AUC\": np.nan, \"Test AUC\": np.nan,\n",
    "                \"Train PR-AUC\": np.nan, \"Test PR-AUC\": np.nan,\n",
    "                \"Num Features\": 0\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        print(f\"   ğŸ”¹ Group: {group_name} (Using {len(my_features)} feats)...\", end=\" \")\n",
    "\n",
    "        # æƒ…æ³ B: åŸ·è¡Œ LightGBM\n",
    "        res = run_lgbm_single(\n",
    "            train_raw, \n",
    "            test_raw, \n",
    "            feature_cols=my_features, # ä½¿ç”¨ç¯©é¸å¾Œçš„è®Šæ•¸\n",
    "            dep_var=\"is_fraud\"\n",
    "        )\n",
    "\n",
    "        if res[\"status\"] == \"success\":\n",
    "            m = res[\"metrics\"]\n",
    "            print(f\"âœ… Test AUC: {m.get('Test AUC', np.nan)}\")\n",
    "            \n",
    "            lgbm_stepwise_results.append({\n",
    "                \"Year\": current_year,\n",
    "                \"Feature Group\": group_name,\n",
    "                \"Train AUC\": m.get(\"Train AUC\"),\n",
    "                \"Test AUC\": m.get(\"Test AUC\"),\n",
    "                \"Train PR-AUC\": m.get(\"Train PR-AUC\"),\n",
    "                \"Test PR-AUC\": m.get(\"Test PR-AUC\"),\n",
    "                \"Num Features\": len(my_features)\n",
    "            })\n",
    "            \n",
    "        elif res[\"status\"] == \"skip\":\n",
    "            print(f\"âš ï¸ Skipped: {res['message']}\")\n",
    "            lgbm_stepwise_results.append({\n",
    "                \"Year\": current_year, \"Feature Group\": group_name,\n",
    "                \"Train AUC\": np.nan, \"Test AUC\": np.nan,\n",
    "                \"Train PR-AUC\": np.nan, \"Test PR-AUC\": np.nan,\n",
    "                \"Num Features\": len(my_features)\n",
    "            })\n",
    "            \n",
    "        else:\n",
    "            print(f\"âŒ Error: {res['message']}\")\n",
    "            # è¦–éœ€æ±‚æ±ºå®šæ˜¯å¦ç´€éŒ„ Error\n",
    "\n",
    "print(\"\\nğŸ‰ All LightGBM models (Stepwise) completed!\")\n",
    "\n",
    "# ===========================================================\n",
    "# 3. ç”¢å‡ºå ±è¡¨\n",
    "# ===========================================================\n",
    "if lgbm_stepwise_results:\n",
    "    df_lgbm_raw = pd.DataFrame(lgbm_stepwise_results)\n",
    "    \n",
    "    # è½‰ç½®\n",
    "    target_metrics = [\"Train AUC\", \"Test AUC\", \"Train PR-AUC\", \"Test PR-AUC\"]\n",
    "    df_lgbm_pivot = df_lgbm_raw.pivot(index=\"Feature Group\", columns=\"Year\", values=target_metrics)\n",
    "    \n",
    "    # èª¿æ•´æ¬„ä½\n",
    "    df_lgbm_pivot.columns = df_lgbm_pivot.columns.swaplevel(0, 1)\n",
    "    unique_years = sorted(df_lgbm_raw[\"Year\"].unique())\n",
    "    ordered_columns = [(y, m) for y in unique_years for m in target_metrics]\n",
    "    \n",
    "    df_lgbm_final = df_lgbm_pivot.reindex(columns=ordered_columns)\n",
    "    \n",
    "    print(\"\\n=== LightGBM Performance (Using Stepwise Selected Features) ===\")\n",
    "    print(df_lgbm_final.to_string())\n",
    "else:\n",
    "    print(\"No results generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²æˆåŠŸå„²å­˜ç‚º stepwise_feature_storage.pkl\n"
     ]
    }
   ],
   "source": [
    "## stepwiseè®Šæ•¸é¸å– çµæœ\n",
    "\n",
    "import pickle\n",
    "\n",
    "# 1. å„²å­˜ (Save)\n",
    "with open('stepwise_feature_storage.pkl', 'wb') as f:\n",
    "    pickle.dump(stepwise_feature_storage, f)\n",
    "\n",
    "print(\"âœ… å·²æˆåŠŸå„²å­˜ç‚º stepwise_feature_storage.pkl\")\n",
    "\n",
    "# ==========================================\n",
    "# ä¸‹æ¬¡è¦ç”¨æ™‚ï¼ŒåŸ·è¡Œé€™æ®µè®€å– (Load)\n",
    "# ==========================================\n",
    "# with open('stepwise_feature_storage.pkl', 'rb') as f:\n",
    "#     stepwise_feature_storage = pickle.load(f)\n",
    "# print(\"âœ… å·²è®€å–è®Šæ•¸è¨­å®š\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lgbm_final.to_csv(\"lgbm_stepwise.csv\") "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
