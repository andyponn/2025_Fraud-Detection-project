{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00_ 01åŒ¯å…¥è³‡æ–™ä¸¦02æ•´ç†æˆä¸€å¼µdataframe (è«‹ç›´æ¥åŸ·è¡Œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-1_import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#https://drive.google.com/drive/folders/18qV82fNY3IIWu3BRoGqm_LNgJzE8Akbr?usp=drive_link\n",
    "#base_dir = \"/Users/Andypon/10_äº¤å¤§ç ”ç©¶æ‰€/1141_01_æ©Ÿå™¨å­¸ç¿’èˆ‡é‡‘èç§‘æŠ€/data\"\n",
    "base_dir= '/Users/andyw.p.chen/Documents/Project/datasets'\n",
    "#base_dir=  \"c:\\Users\\user\\Downloads\\datasets\"\n",
    "\n",
    "def load_json_to_df(filename: str) -> pd.DataFrame:\n",
    "    file_path = os.path.join(base_dir, filename)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # å¦‚æœæ˜¯ { \"target\": {id: value, ...} }\n",
    "    if isinstance(data, dict) and len(data) == 1 and isinstance(next(iter(data.values())), dict):\n",
    "        key, inner = next(iter(data.items()))\n",
    "        return pd.DataFrame(list(inner.items()), columns=[\"id\", key])\n",
    "\n",
    "    # dict of scalar\n",
    "    if isinstance(data, dict):\n",
    "        return pd.DataFrame([{\"code\": k, \"desc\": v} for k, v in data.items()])\n",
    "\n",
    "    # list of dict\n",
    "    elif isinstance(data, list):\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported JSON structure in {filename}: {type(data)}\")\n",
    "\n",
    "\n",
    "def load_csv_to_df(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"è®€å– CSV ä¸¦è½‰ç‚º DataFrameã€‚\"\"\"\n",
    "    return pd.read_csv(os.path.join(base_dir, filename))\n",
    "\n",
    "# JSON è³‡æ–™\n",
    "##mcc_codes_df = load_json_to_df(\"mcc_codes.json\")\n",
    "train_fraud_labels_df = load_json_to_df(\"train_fraud_labels.json\")\n",
    "\n",
    "# CSV è³‡æ–™\n",
    "cards_df = load_csv_to_df(\"cards_data.csv\")\n",
    "transactions_df = load_csv_to_df(\"transactions_data.csv\")\n",
    "users_df = load_csv_to_df(\"users_data.csv\")\n",
    "\n",
    "# ç°¡å–®æª¢æŸ¥\n",
    "#print(mcc_codes_df.head())\n",
    "#print(train_fraud_labels_df.head())\n",
    "#print(cards_df.head())\n",
    "#print(transactions_df.head())\n",
    "#print(users_df.apthead())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-2_rename variable in each data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraud_labels_df = train_fraud_labels_df.rename(columns={'id': 'transactions_id'})\n",
    "train_fraud_labels_df = train_fraud_labels_df.rename(columns={'target': 'is_fraud'})\n",
    "\n",
    "cards_df = cards_df.rename(columns={'id':'card_id'})\n",
    "\n",
    "users_df = users_df.rename(columns={'id':'client_id'})\n",
    "\n",
    "transactions_df = transactions_df.rename(columns={'mcc': 'mcc_code'})\n",
    "transactions_df = transactions_df.rename(columns={'id': 'transaction_id'})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-3_è®Šæ•¸å‹æ…‹çµ±ä¸€åŠç¼ºå¤±å€¼è™•ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_flags(df: pd.DataFrame, cols: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    åœ¨ DataFrame ä¸­å°æŒ‡å®šæ¬„ä½å»ºç«‹ missing flag æ¬„ä½\n",
    "    flag=1 è¡¨ç¤ºç¼ºå¤±å€¼ï¼Œflag=0 è¡¨ç¤ºéç¼ºå¤±å€¼\n",
    "    \n",
    "    åƒæ•¸\n",
    "    ----\n",
    "    df : pd.DataFrame\n",
    "        è¼¸å…¥çš„è³‡æ–™æ¡†\n",
    "    cols : list\n",
    "        è¦æª¢æŸ¥çš„æ¬„ä½åç¨±æ¸…å–®\n",
    "    \n",
    "    å›å‚³\n",
    "    ----\n",
    "    pd.DataFrame : æ–°çš„è³‡æ–™æ¡† (å«æ–°å¢çš„ flag æ¬„ä½)\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        df[f\"{col}_missing_flag\"] = df[col].isna().astype(int)\n",
    "    return df\n",
    "\n",
    "transactions_df = add_missing_flags(transactions_df, [\"merchant_state\", \"zip\", \"errors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train_fraud_labels_df##\n",
    "train_fraud_labels_df[\"is_fraud\"]=train_fraud_labels_df[\"is_fraud\"].astype(\"category\") \n",
    "train_fraud_labels_df[\"transactions_id\"]=train_fraud_labels_df[\"transactions_id\"].astype(int) #åˆä½µè³‡æ–™éœ€è¦\n",
    "\n",
    "##cards_df##\n",
    "cards_df[\"card_brand\"]=cards_df[\"card_brand\"].astype(\"category\") \n",
    "cards_df[\"card_type\"]=cards_df[\"card_type\"].astype(\"category\")\n",
    "#####ä¸è¦loadé€™è¡Œ cards_df[\"expires\"]=pd.to_datetime(cards_df[\"expires\"], format=\"%m/%Y\")\n",
    "cards_df[\"expires\"] = pd.to_datetime(cards_df[\"expires\"], format=\"%m/%Y\").dt.to_period(\"M\")\n",
    "cards_df[\"has_chip\"]=cards_df[\"has_chip\"].astype(\"category\")\n",
    "\n",
    "cards_df['credit_limit'] = cards_df['credit_limit'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
    "#####ä¸è¦loadé€™è¡Œ cards_df[\"acct_open_date\"]=pd.to_datetime(cards_df[\"acct_open_date\"], format=\"%m/%Y\")\n",
    "cards_df[\"acct_open_date\"] = pd.to_datetime(cards_df[\"acct_open_date\"], format=\"%m/%Y\").dt.to_period(\"M\")\n",
    "#####ä¸è¦loadé€™è¡Œ cards_df[\"year_pin_last_changed\"]=pd.to_datetime(cards_df[\"year_pin_last_changed\"], format=\"%Y\")\n",
    "cards_df[\"year_pin_last_changed\"] = pd.to_datetime(cards_df[\"year_pin_last_changed\"], format=\"%Y\").dt.to_period(\"Y\")\n",
    "cards_df[\"card_on_dark_web\"]=cards_df[\"card_on_dark_web\"].astype(\"category\") \n",
    "\n",
    "##users_df##\n",
    "users_df[\"birth_year\"] = pd.to_datetime(users_df[\"birth_year\"], format=\"%Y\").dt.to_period(\"Y\")\n",
    "users_df[\"birth_month\"] = pd.to_datetime(users_df[\"birth_month\"], format=\"%m\").dt.to_period(\"M\")\n",
    "users_df[\"gender\"]=users_df[\"gender\"].astype(\"category\") \n",
    "users_df['per_capita_income'] = users_df['per_capita_income'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
    "users_df['yearly_income'] = users_df['yearly_income'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
    "users_df['total_debt'] = users_df['total_debt'].replace(r'[\\$,]', '', regex=True).astype(int)\n",
    "\n",
    "##transactions_df##\n",
    "transactions_df[\"date\"] = pd.to_datetime(transactions_df[\"date\"])\n",
    "#æµ®é»æ•¸è½‰æ•´æ•¸åŸå› ç¢ºå®šï¼Ÿ\n",
    "transactions_df['amount'] = transactions_df['amount'].replace(r'[\\$,]', '', regex=True).astype(float).astype(int)\n",
    "##è² æ•¸å–logèª¿æˆ1\n",
    "#transactions_df['amount'] = transactions_df['amount'].replace(r'[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "transactions_df[\"use_chip\"]=transactions_df[\"use_chip\"].astype(\"category\") \n",
    "\n",
    "transactions_df.loc[\n",
    "    transactions_df['merchant_city'].str.lower() == 'online',\n",
    "    'merchant_state'\n",
    "] = 'online'\n",
    "\n",
    "transactions_df.loc[\n",
    "    transactions_df['merchant_city'].str.lower() == 'online',\n",
    "    'zip'\n",
    "] = 20000 #åŸæœ¬æ˜¯-1\n",
    "## æˆ‘æ²’æœ‰å…¨éƒ¨æ”¹ï¼Œé€™æ¨£å®Œä¹‹å¾Œä»æœ‰89006ç­†Missingï¼Œå‰©ä¸‹éƒ½æ˜¯åœ¨åœ‹å¤–\n",
    "transactions_df['zip'] = transactions_df['zip'].fillna(10000) #åŸæœ¬æ˜¯-999\n",
    "transactions_df[\"zip\"]=transactions_df[\"zip\"].astype(\"int64\")\n",
    "\n",
    "transactions_df['errors'] = transactions_df['errors'].astype('category')\n",
    "transactions_df['errors'] = transactions_df['errors'].cat.add_categories('No_error').fillna('No_error')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cars one hot encoding\n",
    "##çµ±ä¸€é¡åˆ¥è®Šæ•¸è½‰dummy variable(è¦æ³¨æ„å…±ç·šæ€§å•é¡Œï¼Œæ‡‰åˆªæ‰å…¶ä¸­ä¹‹ä¸€)\n",
    "\n",
    "#card_type åŸå§‹ç¨®é¡ï¼šDebit_57%, Credit_33%, Debit(Prepaid)_9%\n",
    "#card_brand åŸå§‹ç¨®é¡ï¼šMasterCard_52%, Visa_38%, Amex_7%, Discovery_3%\n",
    "#has_chip åŸå§‹ç¨®é¡ï¼šYes_89%, No_11%\n",
    "#card_on_dark_web åŸå§‹ç¨®é¡ï¼šNo_0%\n",
    "cols_to_encode = ['card_type', 'card_brand', 'has_chip']\n",
    "cards_df[cols_to_encode] = cards_df[cols_to_encode].astype('category')\n",
    "dummies_cards = pd.get_dummies(\n",
    "    cards_df[cols_to_encode], \n",
    "    prefix=cols_to_encode, \n",
    "    dtype='uint8'\n",
    "    )\n",
    "cards_df = pd.concat([cards_df, dummies_cards], axis=1)\n",
    "\n",
    "#use_chip åŸå§‹ç¨®é¡ï¼šSwiped_52%, Chipe_36%, Online_12%\n",
    "dummies_use = pd.get_dummies(transactions_df['use_chip'], prefix='use_chip', dtype='uint8')\n",
    "transactions_df = pd.concat([transactions_df, dummies_use], axis=1)\n",
    "\n",
    "#gender åŸå§‹ç¨®é¡ï¼šFemale_51%, Male_49%\n",
    "dummies_gender = pd.get_dummies(users_df['gender'], prefix='gender', dtype='uint8')\n",
    "users_df = pd.concat([users_df, dummies_gender], axis=1)\n",
    "\n",
    "\n",
    "cards_df.drop(columns=[\"has_chip_NO\",\"has_chip\"], inplace=True)\n",
    "transactions_df.drop(columns=[\"use_chip\"], inplace=True)\n",
    "users_df.drop(columns=[\"gender_Female\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_è³‡æ–™æ•´ä½µæˆä¸€å¼µdataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02-1_è³‡æ–™æ•´ä½µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transactions_df.loc[transactions_df[\"transaction_id\"] == 10649266] #transaction_id vs id\n",
    "\n",
    "#åŸå§‹è³‡æ–™ç­†æ•¸ï¼š13305915\n",
    "### transactions_df+train_fraud_labels_df      left æœƒæœ‰4390952 missing values\n",
    "merged = pd.merge(transactions_df, train_fraud_labels_df, left_on=\"transaction_id\", right_on=\"transactions_id\", how=\"outer\")\n",
    "### transactions_df train_fraud_labels_df(8914963) + users_df å°éå»ä¸æœƒæœ‰missing values\n",
    "merged = pd.merge(merged,users_df , left_on=\"client_id\", right_on=\"client_id\", how=\"left\")\n",
    "### transactions_df train_fraud_labels_df users_df + cards_df å°éå»ä¸æœƒæœ‰missing values\n",
    "merged = pd.merge(merged,cards_df , left_on=\"card_id\", right_on=\"card_id\", how=\"left\")\n",
    "\n",
    "#åˆªæ‰é‡è¤‡çš„columns\n",
    "merged.drop(columns=[\"transactions_id\"], inplace=True)\n",
    "merged.drop(columns=[\"client_id_y\"], inplace=True)\n",
    "\n",
    "## åˆä½µå®Œä¹‹å¾Œæœ€å¾Œè™•ç†is_fraud(åŸæœƒæœ‰missing valueså•é¡Œ)\n",
    "merged[\"is_fraud\"] = merged[\"is_fraud\"].astype(str)\n",
    "merged.loc[merged['is_fraud'].str.lower() == 'no','is_fraud'] = '0'\n",
    "merged.loc[merged['is_fraud'].str.lower() == 'yes','is_fraud'] = '1'\n",
    "merged[\"is_fraud\"] = pd.to_numeric(merged[\"is_fraud\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "merged = add_missing_flags(merged, [\"is_fraud\"])\n",
    "\n",
    "#merged.to_csv(\"merged.csv\", index=False)\n",
    "\n",
    "# å…ˆåˆªé™¤ä¸éœ€è¦çš„DataFrameä»¥ç¯€çœè¨˜æ†¶é«”\n",
    "del transactions_df, users_df, cards_df, train_fraud_labels_df, cols_to_encode, dummies_cards, dummies_use, dummies_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backup_merged = merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04_RFM + DK é‡é»å¾®èª¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged = backup_merged.copy() ##æœ‰å‡ºäº‹å†è¶•å¿«å›å¾©åŸç‹€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04_RFM features engineering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04-1_RFM features æ–°å¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ç¢ºä¿æ—¥æœŸæ˜¯ datetime ä¸¦æ’åº\n",
    "merged['date'] = pd.to_datetime(merged['date'])\n",
    "merged = merged.sort_values(by=['client_id_x', 'date']).reset_index(drop=True)\n",
    "\n",
    "# --- RecencyInterval ---\n",
    "merged['RecencyInterval'] = merged.groupby('client_id_x')['date'].diff().dt.total_seconds().fillna(0)/60\n",
    "\n",
    "# --- TxnFrequency for multiple windows (å‘é‡åŒ–æ»‘å‹•çª—å£) ---\n",
    "window_days = [7, 30, 60, 90]\n",
    "for w in window_days:\n",
    "    merged[f'TxnFrequency_{w}d'] = 0\n",
    "\n",
    "def compute_freq_vectorized(dates, windows):\n",
    "    \"\"\"å‘é‡åŒ–è¨ˆç®—æ¯ç­†äº¤æ˜“åœ¨æ¯å€‹ window å…§çš„äº¤æ˜“æ•¸\"\"\"\n",
    "    n = len(dates)\n",
    "    dates_int = dates.values.astype('datetime64[D]').astype(int)\n",
    "    res = {w: np.zeros(n, dtype=int) for w in windows}\n",
    "    for w in windows:\n",
    "        left = 0\n",
    "        counts = np.zeros(n, dtype=int)\n",
    "        for right in range(n):\n",
    "            while dates_int[right] - dates_int[left] > w:\n",
    "                left += 1\n",
    "            counts[right] = right - left + 1\n",
    "        res[w] = counts\n",
    "    return res\n",
    "\n",
    "# åˆ†çµ„è¨ˆç®—\n",
    "for cid, g in merged.groupby('client_id_x', sort=False):\n",
    "    freq_dict = compute_freq_vectorized(g['date'], window_days)\n",
    "    for w in window_days:\n",
    "        merged.loc[g.index, f'TxnFrequency_{w}d'] = freq_dict[w]\n",
    "\n",
    "# --- AmtDelta ---\n",
    "merged['prev_amount'] = merged.groupby('client_id_x')['amount'].shift(1)\n",
    "merged['AmtDelta'] = merged['amount'] - merged['prev_amount']\n",
    "merged['AmtDelta'] = merged['AmtDelta'].fillna(0)\n",
    "merged.drop(columns='prev_amount', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04-3_DK features æ–°å¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# US region mapping\n",
    "us_region_map = {\n",
    "    'Northeast': ['NY','NJ','PA','MA','CT','RI','NH','VT','ME'],\n",
    "    'Midwest': ['IL','OH','MI','IN','WI','MN','IA','MO','ND','SD','NE','KS'],\n",
    "    'South': ['FL','GA','SC','NC','AL','MS','LA','TX','OK','TN','KY','VA','WV','AR','MD','DE','DC'],\n",
    "    'West': ['CA','WA','OR','NV','AZ','NM','CO','UT','ID','MT','WY','AK','HI'],\n",
    "}\n",
    "continent_map = {\n",
    "    'Europe': [ ... ],  # åŸæœ¬ continent_map['Europe'] å¯ç›´æ¥ä½¿ç”¨\n",
    "    'Online': ['online','AA']\n",
    "}\n",
    "\n",
    "us_region_lookup = {state: region for region, states in us_region_map.items() for state in states}\n",
    "\n",
    "# --- å‘é‡åŒ– location ç‰¹å¾µ ---\n",
    "merged['merchant_online'] = merged['merchant_state'].eq('online').astype('uint8')\n",
    "merged['merchant_us'] = merged['merchant_state'].isin(us_region_lookup.keys()).astype('uint8')\n",
    "merged['merchant_eu'] = merged['merchant_state'].isin(continent_map['Europe']).astype('uint8')\n",
    "merged['merchant_others'] = (~merged[['merchant_online','merchant_us','merchant_eu']].any(axis=1)).astype('uint8')\n",
    "\n",
    "# --- é¦–æ¬¡äº¤æ˜“æ¨™è¨˜ ---\n",
    "merged['FirstTxnInRegion'] = (~merged.duplicated(subset=['client_id_x', 'merchant_state'])).astype('uint8')\n",
    "\n",
    "# DifferentState\n",
    "merged['prev_state']=(merged\n",
    "                     .groupby('client_id_x')['merchant_state']\n",
    "                     .shift(1))\n",
    "\n",
    "merged['DifferentState'] = (\n",
    "    (merged['merchant_state'] != merged['prev_state'])\n",
    "    & merged['prev_state'].notna()\n",
    ").astype(int)\n",
    "\n",
    "merged = merged.drop(columns=['prev_state'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04-3_è³‡æ–™é€²è¡Œè®Šæ•¸è½‰æ›ä»¥æ±‚æ¨¡å‹é…é£¾æ›´ä½³è¡¨ç¾(ä¸ä¸€æ¨£)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged[[\"card_id\",\"card_number\"]]\n",
    "import numpy as np\n",
    "from scipy import stats \n",
    "\n",
    "# === (1) logè½‰æ› ===\n",
    "merged['amount'] = np.where(merged['amount'] < 0, 0, merged['amount'])  # è² æ•¸è®Š 0\n",
    "merged['amount'] = np.log(merged['amount'] + 1)  \n",
    "\n",
    "# === (3) å¹³æ–¹æ ¹è½‰æ› ===\n",
    "merged['credit_limit']=np.sqrt(merged['credit_limit'])\n",
    "merged['total_debt']=np.sqrt(merged['total_debt'])\n",
    "\n",
    "# === (3) ç«‹æ–¹æ ¹è½‰æ› ===\n",
    "merged['yearly_income']=np.cbrt(merged['yearly_income'])\n",
    "merged['per_capita_income']=np.cbrt(merged['per_capita_income'])\n",
    "\n",
    "## Box-Cox Transformation\n",
    "###merged['yearly_income'], fitted_lambda = stats.boxcox(merged['yearly_income'])\n",
    "\n",
    "# === (5) Yeoâ€“Johnson è½‰æ›ï¼ˆå¯è™•ç†è² å€¼ï¼‰ ===\n",
    "###merged['per_capita_income'], lambdaValue =stats.yeojohnson(merged['per_capita_income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04-4_åˆ†å‰²è¨“ç·´é›†åŠæ¸¬è©¦é›†ã€ä¸åŒblock ä¸¦å¾é€™è£¡æ‰è¨ˆç®— HighRiskMCC é¿å…è³‡æ–™æ´©æ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Block 0\n",
      "\n",
      "Processing Block 1\n",
      "\n",
      "Processing Block 2\n",
      "\n",
      "Processing Block 3\n",
      "\n",
      "Processing Block 4\n",
      "\n",
      "Processing Block 5\n",
      "\n",
      "Processing Block 6\n",
      "\n",
      "Processing Block 7\n",
      "\n",
      "Processing Block 8\n",
      "\n",
      "Processing Block 9\n",
      "\n",
      "Block 0\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    663110\n",
      "1      2113\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    165846\n",
      "1       460\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 1\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    690705\n",
      "1        37\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    172686\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 2\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    707413\n",
      "1       923\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    177085\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 3\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    725007\n",
      "1       836\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    180960\n",
      "1       501\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 4\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    731394\n",
      "1       664\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    183015\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 5\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    742735\n",
      "1      1444\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    185300\n",
      "1       745\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 6\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    744145\n",
      "1      2064\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    186169\n",
      "1       384\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 7\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    749827\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    187285\n",
      "1       172\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 8\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    746455\n",
      "1      1224\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    186515\n",
      "1       405\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Block 9\n",
      "Train fraud count:\n",
      "is_fraud\n",
      "0    620778\n",
      "1      1093\n",
      "Name: count, dtype: Int64\n",
      "Test fraud count:\n",
      "is_fraud\n",
      "0    155201\n",
      "1       267\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# --- é¸å–æ•¸å€¼å‹è®Šæ•¸ ---\n",
    "num_cols = merged.select_dtypes(include=['int64', 'float64','uint8','datetime64[ns]']).columns\n",
    "df2 = merged[num_cols]\n",
    "\n",
    "# --- dropna ---\n",
    "df_cleaned = df2.dropna()\n",
    "del df2\n",
    "\n",
    "# --- é¿å…å…±ç·šæ€§ ---\n",
    "df_cleaned.drop(columns=[\"is_fraud_missing_flag\",\"card_type_Debit (Prepaid)\", \n",
    "                         \"card_brand_Discover\", \"use_chip_Online Transaction\"], inplace=True)\n",
    "\n",
    "# --- ç¢ºä¿ date æ¬„ä½åœ¨ df_cleaned ä¸­ ---\n",
    "if 'date' not in df_cleaned.columns:\n",
    "    df_cleaned['date'] = merged.loc[df_cleaned.index, 'date']\n",
    "\n",
    "# --- ä¾æ™‚é–“æ’åº ---\n",
    "df_sorted = df_cleaned.sort_values('date')\n",
    "df_sorted['year'] = df_sorted['date'].dt.year\n",
    "\n",
    "# 2010â€“2011 â†’ block 0\n",
    "# 2012â€“2013 â†’ block 1\n",
    "# ...\n",
    "# 2018â€“2019 â†’ block 4ï¼ˆå¦‚æœä½ çœŸçš„æ˜¯ 2010â€“2019 å…± 10 å¹´ï¼Œæœƒæœ‰ 5 å€‹ blockï¼‰\n",
    "df_sorted['time_block'] = (df_sorted['year'] - 2010) // 1\n",
    "\n",
    "\n",
    "#å°æ¯å€‹æ™‚é–“blockåšåˆ‡å‰²\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    print(f\"\\nProcessing Block {block_id}\")\n",
    "\n",
    "    block_df = block_df.sort_values('date')\n",
    "    split_index = int(len(block_df) * 0.8)\n",
    "\n",
    "    train_block = block_df.iloc[:split_index].copy()\n",
    "    test_block  = block_df.iloc[split_index:].copy()\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1ï¸âƒ£ ç”¨ã€Œè©² block çš„ trainã€ç®— fraud rate\n",
    "    # -----------------------------\n",
    "    fraud_rate = (\n",
    "        train_block\n",
    "        .groupby('mcc_code')['is_fraud']\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    high_risk_mcc = fraud_rate[fraud_rate > 0.02].index\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2ï¸âƒ£ å¥—ç”¨åˆ°è©² block çš„ train / test\n",
    "    # -----------------------------\n",
    "    train_block['HighRiskMCC'] = train_block['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "    test_block['HighRiskMCC']  = test_block['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "\n",
    "    train_list.append(train_block)\n",
    "    test_list.append(test_block)\n",
    "\n",
    "\n",
    "train_df = pd.concat(train_list).drop(columns=['date', 'year', 'time_block'])\n",
    "test_df  = pd.concat(test_list).drop(columns=['date', 'year', 'time_block'])\n",
    "\n",
    "\n",
    "#æ¯”ä¾‹æª¢æŸ¥\n",
    "for block_id in sorted(df_sorted['time_block'].unique()):\n",
    "    print(f\"\\nBlock {block_id}\")\n",
    "    print(\"Train fraud count:\")\n",
    "    print(train_df.loc[df_sorted['time_block'] == block_id, 'is_fraud'].value_counts())\n",
    "    print(\"Test fraud count:\")\n",
    "    print(test_df.loc[df_sorted['time_block'] == block_id, 'is_fraud'].value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04-5_å®šç¾©ä¸åŒçš„features group æ–¹ä¾¿æ¨¡å‹é‹ç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "result = pd.DataFrame(columns=[\n",
    "    \"Model\", \"Features\", \n",
    "    \"Train AUC\", \"Test AUC\", \n",
    "    \"Train PR AUC\", \"Test PR AUC\"\n",
    "])\n",
    "\n",
    "'''\n",
    "\n",
    "# ALL features\n",
    "\n",
    "all_cols = ['transaction_id', 'date', 'client_id_x', 'card_id', 'amount',\n",
    "       'merchant_id', 'merchant_city', 'merchant_state', 'zip', 'mcc_code',\n",
    "       'errors', 'merchant_state_missing_flag', 'zip_missing_flag',\n",
    "       'errors_missing_flag', 'use_chip_Chip Transaction',\n",
    "       'use_chip_Online Transaction', 'use_chip_Swipe Transaction',\n",
    "       'current_age', 'retirement_age', 'birth_year', 'birth_month', 'gender',\n",
    "       'address', 'latitude', 'longitude', 'per_capita_income',\n",
    "       'yearly_income', 'total_debt', 'credit_score', 'num_credit_cards',\n",
    "       'gender_Male', 'card_brand', 'card_type', 'card_number', 'expires',\n",
    "       'cvv', 'num_cards_issued', 'credit_limit', 'acct_open_date',\n",
    "       'year_pin_last_changed', 'card_on_dark_web', 'card_type_Credit',\n",
    "       'card_type_Debit', 'card_type_Debit (Prepaid)', 'card_brand_Amex',\n",
    "       'card_brand_Discover', 'card_brand_Mastercard', 'card_brand_Visa',\n",
    "       'has_chip_YES', 'is_fraud_missing_flag']\n",
    "\n",
    "VIF_col = [\"is_fraud_missing_flag\",\"card_type_Debit (Prepaid)\", \n",
    "                         \"card_brand_Discover\", \"use_chip_Online Transaction\",'is_fraud_missing_flag','merchant_state_missing_flag', 'zip_missing_flag','card_on_dark_web','errors_missing_flag']\n",
    "\n",
    "identifier = [\n",
    "    'transaction_id',\n",
    "    'client_id_x',\n",
    "    'card_id',\n",
    "    'card_number',\n",
    "    'cvv'\n",
    "]\n",
    "\n",
    "leakage_cols = ['latitude', 'longitude', 'zip','merchant_id','mcc_code'] #geminiå»ºè­°\n",
    "\n",
    "\n",
    "set_VIF = set(VIF_col)\n",
    "set_identifier =set(identifier)\n",
    "exclude_cols = set(VIF_col) | set(identifier)| set(leakage_cols)\n",
    "all_cols = [x for x in all_cols if x not in exclude_cols]\n",
    "\n",
    "\n",
    "# RFM features\n",
    "rfm_cols = [\n",
    "    'RecencyInterval', 'TxnFrequency_7d','TxnFrequency_30d',\n",
    "    'TxnFrequency_60d', 'TxnFrequency_90d','AmtDelta'\n",
    "]\n",
    "\n",
    "# DK features\n",
    "dk_cols = [\n",
    "    'merchant_online', 'merchant_us', 'merchant_eu', 'merchant_others',\n",
    "    'FirstTxnInRegion','HighRiskMCC','DifferentState'\n",
    "]\n",
    "\n",
    "# Grouping\n",
    "feature_groups = {\n",
    "    \"X_all\": all_cols,\n",
    "    \"X_rfm\": rfm_cols,\n",
    "    \"X_dk\": dk_cols,\n",
    "    \"X_all + X_rfm\": all_cols + rfm_cols,\n",
    "    \"X_all + X_dk\": all_cols + dk_cols,\n",
    "    \"X_rfm + X_dk\": rfm_cols + dk_cols,\n",
    "    \"X_all + X_rfm + X_dk\": all_cols + rfm_cols + dk_cols\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04-6_Assumption: Avoid Multicollinearityï¼ˆè€å¸«å»ºè­°æˆ‘å€‘å…ˆçœç•¥ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n##è™•ç†é«˜åº¦å…±ç·šæ€§è®Šæ•¸\\ntrain_df.drop(columns=[\"per_capita_income\"], inplace=True)\\ntrain_df.drop(columns=[\"use_chip_Chip Transaction\",\"merchant_state_missing_flag\",\"zip_missing_flag\"], inplace=True)           \\ntrain_df.drop(columns=[\"card_brand_Visa\" ,\"card_brand_Amex\",\"card_type_Credit\"], inplace=True)\\n\\ntest_df.drop(columns=[\"per_capita_income\"], inplace=True)\\ntest_df.drop(columns=[\"use_chip_Chip Transaction\",\"merchant_state_missing_flag\",\"zip_missing_flag\"], inplace=True)           \\ntest_df.drop(columns=[\"card_brand_Visa\" ,\"card_brand_Amex\",\"card_type_Credit\"], inplace=True)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "##è™•ç†é«˜åº¦å…±ç·šæ€§è®Šæ•¸\n",
    "train_df.drop(columns=[\"per_capita_income\"], inplace=True)\n",
    "train_df.drop(columns=[\"use_chip_Chip Transaction\",\"merchant_state_missing_flag\",\"zip_missing_flag\"], inplace=True)           \n",
    "train_df.drop(columns=[\"card_brand_Visa\" ,\"card_brand_Amex\",\"card_type_Credit\"], inplace=True)\n",
    "\n",
    "test_df.drop(columns=[\"per_capita_income\"], inplace=True)\n",
    "test_df.drop(columns=[\"use_chip_Chip Transaction\",\"merchant_state_missing_flag\",\"zip_missing_flag\"], inplace=True)           \n",
    "test_df.drop(columns=[\"card_brand_Visa\" ,\"card_brand_Amex\",\"card_type_Credit\"], inplace=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05_Features Selection éƒ¨åˆ†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05-1_Stepwise selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 0 (Year: 2010)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 19)... âœ… Selected 6 feats | Test AUC: 0.9164\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 4 feats | Test AUC: 0.7408\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 4 feats | Test AUC: 0.9654\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 25)... âœ… Selected 10 feats | Test AUC: 0.9411\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 25)... âœ… Selected 8 feats | Test AUC: 0.917\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 7 feats | Test AUC: 0.9295\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 31)... âœ… Selected 12 feats | Test AUC: 0.9768\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 1 (Year: 2011)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 19)... âœ… Selected 2 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 1 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 2 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 25)... âœ… Selected 7 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 25)... âœ… Selected 3 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 5 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 31)... âœ… Selected 7 feats | Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 2 (Year: 2012)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 19)... âœ… Selected 3 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 4 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 1 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 25)... âœ… Selected 6 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 25)... âœ… Selected 3 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 4 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 31)... âœ… Selected 6 feats | Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 3 (Year: 2013)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 19)... âœ… Selected 8 feats | Test AUC: 0.8869\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 5 feats | Test AUC: 0.7592\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 3 feats | Test AUC: 0.8517\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 25)... âœ… Selected 13 feats | Test AUC: 0.9269\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 25)... âœ… Selected 12 feats | Test AUC: 0.8812\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 8 feats | Test AUC: 0.9083\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 31)... âœ… Selected 15 feats | Test AUC: 0.9182\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 4 (Year: 2014)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 19)... âœ… Selected 12 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 4 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 3 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 25)... âœ… Selected 14 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 25)... âœ… Selected 12 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 6 feats | Test AUC: nan\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 31)... âœ… Selected 17 feats | Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 5 (Year: 2015)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 19)... âœ… Selected 11 feats | Test AUC: 0.9023\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 5 feats | Test AUC: 0.7445\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 2 feats | Test AUC: 0.8461\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 25)... âœ… Selected 18 feats | Test AUC: 0.9223\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 25)... âœ… Selected 13 feats | Test AUC: 0.8911\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 7 feats | Test AUC: 0.8956\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 31)... âœ… Selected 17 feats | Test AUC: 0.9159\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 6 (Year: 2016)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 19)... âœ… Selected 9 feats | Test AUC: 0.9169\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 4 feats | Test AUC: 0.7314\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 2 feats | Test AUC: 0.8589\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 25)... âœ… Selected 11 feats | Test AUC: 0.9391\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 25)... âœ… Selected 10 feats | Test AUC: 0.9097\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 6 feats | Test AUC: 0.9192\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 31)... âœ… Selected 15 feats | Test AUC: 0.9326\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 7 (Year: 2017)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 19)... âš ï¸ Skipped: Train set has only 1 class (value: 0)\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âš ï¸ Skipped: Train set has only 1 class (value: 0)\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âš ï¸ Skipped: Train set has only 1 class (value: 0)\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 25)... âš ï¸ Skipped: Train set has only 1 class (value: 0)\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 25)... âš ï¸ Skipped: Train set has only 1 class (value: 0)\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âš ï¸ Skipped: Train set has only 1 class (value: 0)\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 31)... âš ï¸ Skipped: Train set has only 1 class (value: 0)\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 8 (Year: 2018)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 19)... âœ… Selected 5 feats | Test AUC: 0.5399\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 5 feats | Test AUC: 0.7371\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 3 feats | Test AUC: 0.9158\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 25)... âœ… Selected 11 feats | Test AUC: 0.7052\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 25)... âœ… Selected 7 feats | Test AUC: 0.665\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 7 feats | Test AUC: 0.8452\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 31)... âœ… Selected 11 feats | Test AUC: 0.8015\n",
      "\n",
      "============================================================\n",
      "ğŸ§© Stepwise Selection for Block 9 (Year: 2019)\n",
      "============================================================\n",
      "   ğŸ”¸ Group: X_all (Pool: 19)... âœ… Selected 6 feats | Test AUC: 0.6495\n",
      "   ğŸ”¸ Group: X_rfm (Pool: 6)... âœ… Selected 4 feats | Test AUC: 0.7204\n",
      "   ğŸ”¸ Group: X_dk (Pool: 6)... âœ… Selected 2 feats | Test AUC: 0.7503\n",
      "   ğŸ”¸ Group: X_all + X_rfm (Pool: 25)... âœ… Selected 10 feats | Test AUC: 0.7493\n",
      "   ğŸ”¸ Group: X_all + X_dk (Pool: 25)... âœ… Selected 8 feats | Test AUC: 0.7951\n",
      "   ğŸ”¸ Group: X_rfm + X_dk (Pool: 12)... âœ… Selected 7 feats | Test AUC: 0.8865\n",
      "   ğŸ”¸ Group: X_all + X_rfm + X_dk (Pool: 31)... âœ… Selected 11 feats | Test AUC: 0.8628\n",
      "\n",
      "ğŸ‰ Stepwise Selection Completed!\n",
      "è®Šæ•¸çµæœå·²å„²å­˜æ–¼ 'stepwise_feature_storage' å­—å…¸ä¸­ã€‚\n",
      "\n",
      "=== Stepwise Logistic Regression è®Šæ•¸ç¯©é¸æˆæ•ˆè¡¨ ===\n",
      "Year                      2010                                        2011                                        2012                                        2013                                        2014                                        2015                                        2016                                        2017                                        2018                                        2019                                  \n",
      "                     Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC\n",
      "Feature Group                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "X_all                   0.9292   0.9164       0.0754      0.0665    0.9418      NaN       0.0022         NaN    0.8299      NaN       0.0124         NaN    0.9188   0.8869       0.0435      0.0547    0.9134      NaN       0.0402         NaN    0.9182   0.9023       0.0823      0.0874    0.9158   0.9169       0.0735      0.0709       NaN      NaN          NaN         NaN    0.6638   0.5399       0.0039      0.0029    0.6797   0.6495       0.0039      0.0027\n",
      "X_all + X_dk            0.9351   0.9170       0.0829      0.1546    0.9437      NaN       0.0057         NaN    0.8299      NaN       0.0124         NaN    0.9071   0.8812       0.0723      0.0836    0.9033      NaN       0.0607         NaN    0.9074   0.8911       0.1269      0.1298    0.9095   0.9097       0.1046      0.1129       NaN      NaN          NaN         NaN    0.8311   0.6650       0.0270      0.0247    0.8287   0.7951       0.0270      0.0182\n",
      "X_all + X_rfm           0.9394   0.9411       0.0820      0.1499    0.9618      NaN       0.0078         NaN    0.8861      NaN       0.0280         NaN    0.9416   0.9269       0.1028      0.1379    0.9291      NaN       0.1021         NaN    0.9374   0.9223       0.1242      0.1677    0.9314   0.9391       0.1012      0.0689       NaN      NaN          NaN         NaN    0.7816   0.7052       0.0073      0.0070    0.7598   0.7493       0.0063      0.0050\n",
      "X_all + X_rfm + X_dk    0.9727   0.9768       0.1240      0.2117    0.9585      NaN       0.0179         NaN    0.8861      NaN       0.0280         NaN    0.9360   0.9182       0.1355      0.2012    0.9244      NaN       0.1540         NaN    0.9313   0.9159       0.1576      0.2163    0.9271   0.9326       0.1476      0.1139       NaN      NaN          NaN         NaN    0.8774   0.8015       0.0369      0.0289    0.8729   0.8628       0.0341      0.0310\n",
      "X_dk                    0.9612   0.9654       0.0565      0.0584    0.9285      NaN       0.0008         NaN    0.8200      NaN       0.0069         NaN    0.8606   0.8517       0.0129      0.0296    0.8576      NaN       0.0101         NaN    0.8533   0.8461       0.0184      0.0333    0.8551   0.8589       0.0221      0.0174       NaN      NaN          NaN         NaN    0.9435   0.9158       0.0473      0.0338    0.7623   0.7503       0.0114      0.0108\n",
      "X_rfm                   0.6917   0.7408       0.0084      0.0272    0.5822      NaN       0.0005         NaN    0.7197      NaN       0.0040         NaN    0.7740   0.7592       0.0065      0.0146    0.7456      NaN       0.0058         NaN    0.7475   0.7445       0.0099      0.0181    0.7114   0.7314       0.0091      0.0104       NaN      NaN          NaN         NaN    0.7465   0.7371       0.0061      0.0083    0.7026   0.7204       0.0051      0.0047\n",
      "X_rfm + X_dk            0.9363   0.9295       0.0764      0.1830    0.9535      NaN       0.0053         NaN    0.8862      NaN       0.0275         NaN    0.9230   0.9083       0.0759      0.1623    0.9141      NaN       0.0846         NaN    0.9118   0.8956       0.0997      0.1574    0.9102   0.9192       0.0941      0.0733       NaN      NaN          NaN         NaN    0.8609   0.8452       0.0255      0.0255    0.8879   0.8865       0.0305      0.0319\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import warnings\n",
    "\n",
    "# å¿½ç•¥ statsmodels å¯èƒ½ç”¢ç”Ÿçš„è¿­ä»£è­¦å‘Šï¼Œä¿æŒè¼¸å‡ºä¹¾æ·¨\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ===========================================================\n",
    "# 1. æ ¸å¿ƒå‡½æ•¸ï¼šåš´è¬¹ç‰ˆ Stepwise (Forward + Backward)\n",
    "# ===========================================================\n",
    "\n",
    "def check_data_validity(y_data, stage=\"Train\"):\n",
    "    \"\"\"æª¢æŸ¥è³‡æ–™æ˜¯å¦è¶³å¤ é€²è¡Œ Logistic Regression\"\"\"\n",
    "    if len(y_data) == 0:\n",
    "        return False, f\"{stage} set is empty\"\n",
    "    if y_data.nunique() < 2:\n",
    "        val = y_data.iloc[0] if len(y_data) > 0 else \"None\"\n",
    "        return False, f\"{stage} set has only 1 class (value: {val})\"\n",
    "    return True, \"\"\n",
    "\n",
    "def run_stepwise_logit(train_df, test_df, feature_cols, dep_var=\"is_fraud\", \n",
    "                       threshold_in=0.01, threshold_out=0.05, max_iter=50):\n",
    "    \"\"\"\n",
    "    Stepwise Selection based on P-values (Forward Selection + Backward Elimination)\n",
    "    \"\"\"\n",
    "    # --- 1. æº–å‚™æ•¸æ“š ---\n",
    "    X_train = train_df[feature_cols].fillna(0)\n",
    "    y_train = train_df[dep_var]\n",
    "    X_test  = test_df[feature_cols].fillna(0)\n",
    "    y_test  = test_df[dep_var]\n",
    "\n",
    "    # --- 2. é˜²å´©æ½°æª¢æŸ¥ (Edge Case Handling) ---\n",
    "    is_valid_train, msg_train = check_data_validity(y_train, \"Train\")\n",
    "    if not is_valid_train:\n",
    "        return {\"status\": \"skip\", \"message\": msg_train}\n",
    "    \n",
    "    # æ¸¬è©¦é›†è‹¥ç„¡æ•ˆï¼Œæ¨¡å‹ä»å¯è¨“ç·´ï¼Œåªæ˜¯ç„¡æ³•ç®— Test AUC\n",
    "    is_valid_test, _ = check_data_validity(y_test, \"Test\")\n",
    "\n",
    "    # --- 3. æ¨™æº–åŒ– (Standardization) ---\n",
    "    # Logistic å°è®Šæ•¸å°ºåº¦æ¥µå…¶æ•æ„Ÿï¼ŒStepwise å‰å‹™å¿…æ¨™æº–åŒ–\n",
    "    try:\n",
    "        scaler = StandardScaler()\n",
    "        X_train_std = pd.DataFrame(scaler.fit_transform(X_train), columns=feature_cols, index=train_df.index)\n",
    "        X_test_std  = pd.DataFrame(scaler.transform(X_test), columns=feature_cols, index=test_df.index)\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": f\"Scaling failed: {str(e)}\"}\n",
    "\n",
    "    # --- 4. è¿­ä»£ç¯©é¸ ---\n",
    "    included = []\n",
    "    candidates = list(feature_cols)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        changed = False\n",
    "        \n",
    "        # ====== Forward Step: å˜—è©¦åŠ å…¥ä¸€å€‹æœ€å¥½çš„è®Šæ•¸ ======\n",
    "        best_pval = 1.0\n",
    "        best_feature = None\n",
    "        \n",
    "        for candidate in candidates:\n",
    "            try:\n",
    "                # æš«æ™‚åŠ å…¥å€™é¸è®Šæ•¸\n",
    "                current_vars = included + [candidate]\n",
    "                X_const = sm.add_constant(X_train_std[current_vars])\n",
    "                \n",
    "                # è¨“ç·´ (disp=0 ä¸å°å‡º log)\n",
    "                model = sm.Logit(y_train, X_const).fit(disp=0, method='newton')\n",
    "                \n",
    "                # å–å¾—è©²è®Šæ•¸çš„ p-value\n",
    "                pval = model.pvalues[candidate]\n",
    "                \n",
    "                if pval < best_pval:\n",
    "                    best_pval = pval\n",
    "                    best_feature = candidate\n",
    "            except:\n",
    "                # è‹¥ç™¼ç”Ÿ Singular Matrix (çŸ©é™£å¥‡ç•°) æˆ–æ”¶æ–‚å¤±æ•—ï¼Œè·³éè©²è®Šæ•¸\n",
    "                continue\n",
    "        \n",
    "        # è‹¥ P-value å°æ–¼é–€æª»å‰‡åŠ å…¥\n",
    "        if best_feature is not None and best_pval < threshold_in:\n",
    "            included.append(best_feature)\n",
    "            candidates.remove(best_feature)\n",
    "            changed = True\n",
    "            # print(f\"    + Add: {best_feature} (p={best_pval:.4f})\")\n",
    "\n",
    "        # ====== Backward Step: å˜—è©¦ç§»é™¤ä¸€å€‹æœ€å·®çš„è®Šæ•¸ ======\n",
    "        if included:\n",
    "            try:\n",
    "                X_const = sm.add_constant(X_train_std[included])\n",
    "                model = sm.Logit(y_train, X_const).fit(disp=0)\n",
    "                \n",
    "                # æ‰¾å‡º p-value æœ€å¤§çš„è®Šæ•¸ (æ’é™¤ const)\n",
    "                pvalues = model.pvalues.drop('const', errors='ignore')\n",
    "                if not pvalues.empty:\n",
    "                    worst_pval = pvalues.max()\n",
    "                    worst_feature = pvalues.idxmax()\n",
    "                    \n",
    "                    # è‹¥ P-value å¤§æ–¼é–€æª»å‰‡ç§»é™¤\n",
    "                    if worst_pval > threshold_out:\n",
    "                        included.remove(worst_feature)\n",
    "                        candidates.append(worst_feature)\n",
    "                        changed = True\n",
    "                        # print(f\"    - Drop: {worst_feature} (p={worst_pval:.4f})\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if not changed:\n",
    "            break\n",
    "\n",
    "    # --- 5. æœ€çµ‚çµæœå›å‚³ ---\n",
    "    if not included:\n",
    "        return {\"status\": \"skip\", \"message\": \"No variables selected (all insignificant)\"}\n",
    "\n",
    "    # è¨ˆç®—ç•¶ä¸‹ Stepwise æ¨¡å‹çš„ Metrics (ä¾›åƒè€ƒ)\n",
    "    try:\n",
    "        X_train_final = sm.add_constant(X_train_std[included])\n",
    "        final_model = sm.Logit(y_train, X_train_final).fit(disp=0)\n",
    "        \n",
    "        train_prob = final_model.predict(X_train_final)\n",
    "        train_auc = roc_auc_score(y_train, train_prob)\n",
    "        train_pr  = average_precision_score(y_train, train_prob)\n",
    "        \n",
    "        test_auc = np.nan\n",
    "        test_pr = np.nan\n",
    "        \n",
    "        if is_valid_test:\n",
    "            try:\n",
    "                X_test_final = sm.add_constant(X_test_std[included])\n",
    "                test_prob = final_model.predict(X_test_final)\n",
    "                test_auc = roc_auc_score(y_test, test_prob)\n",
    "                test_pr  = average_precision_score(y_test, test_prob)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"selected_features\": included,  # <--- é‡é»ï¼šé¸å‡ºçš„è®Šæ•¸åˆ—è¡¨\n",
    "            \"metrics\": {\n",
    "                \"Train AUC\": round(train_auc, 4),\n",
    "                \"Test AUC\": round(test_auc, 4) if not np.isnan(test_auc) else np.nan,\n",
    "                \"Train PR-AUC\": round(train_pr, 4),\n",
    "                \"Test PR-AUC\": round(test_pr, 4) if not np.isnan(test_pr) else np.nan,\n",
    "                \"Num Features\": len(included)\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# 2. è¨­å®šèˆ‡ç‰¹å¾µç¾¤çµ„\n",
    "# ===========================================================\n",
    "\n",
    "# ç¢ºä¿ df_sorted å­˜åœ¨\n",
    "if 'df_sorted' not in locals():\n",
    "    raise ValueError(\"âš ï¸ Error: 'df_sorted' æœªå®šç¾©ï¼Œè«‹å…ˆè¼‰å…¥æ‚¨çš„è³‡æ–™ã€‚\")\n",
    "\n",
    "# å®šç¾©è¦æ’é™¤çš„æ¬„ä½\n",
    "identifier = ['transaction_id', 'client_id_x', 'card_id', 'card_number', 'cvv']\n",
    "exclude_cols = set(identifier) | {'is_fraud', 'date', 'year', 'time_block', 'HighRiskMCC'}\n",
    "\n",
    "def clean_cols(cols):\n",
    "    \"\"\"éæ¿¾æ‰ ID èˆ‡ Target ç­‰ä¸æ‡‰æ”¾å…¥æ¨¡å‹çš„æ¬„ä½\"\"\"\n",
    "    return [c for c in cols if c not in exclude_cols]\n",
    "\n",
    "# å®šç¾©æ‚¨çš„ Feature Groups\n",
    "# (å‡è¨­ all_cols, rfm_cols, dk_cols è®Šæ•¸å·²å­˜åœ¨æ–¼æ‚¨çš„ç’°å¢ƒä¸­)\n",
    "feature_groups = {\n",
    "    \"X_all\": clean_cols(all_cols),\n",
    "    \"X_rfm\": clean_cols(rfm_cols),\n",
    "    \"X_dk\": clean_cols(dk_cols),\n",
    "    \"X_all + X_rfm\": clean_cols(all_cols + rfm_cols),\n",
    "    \"X_all + X_dk\": clean_cols(all_cols + dk_cols),\n",
    "    \"X_rfm + X_dk\": clean_cols(rfm_cols + dk_cols),\n",
    "    \"X_all + X_rfm + X_dk\": clean_cols(all_cols + rfm_cols + dk_cols)\n",
    "}\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# 3. ä¸»åŸ·è¡Œè¿´åœˆ (å„²å­˜è®Šæ•¸ + ç”¢å‡ºåˆæ­¥å ±è¡¨)\n",
    "# ===========================================================\n",
    "\n",
    "# â˜… é€™æ˜¯æœ€é‡è¦çš„å„²å­˜å®¹å™¨ï¼š[Block ID][Group Name] -> [è®Šæ•¸åˆ—è¡¨]\n",
    "stepwise_feature_storage = {} \n",
    "stepwise_report_list = []\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    \n",
    "    current_year = 2010 + block_id\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ§© Stepwise Selection for Block {block_id} (Year: {current_year})\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # --- 1. æ™‚é–“åºåˆ—åˆ‡åˆ† (Temporal Split) ---\n",
    "    block_df = block_df.sort_values('date')\n",
    "    split_index = int(len(block_df) * 0.8)\n",
    "    \n",
    "    train_raw = block_df.iloc[:split_index].copy()\n",
    "    test_raw  = block_df.iloc[split_index:].copy()\n",
    "\n",
    "    # --- 2. ç‰¹å¾µå·¥ç¨‹ (Anti-Leakage) ---\n",
    "    # å¿…é ˆåœ¨åˆ‡åˆ†å¾Œæ‰åš Risk è¨ˆç®—\n",
    "    try:\n",
    "        fraud_rate = train_raw.groupby('mcc_code')['is_fraud'].mean()\n",
    "        high_risk_mcc = fraud_rate[fraud_rate > 0.02].index\n",
    "        train_raw['HighRiskMCC'] = train_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "        test_raw['HighRiskMCC']  = test_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "    except:\n",
    "        pass # è‹¥ train ç©ºäº†æœƒè¢«å¾Œé¢çš„ check æ“‹ä¸‹ï¼Œé€™è£¡å¿½ç•¥\n",
    "\n",
    "    # åˆå§‹åŒ–è©²å¹´ä»½çš„å„²å­˜ç©ºé–“\n",
    "    stepwise_feature_storage[block_id] = {}\n",
    "\n",
    "    # --- 3. é‡å°æ¯å€‹ Group è·‘ Stepwise ---\n",
    "    for group_name, feature_list in feature_groups.items():\n",
    "        \n",
    "        # ç¢ºä¿ç‰¹å¾µå­˜åœ¨\n",
    "        valid_features = [f for f in feature_list if f in train_raw.columns]\n",
    "        if not valid_features:\n",
    "            continue\n",
    "            \n",
    "        print(f\"   ğŸ”¸ Group: {group_name} (Pool: {len(valid_features)})...\", end=\" \")\n",
    "\n",
    "        # åŸ·è¡Œ Stepwise\n",
    "        res = run_stepwise_logit(\n",
    "            train_raw, \n",
    "            test_raw, \n",
    "            feature_cols=valid_features,\n",
    "            threshold_in=0.01,   # é¡¯è‘—æ‰å…¥é¸\n",
    "            threshold_out=0.05   # ä¸é¡¯è‘—å°±è¸¢é™¤\n",
    "        )\n",
    "\n",
    "        # è™•ç†çµæœ\n",
    "        if res[\"status\"] == \"success\":\n",
    "            m = res[\"metrics\"]\n",
    "            selected_feats = res[\"selected_features\"]\n",
    "            \n",
    "            print(f\"âœ… Selected {len(selected_feats)} feats | Test AUC: {m['Test AUC']}\")\n",
    "            \n",
    "            # (A) å­˜è®Šæ•¸ (çµ¦å¾ŒçºŒæ¨¡å‹ç”¨)\n",
    "            stepwise_feature_storage[block_id][group_name] = selected_feats\n",
    "            \n",
    "            # (B) å­˜å ±è¡¨æ•¸æ“š\n",
    "            row = {\n",
    "                \"Year\": current_year,\n",
    "                \"Feature Group\": group_name,\n",
    "                \"Train AUC\": m[\"Train AUC\"], \"Test AUC\": m[\"Test AUC\"],\n",
    "                \"Train PR-AUC\": m[\"Train PR-AUC\"], \"Test PR-AUC\": m[\"Test PR-AUC\"],\n",
    "                \"Num Features\": m[\"Num Features\"]\n",
    "            }\n",
    "            stepwise_report_list.append(row)\n",
    "            \n",
    "        elif res[\"status\"] == \"skip\":\n",
    "            print(f\"âš ï¸ Skipped: {res['message']}\")\n",
    "            stepwise_feature_storage[block_id][group_name] = [] # å­˜ç©º list\n",
    "            # å­˜ NaN å ±è¡¨\n",
    "            row = {\n",
    "                \"Year\": current_year, \"Feature Group\": group_name,\n",
    "                \"Train AUC\": np.nan, \"Test AUC\": np.nan,\n",
    "                \"Train PR-AUC\": np.nan, \"Test PR-AUC\": np.nan,\n",
    "                \"Num Features\": 0\n",
    "            }\n",
    "            stepwise_report_list.append(row)\n",
    "            \n",
    "        else:\n",
    "            print(f\"âŒ Error: {res['message']}\")\n",
    "            stepwise_feature_storage[block_id][group_name] = []\n",
    "\n",
    "print(\"\\nğŸ‰ Stepwise Selection Completed!\")\n",
    "print(f\"è®Šæ•¸çµæœå·²å„²å­˜æ–¼ 'stepwise_feature_storage' å­—å…¸ä¸­ã€‚\")\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# 4. é¡¯ç¤º Stepwise åˆæ­¥çµæœå ±è¡¨\n",
    "# ===========================================================\n",
    "if stepwise_report_list:\n",
    "    df_sw_raw = pd.DataFrame(stepwise_report_list)\n",
    "    \n",
    "    # è½‰ç½®è¡¨æ ¼ (Pivot) ä»¥ç¬¦åˆæ‚¨ç¿’æ…£çš„æ ¼å¼\n",
    "    target_metrics = [\"Train AUC\", \"Test AUC\", \"Train PR-AUC\", \"Test PR-AUC\"]\n",
    "    df_sw_pivot = df_sw_raw.pivot(index=\"Feature Group\", columns=\"Year\", values=target_metrics)\n",
    "    \n",
    "    # èª¿æ•´æ¬„ä½é †åº\n",
    "    df_sw_pivot.columns = df_sw_pivot.columns.swaplevel(0, 1)\n",
    "    unique_years = sorted(df_sw_raw[\"Year\"].unique())\n",
    "    ordered_columns = [(y, m) for y in unique_years for m in target_metrics]\n",
    "    \n",
    "    df_sw_final = df_sw_pivot.reindex(columns=ordered_columns)\n",
    "    \n",
    "    print(\"\\n=== Stepwise Logistic Regression è®Šæ•¸ç¯©é¸æˆæ•ˆè¡¨ ===\")\n",
    "    print(df_sw_final.to_string())\n",
    "else:\n",
    "    print(\"No data to report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stepwiseè®Šæ•¸é¸å– çµæœ\n",
    "\n",
    "import pickle\n",
    "\n",
    "# 1. å„²å­˜ (Save)\n",
    "with open('stepwise_feature_storage.pkl', 'wb') as f:\n",
    "    pickle.dump(stepwise_feature_storage, f)\n",
    "\n",
    "print(\"âœ… å·²æˆåŠŸå„²å­˜ç‚º stepwise_feature_storage.pkl\")\n",
    "\n",
    "# ==========================================\n",
    "# ä¸‹æ¬¡è¦ç”¨æ™‚ï¼ŒåŸ·è¡Œé€™æ®µè®€å– (Load)\n",
    "# ==========================================\n",
    "# with open('stepwise_feature_storage.pkl', 'rb') as f:\n",
    "#     stepwise_feature_storage = pickle.load(f)\n",
    "# print(\"âœ… å·²è®€å–è®Šæ•¸è¨­å®š\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05-2_Elast Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05-3_SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06_Modeling (LR, XGB and LGBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06-1 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6-1 a) Logistic functionå®šç¾©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸš€ Running Full Logit for Block 0 (Year: 2010)\n",
      "==================================================\n",
      "   ğŸ”¹ Group: X_all (19 features)... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 137\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   ğŸ”¹ Group: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroup_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(valid_features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features)...\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# åŸ·è¡Œ Full Logistic Regression\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m res = \u001b[43mfit_full_logit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdep_var\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mis_fraud\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    142\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res[\u001b[33m\"\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33msuccess\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    145\u001b[39m     metrics = res[\u001b[33m\"\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mfit_full_logit\u001b[39m\u001b[34m(train_df, test_df, feature_cols, dep_var)\u001b[39m\n\u001b[32m     34\u001b[39m model = LogisticRegression(\n\u001b[32m     35\u001b[39m     penalty=\u001b[33m\"\u001b[39m\u001b[33ml2\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     36\u001b[39m     solver=\u001b[33m\"\u001b[39m\u001b[33mlbfgs\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m     40\u001b[39m )\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     \u001b[38;5;66;03m# 3. é æ¸¬æ©Ÿç‡\u001b[39;00m\n\u001b[32m     46\u001b[39m     train_pred_prob = model.predict_proba(X_train_scaled)[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1384\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1382\u001b[39m     n_threads = \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1384\u001b[39m fold_coefs_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1409\u001b[39m fold_coefs_, _, n_iter_ = \u001b[38;5;28mzip\u001b[39m(*fold_coefs_)\n\u001b[32m   1410\u001b[39m \u001b[38;5;28mself\u001b[39m.n_iter_ = np.asarray(n_iter_, dtype=np.int32)[:, \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import copy\n",
    "\n",
    "# ===========================================================\n",
    "# 1. Full Logistic Regression è¨“ç·´å‡½æ•¸\n",
    "# ===========================================================\n",
    "def fit_full_logit(train_df, test_df, feature_cols, dep_var=\"is_fraud\"):\n",
    "    \"\"\"\n",
    "    é‡å°çµ¦å®šçš„ç‰¹å¾µåˆ—è¡¨é€²è¡Œå…¨è®Šæ•¸ Logistic Regression (L2 Penalty)\n",
    "    \"\"\"\n",
    "    # æº–å‚™ X å’Œ y\n",
    "    X_train = train_df[feature_cols]\n",
    "    y_train = train_df[dep_var]\n",
    "\n",
    "    X_test = test_df[feature_cols]\n",
    "    y_test = test_df[dep_var]\n",
    "\n",
    "    # è™•ç†ç¼ºå¤±å€¼ (Sklearn ä¸æ¥å— NaN)\n",
    "    # ç°¡å–®ç­–ç•¥ï¼šå¡«è£œ 0 æˆ–åˆªé™¤ (é€™é‚Šå‡è¨­ä½ å‰é¢çš„è³‡æ–™æ¸…æ´—å·²ç¶“è™•ç†å®Œ NaNï¼Œè‹¥æœ‰æ®˜ç•™å»ºè­° fillna)\n",
    "    X_train = X_train.fillna(0)\n",
    "    X_test = X_test.fillna(0)\n",
    "\n",
    "    # 1. æ¨™æº–åŒ– (Standardization) - éå¸¸é‡è¦ï¼\n",
    "    # å¿…é ˆç”¨ Train çš„æ•¸æ“šä¾† fitï¼Œç„¶å¾Œ transform åˆ° Train å’Œ Test\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 2. è¨“ç·´æ¨¡å‹ (ä½¿ç”¨ L2 Regularization é˜²æ­¢éæ“¬åˆ)\n",
    "    model = LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=2000,  # å¢åŠ è¿­ä»£æ¬¡æ•¸é¿å…æ”¶æ–‚å¤±æ•—\n",
    "        n_jobs=-1,      # å¹³è¡Œé‹ç®—\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # 3. é æ¸¬æ©Ÿç‡\n",
    "        train_pred_prob = model.predict_proba(X_train_scaled)[:, 1]\n",
    "        test_pred_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "        # 4. è¨ˆç®—æŒ‡æ¨™\n",
    "        train_auc = roc_auc_score(y_train, train_pred_prob)\n",
    "        test_auc = roc_auc_score(y_test, test_pred_prob)\n",
    "        \n",
    "        train_prauc = average_precision_score(y_train, train_pred_prob)\n",
    "        test_prauc = average_precision_score(y_test, test_pred_prob)\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"model\": model,\n",
    "            \"scaler\": scaler,\n",
    "            \"metrics\": {\n",
    "                \"Train AUC\": round(train_auc, 4),\n",
    "                \"Test AUC\": round(test_auc, 4),\n",
    "                \"Train PR-AUC\": round(train_prauc, 4),\n",
    "                \"Test PR-AUC\": round(test_prauc, 4)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# 2. æº–å‚™ Feature Groups (ç¢ºä¿ç„¡ç›®æ¨™è®Šæ•¸èˆ‡ID)\n",
    "# ===========================================================\n",
    "# ç¢ºä¿ all_cols, rfm_cols, dk_cols å·²ç¶“å®šç¾©\n",
    "identifier = ['transaction_id', 'client_id_x', 'card_id', 'card_number', 'cvv']\n",
    "exclude_cols = set(identifier) | {'is_fraud', 'date', 'year', 'time_block'}\n",
    "\n",
    "# é€™è£¡å‡è¨­ä½ çš„ cols åˆ—è¡¨å·²ç¶“å­˜åœ¨ï¼Œåšæœ€å¾Œä¸€æ¬¡æ¸…æ´—ç¢ºä¿å®‰å…¨\n",
    "# å¦‚æœä½ ä¹‹å‰çš„ all_cols å·²ç¶“æ¸…ä¹¾æ·¨äº†ï¼Œé€™è£¡åªæ˜¯é›™é‡ä¿éšª\n",
    "def clean_cols(cols):\n",
    "    return [c for c in cols if c not in exclude_cols]\n",
    "\n",
    "feature_groups = {\n",
    "    \"X_all\": clean_cols(all_cols),\n",
    "    \"X_rfm\": clean_cols(rfm_cols),\n",
    "    \"X_dk\": clean_cols(dk_cols),\n",
    "    \"X_all + X_rfm\": clean_cols(all_cols + rfm_cols),\n",
    "    \"X_all + X_dk\": clean_cols(all_cols + dk_cols),\n",
    "    \"X_rfm + X_dk\": clean_cols(rfm_cols + dk_cols),\n",
    "    \"X_all + X_rfm + X_dk\": clean_cols(all_cols + rfm_cols + dk_cols)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6-1 b) Run Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# 3. ä¸»è¿´åœˆ (Block + Feature Groups)\n",
    "# ===========================================================\n",
    "full_logit_results = {}\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ğŸš€ Running Full Logit for Block {block_id} (Year: {2010 + block_id*2})\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # --- è³‡æ–™åˆ‡åˆ† (Split) ---\n",
    "    block_df = block_df.sort_values('date')\n",
    "    split_index = int(len(block_df) * 0.8)\n",
    "    \n",
    "    train_raw = block_df.iloc[:split_index].copy()\n",
    "    test_raw  = block_df.iloc[split_index:].copy()\n",
    "\n",
    "    # --- é‡ç®— HighRiskMCC (Anti-Leakage) ---\n",
    "    fraud_rate = train_raw.groupby('mcc_code')['is_fraud'].mean()\n",
    "    high_risk_mcc = fraud_rate[fraud_rate > 0.02].index\n",
    "    \n",
    "    train_raw['HighRiskMCC'] = train_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "    test_raw['HighRiskMCC']  = test_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "\n",
    "    # åˆå§‹åŒ–çµæœå­˜æ”¾\n",
    "    full_logit_results[block_id] = {}\n",
    "\n",
    "    # --- é‡å°æ¯å€‹ Feature Group è·‘æ¨¡å‹ ---\n",
    "    for group_name, feature_list in feature_groups.items():\n",
    "        \n",
    "        # ç¢ºä¿ç‰¹å¾µå­˜åœ¨æ–¼ DataFrame\n",
    "        valid_features = [f for f in feature_list if f in train_raw.columns]\n",
    "        \n",
    "        # ç°¡å–®æª¢æŸ¥ï¼šè‹¥ç‰¹å¾µå°‘æ–¼ 1 å€‹å°±è·³é\n",
    "        if not valid_features:\n",
    "            print(f\"   âš ï¸ Group: {group_name} - No valid features found. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"   ğŸ”¹ Group: {group_name} ({len(valid_features)} features)...\", end=\" \")\n",
    "\n",
    "        # åŸ·è¡Œ Full Logistic Regression\n",
    "        res = fit_full_logit(\n",
    "            train_raw, \n",
    "            test_raw, \n",
    "            feature_cols=valid_features, \n",
    "            dep_var=\"is_fraud\"\n",
    "        )\n",
    "\n",
    "        if res[\"status\"] == \"success\":\n",
    "            metrics = res[\"metrics\"]\n",
    "            print(f\"âœ… Done.\")\n",
    "            print(f\"      Train AUC: {metrics['Train AUC']} | Test AUC: {metrics['Test AUC']}\")\n",
    "            print(f\"      Train PR : {metrics['Train PR-AUC']} | Test PR : {metrics['Test PR-AUC']}\")\n",
    "            \n",
    "            # å„²å­˜çµæœ\n",
    "            full_logit_results[block_id][group_name] = metrics\n",
    "        else:\n",
    "            print(f\"âŒ Error: {res['message']}\")\n",
    "            full_logit_results[block_id][group_name] = {\"error\": res['message']}\n",
    "\n",
    "print(\"\\nğŸ‰ All Full Logistic Regression models completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6-1 c) Logistic result output\n",
    "\n",
    "6-1 c **è·‘å®ŒLogisticå¾Œçš„çµæœ**æœƒè¼¸å‡ºåœ¨è³‡æ–™å¤¾åç‚º<font color=blue>â€œlogit_results_wide.csvâ€</font>çš„csvæª”æ¡ˆç•¶ä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Traing AUC ç¸¾æ•ˆçŸ©é™£ (æ•¸å€¼è¶Šé«˜è¶Šå¥½) ===\n",
      "Year                    2010    2011    2012    2013    2014    2015    2016  \\\n",
      "Feature Group                                                                  \n",
      "X_all                 0.9292  0.9621  0.8383  0.9198  0.9123  0.9190  0.9158   \n",
      "X_all + X_dk          0.9749  0.9779  0.8291  0.9114  0.9020  0.9147  0.9165   \n",
      "X_all + X_rfm         0.9394  0.9577  0.8858  0.9405  0.9287  0.9375  0.9317   \n",
      "X_all + X_rfm + X_dk  0.9785  0.9841  0.8887  0.9416  0.9295  0.9371  0.9312   \n",
      "X_dk                  0.9716  0.9631  0.8086  0.8760  0.8708  0.8684  0.8722   \n",
      "X_rfm                 0.6884  0.7059  0.7156  0.7735  0.7351  0.7469  0.7122   \n",
      "X_rfm + X_dk          0.9778  0.9743  0.8904  0.9315  0.9214  0.9179  0.9150   \n",
      "\n",
      "Year                    2018    2019  \n",
      "Feature Group                         \n",
      "X_all                 0.6801  0.7024  \n",
      "X_all + X_dk          0.9992  0.9990  \n",
      "X_all + X_rfm         0.7934  0.7809  \n",
      "X_all + X_rfm + X_dk  0.9994  0.9992  \n",
      "X_dk                  0.9987  0.9986  \n",
      "X_rfm                 0.7378  0.6992  \n",
      "X_rfm + X_dk          0.9991  0.9990  \n",
      "\n",
      "=== Test AUC ç¸¾æ•ˆçŸ©é™£ (æ•¸å€¼è¶Šé«˜è¶Šå¥½) ===\n",
      "Year                    2010  2011  2012    2013  2014    2015    2016  \\\n",
      "Feature Group                                                            \n",
      "X_all                 0.9160   NaN   NaN  0.8891   NaN  0.9028  0.9177   \n",
      "X_all + X_dk          0.9753   NaN   NaN  0.8783   NaN  0.9001  0.9136   \n",
      "X_all + X_rfm         0.9405   NaN   NaN  0.9211   NaN  0.9242  0.9394   \n",
      "X_all + X_rfm + X_dk  0.9802   NaN   NaN  0.9198   NaN  0.9235  0.9351   \n",
      "X_dk                  0.9736   NaN   NaN  0.8624   NaN  0.8624  0.8718   \n",
      "X_rfm                 0.7442   NaN   NaN  0.7569   NaN  0.7450  0.7321   \n",
      "X_rfm + X_dk          0.9807   NaN   NaN  0.9187   NaN  0.9029  0.9253   \n",
      "\n",
      "Year                    2018    2019  \n",
      "Feature Group                         \n",
      "X_all                 0.5487  0.6327  \n",
      "X_all + X_dk          0.8771  0.9986  \n",
      "X_all + X_rfm         0.6498  0.7389  \n",
      "X_all + X_rfm + X_dk  0.8482  0.9988  \n",
      "X_dk                  0.8773  0.9987  \n",
      "X_rfm                 0.7232  0.7151  \n",
      "X_rfm + X_dk          0.8410  0.9991  \n",
      "\n",
      "=== Traing PR-AUC ç¸¾æ•ˆçŸ©é™£ (æ•¸å€¼è¶Šé«˜è¶Šå¥½) ===\n",
      "Year                    2010    2011    2012    2013    2014    2015    2016  \\\n",
      "Feature Group                                                                  \n",
      "X_all                 0.0789  0.0039  0.0129  0.0447  0.0395  0.0741  0.0780   \n",
      "X_all + X_dk          0.1608  0.0375  0.0728  0.1100  0.0915  0.1605  0.1313   \n",
      "X_all + X_rfm         0.0878  0.0026  0.0287  0.1079  0.1080  0.1276  0.1031   \n",
      "X_all + X_rfm + X_dk  0.2008  0.0347  0.0849  0.1793  0.1745  0.2213  0.1916   \n",
      "X_dk                  0.1047  0.0279  0.0413  0.0612  0.0506  0.1043  0.0592   \n",
      "X_rfm                 0.0098  0.0005  0.0040  0.0065  0.0060  0.0100  0.0092   \n",
      "X_rfm + X_dk          0.1357  0.0376  0.0708  0.1369  0.1213  0.1797  0.1265   \n",
      "\n",
      "Year                    2018    2019  \n",
      "Feature Group                         \n",
      "X_all                 0.0034  0.0043  \n",
      "X_all + X_dk          0.6623  0.6600  \n",
      "X_all + X_rfm         0.0086  0.0074  \n",
      "X_all + X_rfm + X_dk  0.7290  0.7245  \n",
      "X_dk                  0.4696  0.4762  \n",
      "X_rfm                 0.0058  0.0051  \n",
      "X_rfm + X_dk          0.6366  0.6323  \n",
      "\n",
      "=== Test PR-AUC ç¸¾æ•ˆçŸ©é™£ (æ•¸å€¼è¶Šé«˜è¶Šå¥½) ===\n",
      "Year                    2010  2011  2012    2013  2014    2015    2016  \\\n",
      "Feature Group                                                            \n",
      "X_all                 0.0633   0.0   0.0  0.0463   0.0  0.0872  0.0835   \n",
      "X_all + X_dk          0.1653   0.0   0.0  0.1289   0.0  0.1755  0.1403   \n",
      "X_all + X_rfm         0.1452   0.0   0.0  0.1399   0.0  0.1687  0.0744   \n",
      "X_all + X_rfm + X_dk  0.2280   0.0   0.0  0.2398   0.0  0.2698  0.1850   \n",
      "X_dk                  0.1060   0.0   0.0  0.0956   0.0  0.1276  0.0439   \n",
      "X_rfm                 0.0260   0.0   0.0  0.0144   0.0  0.0176  0.0107   \n",
      "X_rfm + X_dk          0.2014   0.0   0.0  0.2195   0.0  0.2564  0.1114   \n",
      "\n",
      "Year                    2018    2019  \n",
      "Feature Group                         \n",
      "X_all                 0.0029  0.0024  \n",
      "X_all + X_dk          0.5110  0.5814  \n",
      "X_all + X_rfm         0.0067  0.0045  \n",
      "X_all + X_rfm + X_dk  0.5658  0.6330  \n",
      "X_dk                  0.4291  0.4819  \n",
      "X_rfm                 0.0077  0.0045  \n",
      "X_rfm + X_dk          0.5191  0.6342  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==========================================\n",
    "# 1. å°‡å·¢ç‹€å­—å…¸è½‰ç‚º DataFrame\n",
    "# ==========================================\n",
    "data_list = []\n",
    "\n",
    "for block_id, groups in full_logit_results.items():\n",
    "    for group_name, metrics in groups.items():\n",
    "        # æ’é™¤ç™¼ç”ŸéŒ¯èª¤çš„çµ„åˆ¥\n",
    "        if \"error\" in metrics:\n",
    "            continue\n",
    "            \n",
    "        row = {\n",
    "            \"Block\": block_id,\n",
    "            \"Year\": f\"{2010 + block_id}\",\n",
    "            \"Feature Group\": group_name,\n",
    "            \"Train AUC\": metrics.get(\"Train AUC\"),\n",
    "            \"Test AUC\": metrics.get(\"Test AUC\"),\n",
    "            \"Train PR-AUC\": metrics.get(\"Train PR-AUC\"),\n",
    "            \"Test PR-AUC\": metrics.get(\"Test PR-AUC\")\n",
    "        }\n",
    "        data_list.append(row)\n",
    "\n",
    "df_results = pd.DataFrame(data_list)\n",
    "\n",
    "# èª¿æ•´æ¬„ä½é †åº\n",
    "cols = [\"Block\", \"Year\", \"Feature Group\", \"Train AUC\", \"Test AUC\", \"Train PR-AUC\", \"Test PR-AUC\"]\n",
    "df_results = df_results[cols]\n",
    "\n",
    "# é¡¯ç¤ºå‰å¹¾ç­†\n",
    "#print(\"=== è©³ç´°çµæœç¸½è¡¨ (å‰ 5 ç­†) ===\")\n",
    "#print(df_results.head())\n",
    "\n",
    "# ==========================================\n",
    "# 2. è£½ä½œ Test AUC æ¯”è¼ƒçŸ©é™£ (Pivot Table)\n",
    "# ==========================================\n",
    "# é€™æ˜¯æœ€ç›´è§€çš„è¡¨æ ¼ï¼šæ©«è»¸æ˜¯æ™‚é–“ï¼Œç¸±è»¸æ˜¯ç‰¹å¾µç¾¤çµ„ï¼Œæ•¸å€¼æ˜¯ Test AUC\n",
    "train_auc = df_results.pivot(index=\"Feature Group\", columns=\"Year\", values=\"Train AUC\")\n",
    "test_auc = df_results.pivot(index=\"Feature Group\", columns=\"Year\", values=\"Test AUC\")\n",
    "train_prauc = df_results.pivot(index=\"Feature Group\", columns=\"Year\", values=\"Train PR-AUC\")\n",
    "test_prauc = df_results.pivot(index=\"Feature Group\", columns=\"Year\", values=\"Test PR-AUC\")\n",
    "\n",
    "\n",
    "print(\"\\n=== Traing AUC ç¸¾æ•ˆçŸ©é™£ (æ•¸å€¼è¶Šé«˜è¶Šå¥½) ===\")\n",
    "print(train_auc)\n",
    "print(\"\\n=== Test AUC ç¸¾æ•ˆçŸ©é™£ (æ•¸å€¼è¶Šé«˜è¶Šå¥½) ===\")\n",
    "print(test_auc)\n",
    "print(\"\\n=== Traing PR-AUC ç¸¾æ•ˆçŸ©é™£ (æ•¸å€¼è¶Šé«˜è¶Šå¥½) ===\")\n",
    "print(train_prauc)\n",
    "print(\"\\n=== Test PR-AUC ç¸¾æ•ˆçŸ©é™£ (æ•¸å€¼è¶Šé«˜è¶Šå¥½) ===\")\n",
    "print(test_prauc)\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. è£½ä½œæ•´åˆæ–¹ä¾¿çµæœè¼¸å‡ºå¤§è¡¨ (Hierarchical Columns)\n",
    "# ==========================================\n",
    "\n",
    "# 1. è¨­å®šè¦è½‰ç½®çš„æ‰€æœ‰æŒ‡æ¨™\n",
    "metrics = [\"Train AUC\", \"Test AUC\", \"Train PR-AUC\", \"Test PR-AUC\"]\n",
    "\n",
    "# 2. ä½¿ç”¨ pivot ä¸€æ¬¡è™•ç†å¤šå€‹ values\n",
    "# é€™æœƒç”¢ç”Ÿä¸€å€‹ MultiIndexï¼Œç¬¬ä¸€å±¤æ˜¯æŒ‡æ¨™ (Metric)ï¼Œç¬¬äºŒå±¤æ˜¯å¹´ä»½ (Year)\n",
    "df_pivot = df_results.pivot(index=\"Feature Group\", columns=\"Year\", values=metrics)\n",
    "\n",
    "# 3. äº¤æ›æ¬„ä½å±¤ç´šï¼šå°‡ã€Œå¹´ä»½ã€ç§»åˆ°æœ€ä¸Šå±¤ï¼ŒæŒ‡æ¨™ç§»åˆ°ç¬¬äºŒå±¤\n",
    "df_pivot.columns = df_pivot.columns.swaplevel(0, 1)\n",
    "\n",
    "# 4. (é¸æ“‡æ€§) æ’åºæ¬„ä½\n",
    "# å¦‚æœç›´æ¥ sort_indexï¼Œæ¬„ä½æœƒä¾ç…§å­—æ¯æ’åº (Test æœƒè·‘å» Train å‰é¢)\n",
    "# ç‚ºäº†è·Ÿä½ çš„æˆªåœ–ä¸€æ¨£ (Train -> Test)ï¼Œæˆ‘å€‘éœ€è¦è‡ªå®šç¾©æ’åº\n",
    "unique_years = sorted(df_results[\"Year\"].unique())\n",
    "ordered_columns = []\n",
    "\n",
    "for year in unique_years:\n",
    "    for metric in metrics:\n",
    "        # å»ºç«‹ (Year, Metric) çš„ tuple åˆ—è¡¨\n",
    "        ordered_columns.append((year, metric))\n",
    "\n",
    "# æ ¹æ“šæˆ‘å€‘æƒ³è¦çš„é †åºé‡æ–°ç´¢å¼•\n",
    "df_final = df_pivot.reindex(columns=ordered_columns)\n",
    "\n",
    "print(\"=== æ•´åˆçµæœç¸½è¡¨ ===\")\n",
    "# å¦‚æœä½ åœ¨ Jupyter Notebookï¼Œç›´æ¥è¼¸å…¥ df_final å³å¯çœ‹åˆ°æ¼‚äº®è¡¨æ ¼\n",
    "# å¦‚æœæ˜¯ç´”æ–‡å­—ä»‹é¢ï¼Œç”¨ to_string() æ¯”è¼ƒæ¸…æ¥š\n",
    "print(df_final.to_string())\n",
    "\n",
    "# ç°¡å–®çš„åŒ¯å‡º csv æª¢æŸ¥ (é€šå¸¸ Excel æ‰“é–‹å°±æœƒæœ‰é›™å±¤æ¨™é ­)\n",
    "df_final.to_csv(\"logit_results_wide.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6-1 d) Logistic Regression(ä½¿ç”¨stepwise features ç‰ˆæœ¬)\n",
    "\n",
    "6-1 d ç”¨æ–¼è·‘å®Œstepwise features selection å¾Œï¼Œç›´æ¥è®€å–é¸å®Œçš„featuresä¾†é€²è¡Œé‚è¼¯æ–¯å›æ­¸ï¼Œè‹¥è¦å–®ç¨é‹è¡Œæ­¤æ®µç¨‹å¼ï¼Œè¨˜å¾—å…ˆè¼‰å¥½6-1 açš„functionå³å¯ï¼ï¼\n",
    "**LR é‹è¡Œstepwise selectionçš„çµæœ**æœƒè¼¸å‡ºåœ¨è³‡æ–™å¤¾åç‚º<font color=blue>â€œLR_step.csvâ€</font>çš„csvæª”æ¡ˆç•¶ä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 0 (Year: 2010)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 6 features)... âœ… Test AUC: 0.9171\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 features)... âœ… Test AUC: 0.7362\n",
      "   ğŸ”¹ Group: X_dk (Using 4 features)... âœ… Test AUC: 0.9654\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 10 features)... âœ… Test AUC: 0.9408\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 8 features)... âœ… Test AUC: 0.9176\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 7 features)... âœ… Test AUC: 0.9289\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 12 features)... âœ… Test AUC: 0.9761\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 1 (Year: 2011)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 2 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm (Using 1 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_dk (Using 2 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 7 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 3 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 5 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 7 features)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 2 (Year: 2012)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 3 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_dk (Using 1 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 6 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 3 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 4 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 6 features)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 3 (Year: 2013)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 8 features)... âœ… Test AUC: 0.8863\n",
      "   ğŸ”¹ Group: X_rfm (Using 5 features)... âœ… Test AUC: 0.7536\n",
      "   ğŸ”¹ Group: X_dk (Using 3 features)... âœ… Test AUC: 0.8517\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 13 features)... âœ… Test AUC: 0.922\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 12 features)... âœ… Test AUC: 0.8767\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 8 features)... âœ… Test AUC: 0.9143\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 15 features)... âœ… Test AUC: 0.9145\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 4 (Year: 2014)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 12 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_dk (Using 3 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 14 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 12 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 6 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 17 features)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 5 (Year: 2015)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 11 features)... âœ… Test AUC: 0.902\n",
      "   ğŸ”¹ Group: X_rfm (Using 5 features)... âœ… Test AUC: 0.7449\n",
      "   ğŸ”¹ Group: X_dk (Using 2 features)... âœ… Test AUC: 0.8461\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 18 features)... âœ… Test AUC: 0.923\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 13 features)... âœ… Test AUC: 0.8901\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 7 features)... âœ… Test AUC: 0.8954\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 17 features)... âœ… Test AUC: 0.9174\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 6 (Year: 2016)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 9 features)... âœ… Test AUC: 0.917\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 features)... âœ… Test AUC: 0.7342\n",
      "   ğŸ”¹ Group: X_dk (Using 2 features)... âœ… Test AUC: 0.8589\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 11 features)... âœ… Test AUC: 0.9395\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 10 features)... âœ… Test AUC: 0.9094\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 6 features)... âœ… Test AUC: 0.9208\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 15 features)... âœ… Test AUC: 0.9326\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 7 (Year: 2017)\n",
      "============================================================\n",
      "   âš ï¸ Group: X_all - Skipped (No Stepwise features)\n",
      "   âš ï¸ Group: X_rfm - Skipped (No Stepwise features)\n",
      "   âš ï¸ Group: X_dk - Skipped (No Stepwise features)\n",
      "   âš ï¸ Group: X_all + X_rfm - Skipped (No Stepwise features)\n",
      "   âš ï¸ Group: X_all + X_dk - Skipped (No Stepwise features)\n",
      "   âš ï¸ Group: X_rfm + X_dk - Skipped (No Stepwise features)\n",
      "   âš ï¸ Group: X_all + X_rfm + X_dk - Skipped (No Stepwise features)\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 8 (Year: 2018)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 5 features)... âœ… Test AUC: 0.5402\n",
      "   ğŸ”¹ Group: X_rfm (Using 5 features)... âœ… Test AUC: 0.7217\n",
      "   ğŸ”¹ Group: X_dk (Using 3 features)... âœ… Test AUC: 0.9158\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 11 features)... âœ… Test AUC: 0.6948\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 7 features)... âœ… Test AUC: 0.6696\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 7 features)... âœ… Test AUC: 0.8341\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 11 features)... âœ… Test AUC: 0.7925\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Running Logit (Stepwise Feats) for Block 9 (Year: 2019)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 6 features)... âœ… Test AUC: 0.6481\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 features)... âœ… Test AUC: 0.7191\n",
      "   ğŸ”¹ Group: X_dk (Using 2 features)... âœ… Test AUC: 0.7503\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 10 features)... âœ… Test AUC: 0.7498\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 8 features)... âœ… Test AUC: 0.7952\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 7 features)... âœ… Test AUC: 0.8867\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 11 features)... âœ… Test AUC: 0.8639\n",
      "\n",
      "ğŸ‰ All Logistic Regression (Stepwise) models completed!\n",
      "\n",
      "=== Logistic Regression Performance (Using Stepwise Selected Features) ===\n",
      "Year                      2010                                        2011                                        2012                                        2013                                        2014                                        2015                                        2016                                        2017                                        2018                                        2019                                  \n",
      "                     Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC\n",
      "Feature Group                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "X_all                   0.9290   0.9171       0.0785      0.0699    0.9418      NaN       0.0022         NaN    0.8299      NaN       0.0124         NaN    0.9190   0.8863       0.0427      0.0494    0.9142      NaN       0.0330         NaN    0.9185   0.9020       0.0793      0.0863    0.9159   0.9170       0.0759      0.0749       NaN      NaN          NaN         NaN    0.6636   0.5402       0.0039      0.0029    0.6796   0.6481       0.0039      0.0027\n",
      "X_all + X_dk            0.9351   0.9176       0.0840      0.1611    0.9475      NaN       0.0057         NaN    0.8299      NaN       0.0124         NaN    0.9057   0.8767       0.0667      0.0705    0.9039      NaN       0.0595         NaN    0.9066   0.8901       0.1264      0.1297    0.9093   0.9094       0.1094      0.1205       NaN      NaN          NaN         NaN    0.8304   0.6696       0.0270      0.0247    0.8277   0.7952       0.0268      0.0182\n",
      "X_all + X_rfm           0.9393   0.9408       0.0851      0.1547    0.9524      NaN       0.0072         NaN    0.8837      NaN       0.0265         NaN    0.9408   0.9220       0.0907      0.1070    0.9288      NaN       0.0747         NaN    0.9372   0.9230       0.1285      0.1667    0.9309   0.9395       0.1012      0.0755       NaN      NaN          NaN         NaN    0.7751   0.6948       0.0071      0.0068    0.7600   0.7498       0.0062      0.0050\n",
      "X_all + X_rfm + X_dk    0.9721   0.9761       0.1318      0.2123    0.9524      NaN       0.0207         NaN    0.8837      NaN       0.0265         NaN    0.9337   0.9145       0.1411      0.1891    0.9239      NaN       0.1487         NaN    0.9314   0.9174       0.1662      0.2203    0.9262   0.9326       0.1443      0.1259       NaN      NaN          NaN         NaN    0.8704   0.7925       0.0367      0.0271    0.8732   0.8639       0.0344      0.0315\n",
      "X_dk                    0.9612   0.9654       0.0565      0.0584    0.9285      NaN       0.0008         NaN    0.8200      NaN       0.0069         NaN    0.8606   0.8517       0.0129      0.0296    0.8576      NaN       0.0101         NaN    0.8533   0.8461       0.0184      0.0333    0.8551   0.8589       0.0221      0.0174       NaN      NaN          NaN         NaN    0.9435   0.9158       0.0473      0.0338    0.7623   0.7503       0.0114      0.0108\n",
      "X_rfm                   0.6898   0.7362       0.0097      0.0262    0.5822      NaN       0.0005         NaN    0.7159      NaN       0.0040         NaN    0.7727   0.7536       0.0065      0.0150    0.7437      NaN       0.0057         NaN    0.7473   0.7449       0.0100      0.0176    0.7117   0.7342       0.0093      0.0116       NaN      NaN          NaN         NaN    0.7359   0.7217       0.0059      0.0077    0.7029   0.7191       0.0052      0.0048\n",
      "X_rfm + X_dk            0.9367   0.9289       0.0772      0.1778    0.9427      NaN       0.0055         NaN    0.8855      NaN       0.0278         NaN    0.9249   0.9143       0.0771      0.1602    0.9137      NaN       0.0831         NaN    0.9112   0.8954       0.0979      0.1577    0.9092   0.9208       0.0940      0.0760       NaN      NaN          NaN         NaN    0.8527   0.8341       0.0253      0.0239    0.8883   0.8867       0.0304      0.0320\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# ===========================================================\n",
    "# 0. è¼”åŠ©æª¢æŸ¥å‡½æ•¸ (è·Ÿä¹‹å‰ä¸€æ¨£)\n",
    "# ===========================================================\n",
    "def check_data_validity(y_data, stage=\"Train\"):\n",
    "    if len(y_data) == 0:\n",
    "        return False, f\"{stage} set is empty\"\n",
    "    if y_data.nunique() < 2:\n",
    "        val = y_data.iloc[0] if len(y_data) > 0 else \"None\"\n",
    "        return False, f\"{stage} set has only 1 class (value: {val})\"\n",
    "    return True, \"\"\n",
    "\n",
    "# ===========================================================\n",
    "# 1. å¢å¼·ç‰ˆ Logistic Regression è¨“ç·´å‡½æ•¸ (å«é˜²å‘†)\n",
    "# ===========================================================\n",
    "def fit_stepwise_logit(train_df, test_df, feature_cols, dep_var=\"is_fraud\"):\n",
    "    \"\"\"\n",
    "    é‡å° Stepwise ç¯©é¸å¾Œçš„è®Šæ•¸è·‘ Logistic Regression\n",
    "    \"\"\"\n",
    "    X_train = train_df[feature_cols]\n",
    "    y_train = train_df[dep_var]\n",
    "    X_test  = test_df[feature_cols]\n",
    "    y_test  = test_df[dep_var]\n",
    "\n",
    "    # --- 1. é˜²å´©æ½°æª¢æŸ¥ ---\n",
    "    is_valid_train, msg_train = check_data_validity(y_train, \"Train\")\n",
    "    if not is_valid_train:\n",
    "        return {\"status\": \"skip\", \"message\": msg_train}\n",
    "\n",
    "    is_valid_test, _ = check_data_validity(y_test, \"Test\")\n",
    "\n",
    "    # --- 2. ç¼ºå¤±å€¼è™•ç† ---\n",
    "    # é›–ç„¶ Stepwise éšæ®µå¯èƒ½è™•ç†éï¼Œä½†é˜²è¬ä¸€\n",
    "    X_train = X_train.fillna(0)\n",
    "    X_test  = X_test.fillna(0)\n",
    "\n",
    "    # --- 3. æ¨™æº–åŒ– (Logistic Regression å¿…å‚™) ---\n",
    "    try:\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled  = scaler.transform(X_test)\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": f\"Scaling error: {str(e)}\"}\n",
    "\n",
    "    # --- 4. è¨“ç·´æ¨¡å‹ ---\n",
    "    model = LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=2000,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # --- 5. è¨ˆç®—æŒ‡æ¨™ ---\n",
    "        train_prob = model.predict_proba(X_train_scaled)[:, 1]\n",
    "        train_auc  = roc_auc_score(y_train, train_prob)\n",
    "        train_pr   = average_precision_score(y_train, train_prob)\n",
    "        \n",
    "        test_auc = np.nan\n",
    "        test_pr  = np.nan\n",
    "        \n",
    "        if is_valid_test:\n",
    "            try:\n",
    "                test_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "                test_auc  = roc_auc_score(y_test, test_prob)\n",
    "                test_pr   = average_precision_score(y_test, test_prob)\n",
    "            except:\n",
    "                pass # ä¿æŒ NaN\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"model\": model,\n",
    "            \"metrics\": {\n",
    "                \"Train AUC\": round(train_auc, 4),\n",
    "                \"Test AUC\": round(test_auc, 4) if not np.isnan(test_auc) else np.nan,\n",
    "                \"Train PR-AUC\": round(train_pr, 4),\n",
    "                \"Test PR-AUC\": round(test_pr, 4) if not np.isnan(test_pr) else np.nan\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "# ===========================================================\n",
    "# 2. ä¸»è¿´åœˆ (Stepwise Storage -> Logistic Regression)\n",
    "# ===========================================================\n",
    "\n",
    "# ç¢ºä¿å¿…è¦è®Šæ•¸å­˜åœ¨\n",
    "if 'stepwise_feature_storage' not in locals():\n",
    "    raise ValueError(\"âš ï¸ è«‹å…ˆåŸ·è¡Œ Stepwise ç¯©é¸ï¼Œå–å¾— stepwise_feature_storageï¼\")\n",
    "\n",
    "logit_stepwise_results = []\n",
    "\n",
    "# é€™è£¡æˆ‘å€‘éœ€è¦ group names ä¾†éæ­·å­—å…¸\n",
    "group_names = feature_groups.keys()\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    \n",
    "    current_year = 2010 + block_id\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ“Š Running Logit (Stepwise Feats) for Block {block_id} (Year: {current_year})\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # --- è³‡æ–™åˆ‡åˆ† (Split) ---\n",
    "    block_df = block_df.sort_values('date')\n",
    "    split_index = int(len(block_df) * 0.8)\n",
    "    \n",
    "    train_raw = block_df.iloc[:split_index].copy()\n",
    "    test_raw  = block_df.iloc[split_index:].copy()\n",
    "\n",
    "    # --- ç‰¹å¾µå·¥ç¨‹ (Anti-Leakage) ---\n",
    "    # å¿…é ˆåšï¼å› ç‚º Stepwise é¸å‡ºçš„è®Šæ•¸è£¡å¯èƒ½åŒ…å« HighRiskMCC\n",
    "    try:\n",
    "        fraud_rate = train_raw.groupby('mcc_code')['is_fraud'].mean()\n",
    "        high_risk_mcc = fraud_rate[fraud_rate > 0.02].index\n",
    "        train_raw['HighRiskMCC'] = train_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "        test_raw['HighRiskMCC']  = test_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # --- è®€å–è©²å¹´ä»½ Stepwise çµæœ ---\n",
    "    block_feats_dict = stepwise_feature_storage.get(block_id, {})\n",
    "\n",
    "    # --- é‡å°æ¯å€‹ Group è·‘æ¨¡å‹ ---\n",
    "    for group_name in group_names:\n",
    "        \n",
    "        # â˜… é—œéµï¼šå¾å­—å…¸å–å‡ºã€Œè©²å¹´ä»½ã€è©²ç¾¤çµ„ã€è¢« Stepwise é¸ä¸­çš„è®Šæ•¸\n",
    "        my_features = block_feats_dict.get(group_name, [])\n",
    "        \n",
    "        # æƒ…æ³ A: Stepwise æ²’é¸å‡ºä»»ä½•è®Šæ•¸ (æˆ–ç©ºé›†åˆ)\n",
    "        if not my_features:\n",
    "            print(f\"   âš ï¸ Group: {group_name} - Skipped (No Stepwise features)\")\n",
    "            logit_stepwise_results.append({\n",
    "                \"Year\": current_year, \"Feature Group\": group_name,\n",
    "                \"Train AUC\": np.nan, \"Test AUC\": np.nan,\n",
    "                \"Train PR-AUC\": np.nan, \"Test PR-AUC\": np.nan,\n",
    "                \"Num Features\": 0\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        print(f\"   ğŸ”¹ Group: {group_name} (Using {len(my_features)} features)...\", end=\" \")\n",
    "\n",
    "        # æƒ…æ³ B: åŸ·è¡Œ Logistic Regression\n",
    "        res = fit_stepwise_logit(\n",
    "            train_raw, \n",
    "            test_raw, \n",
    "            feature_cols=my_features, # <--- ä½¿ç”¨ Stepwise é¸å‡ºçš„è®Šæ•¸\n",
    "            dep_var=\"is_fraud\"\n",
    "        )\n",
    "\n",
    "        if res[\"status\"] == \"success\":\n",
    "            m = res[\"metrics\"]\n",
    "            print(f\"âœ… Test AUC: {m.get('Test AUC', np.nan)}\")\n",
    "            \n",
    "            logit_stepwise_results.append({\n",
    "                \"Year\": current_year,\n",
    "                \"Feature Group\": group_name,\n",
    "                \"Train AUC\": m.get(\"Train AUC\"),\n",
    "                \"Test AUC\": m.get(\"Test AUC\"),\n",
    "                \"Train PR-AUC\": m.get(\"Train PR-AUC\"),\n",
    "                \"Test PR-AUC\": m.get(\"Test PR-AUC\"),\n",
    "                \"Num Features\": len(my_features)\n",
    "            })\n",
    "            \n",
    "        elif res[\"status\"] == \"skip\":\n",
    "            print(f\"âš ï¸ Skipped: {res['message']}\")\n",
    "            logit_stepwise_results.append({\n",
    "                \"Year\": current_year, \"Feature Group\": group_name,\n",
    "                \"Train AUC\": np.nan, \"Test AUC\": np.nan,\n",
    "                \"Train PR-AUC\": np.nan, \"Test PR-AUC\": np.nan,\n",
    "                \"Num Features\": len(my_features)\n",
    "            })\n",
    "            \n",
    "        else:\n",
    "            print(f\"âŒ Error: {res['message']}\")\n",
    "\n",
    "print(\"\\nğŸ‰ All Logistic Regression (Stepwise) models completed!\")\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# 3. ç”¢å‡ºå ±è¡¨\n",
    "# ===========================================================\n",
    "if logit_stepwise_results:\n",
    "    df_logit_raw = pd.DataFrame(logit_stepwise_results)\n",
    "    \n",
    "    # Pivot è½‰ç½®\n",
    "    target_metrics = [\"Train AUC\", \"Test AUC\", \"Train PR-AUC\", \"Test PR-AUC\"]\n",
    "    df_logit_pivot = df_logit_raw.pivot(index=\"Feature Group\", columns=\"Year\", values=target_metrics)\n",
    "    \n",
    "    # èª¿æ•´æ¬„ä½é †åº\n",
    "    df_logit_pivot.columns = df_logit_pivot.columns.swaplevel(0, 1)\n",
    "    unique_years = sorted(df_logit_raw[\"Year\"].unique())\n",
    "    ordered_columns = [(y, m) for y in unique_years for m in target_metrics]\n",
    "    \n",
    "    df_logit_final = df_logit_pivot.reindex(columns=ordered_columns)\n",
    "    \n",
    "    print(\"\\n=== Logistic Regression Performance (Using Stepwise Selected Features) ===\")\n",
    "    print(df_logit_final.to_string())\n",
    "else:\n",
    "    print(\"No results generated.\")\n",
    "\n",
    "df_logit_final.to_csv(\"LR_step.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06-2 XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6-2 a) XGB functionå®šç¾©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 98\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdf_sorted\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdf_sorted is not defined. Please ensure your DataFrame is prepared.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblock_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_df\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf_sorted\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime_block\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m=\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m*\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mğŸš€ Running XGBoost for Block \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mblock_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m (Year: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[32;43m2010\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43m+\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mblock_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/pandas/core/groupby/ops.py:620\u001b[39m, in \u001b[36mBaseGrouper.get_iterator\u001b[39m\u001b[34m(self, data, axis)\u001b[39m\n\u001b[32m    618\u001b[39m splitter = \u001b[38;5;28mself\u001b[39m._get_splitter(data, axis=axis)\n\u001b[32m    619\u001b[39m keys = \u001b[38;5;28mself\u001b[39m.group_keys_seq\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, splitter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/pandas/core/groupby/ops.py:1150\u001b[39m, in \u001b[36mDataSplitter.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1149\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator:\n\u001b[32m-> \u001b[39m\u001b[32m1150\u001b[39m     sdata = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sorted_data\u001b[49m\n\u001b[32m   1152\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ngroups == \u001b[32m0\u001b[39m:\n\u001b[32m   1153\u001b[39m         \u001b[38;5;66;03m# we are inside a generator, rather than raise StopIteration\u001b[39;00m\n\u001b[32m   1154\u001b[39m         \u001b[38;5;66;03m# we merely return signal the end\u001b[39;00m\n\u001b[32m   1155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/properties.pyx:36\u001b[39m, in \u001b[36mpandas._libs.properties.CachedProperty.__get__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/pandas/core/groupby/ops.py:1164\u001b[39m, in \u001b[36mDataSplitter._sorted_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1162\u001b[39m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[32m   1163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sorted_data\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> NDFrameT:\n\u001b[32m-> \u001b[39m\u001b[32m1164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sort_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/pandas/core/generic.py:4152\u001b[39m, in \u001b[36mNDFrame.take\u001b[39m\u001b[34m(self, indices, axis, **kwargs)\u001b[39m\n\u001b[32m   4147\u001b[39m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[32m   4148\u001b[39m     indices = np.arange(\n\u001b[32m   4149\u001b[39m         indices.start, indices.stop, indices.step, dtype=np.intp\n\u001b[32m   4150\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4152\u001b[39m new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4154\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes).__finalize__(\n\u001b[32m   4158\u001b[39m     \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mtake\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4159\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/pandas/core/internals/managers.py:894\u001b[39m, in \u001b[36mBaseBlockManager.take\u001b[39m\u001b[34m(self, indexer, axis, verify)\u001b[39m\n\u001b[32m    891\u001b[39m indexer = maybe_convert_indices(indexer, n, verify=verify)\n\u001b[32m    893\u001b[39m new_labels = \u001b[38;5;28mself\u001b[39m.axes[axis].take(indexer)\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/pandas/core/internals/managers.py:688\u001b[39m, in \u001b[36mBaseBlockManager.reindex_indexer\u001b[39m\u001b[34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[39m\n\u001b[32m    680\u001b[39m     new_blocks = \u001b[38;5;28mself\u001b[39m._slice_take_blocks_ax0(\n\u001b[32m    681\u001b[39m         indexer,\n\u001b[32m    682\u001b[39m         fill_value=fill_value,\n\u001b[32m    683\u001b[39m         only_slice=only_slice,\n\u001b[32m    684\u001b[39m         use_na_proxy=use_na_proxy,\n\u001b[32m    685\u001b[39m     )\n\u001b[32m    686\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    687\u001b[39m     new_blocks = [\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m         \u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks\n\u001b[32m    696\u001b[39m     ]\n\u001b[32m    698\u001b[39m new_axes = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.axes)\n\u001b[32m    699\u001b[39m new_axes[axis] = new_axis\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/pandas/core/internals/blocks.py:1373\u001b[39m, in \u001b[36mBlock.take_nd\u001b[39m\u001b[34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[39m\n\u001b[32m   1370\u001b[39m     allow_fill = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1372\u001b[39m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m new_values = \u001b[43malgos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[32m   1378\u001b[39m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[32m   1380\u001b[39m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[32m   1381\u001b[39m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/pandas/core/array_algos/take.py:117\u001b[39m, in \u001b[36mtake_nd\u001b[39m\u001b[34m(arr, indexer, axis, fill_value, allow_fill)\u001b[39m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.take(indexer, fill_value=fill_value, allow_fill=allow_fill)\n\u001b[32m    116\u001b[39m arr = np.asarray(arr)\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/pandas/core/array_algos/take.py:162\u001b[39m, in \u001b[36m_take_nd_ndarray\u001b[39m\u001b[34m(arr, indexer, axis, fill_value, allow_fill)\u001b[39m\n\u001b[32m    157\u001b[39m     out = np.empty(out_shape, dtype=dtype)\n\u001b[32m    159\u001b[39m func = _get_take_nd_function(\n\u001b[32m    160\u001b[39m     arr.ndim, arr.dtype, out.dtype, axis=axis, mask_info=mask_info\n\u001b[32m    161\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[32m    165\u001b[39m     out = out.T\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/pandas/core/array_algos/take.py:345\u001b[39m, in \u001b[36m_get_take_nd_function.<locals>.func\u001b[39m\u001b[34m(arr, indexer, out, fill_value)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunc\u001b[39m(arr, indexer, out, fill_value=np.nan) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    344\u001b[39m     indexer = ensure_platform_int(indexer)\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m     \u001b[43m_take_nd_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m        \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask_info\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/pandas/core/array_algos/take.py:528\u001b[39m, in \u001b[36m_take_nd_object\u001b[39m\u001b[34m(arr, indexer, out, axis, fill_value, mask_info)\u001b[39m\n\u001b[32m    526\u001b[39m     arr = arr.astype(out.dtype)\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arr.shape[axis] > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m     \u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m needs_masking:\n\u001b[32m    530\u001b[39m     outindexer = [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)] * arr.ndim\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import copy\n",
    "\n",
    "# ===========================================================\n",
    "# 1. å®šç¾©å–®æ¬¡ XGBoost è¨“ç·´å‡½æ•¸\n",
    "# ===========================================================\n",
    "def run_xgb_single(train_df, test_df, feature_cols, dep_var=\"is_fraud\"):\n",
    "    \"\"\"\n",
    "    é‡å°çµ¦å®šçš„ Train/Test å’Œç‰¹å¾µåˆ—è¡¨è¨“ç·´ XGBoost\n",
    "    \"\"\"\n",
    "    X_train = train_df[feature_cols]\n",
    "    y_train = train_df[dep_var]\n",
    "    X_test = test_df[feature_cols]\n",
    "    y_test = test_df[dep_var]\n",
    "\n",
    "    # åˆå§‹åŒ– XGBoost\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"auc\", # æ”¹ç”¨ AUC ä½œç‚ºè©•ä¼°æŒ‡æ¨™é€šå¸¸æ¯”è¼ƒç›´è§€ï¼Œlogloss ä¹Ÿå¯ä»¥\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\", # åŠ é€Ÿè¨“ç·´\n",
    "        n_jobs=-1,\n",
    "        early_stopping_rounds=50 # å¦‚æœ 50 è¼ªå…§é©—è­‰é›† AUC æ²’æå‡å°±åœæ­¢\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # è¨“ç·´æ¨¡å‹\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            verbose=False # é—œé–‰è©³ç´°è¨“ç·´éç¨‹è¼¸å‡ºï¼Œé¿å…æ´—ç‰ˆ\n",
    "        )\n",
    "\n",
    "        # é æ¸¬æ©Ÿç‡\n",
    "        train_pred = model.predict_proba(X_train)[:, 1]\n",
    "        test_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # è¨ˆç®—æŒ‡æ¨™\n",
    "        train_roc = roc_auc_score(y_train, train_pred)\n",
    "        test_roc = roc_auc_score(y_test, test_pred)\n",
    "        train_pr = average_precision_score(y_train, train_pred)\n",
    "        test_pr = average_precision_score(y_test, test_pred)\n",
    "\n",
    "        # å–å¾—æœ€ä½³è¿­ä»£æ¬¡æ•¸ (å¦‚æœè§¸ç™¼æ—©åœ)\n",
    "        best_iter = model.best_iteration if hasattr(model, 'best_iteration') else 300\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"model\": model,\n",
    "            \"metrics\": {\n",
    "                \"Train AUC\": round(train_roc, 4),\n",
    "                \"Test AUC\": round(test_roc, 4),\n",
    "                \"Train PR-AUC\": round(train_pr, 4),\n",
    "                \"Test PR-AUC\": round(test_pr, 4),\n",
    "                \"Best Iteration\": best_iter\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# 2. æº–å‚™ Feature Groups (ç¢ºä¿ç„¡ç›®æ¨™è®Šæ•¸èˆ‡ID)\n",
    "# ===========================================================\n",
    "# å‡è¨­ identifier, all_cols, rfm_cols, dk_cols å·²ç¶“å®šç¾©å¥½\n",
    "identifier = ['transaction_id', 'client_id_x', 'card_id', 'card_number', 'cvv']\n",
    "exclude_cols = set(identifier) | {'is_fraud', 'date', 'year', 'time_block'}\n",
    "\n",
    "def clean_cols(cols):\n",
    "    return [c for c in cols if c not in exclude_cols]\n",
    "\n",
    "feature_groups = {\n",
    "    \"X_all\": clean_cols(all_cols),\n",
    "    \"X_rfm\": clean_cols(rfm_cols),\n",
    "    \"X_dk\": clean_cols(dk_cols),\n",
    "    \"X_all + X_rfm\": clean_cols(all_cols + rfm_cols),\n",
    "    \"X_all + X_dk\": clean_cols(all_cols + dk_cols),\n",
    "    \"X_rfm + X_dk\": clean_cols(rfm_cols + dk_cols),\n",
    "    \"X_all + X_rfm + X_dk\": clean_cols(all_cols + rfm_cols + dk_cols)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6-2 b) Run XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===========================================================\n",
    "# 3. ä¸»è¿´åœˆ (Block + Feature Groups)\n",
    "# ===========================================================\n",
    "xgb_results = {}\n",
    "\n",
    "# ç¢ºä¿ df_sorted å­˜åœ¨\n",
    "if 'df_sorted' not in locals():\n",
    "    raise ValueError(\"df_sorted is not defined. Please ensure your DataFrame is prepared.\")\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸš€ Running XGBoost for Block {block_id} (Year: {2010 + block_id})\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # --- è³‡æ–™åˆ‡åˆ† (Split) ---\n",
    "    block_df = block_df.sort_values('date')\n",
    "    split_index = int(len(block_df) * 0.8)\n",
    "    \n",
    "    train_raw = block_df.iloc[:split_index].copy()\n",
    "    test_raw  = block_df.iloc[split_index:].copy()\n",
    "\n",
    "    # --- é‡ç®— HighRiskMCC (Anti-Leakage) ---\n",
    "    fraud_rate = train_raw.groupby('mcc_code')['is_fraud'].mean()\n",
    "    high_risk_mcc = fraud_rate[fraud_rate > 0.02].index\n",
    "    \n",
    "    train_raw['HighRiskMCC'] = train_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "    test_raw['HighRiskMCC']  = test_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "\n",
    "    # åˆå§‹åŒ–çµæœå­˜æ”¾\n",
    "    xgb_results[block_id] = {}\n",
    "\n",
    "    # --- é‡å°æ¯å€‹ Feature Group è·‘æ¨¡å‹ ---\n",
    "    for group_name, feature_list in feature_groups.items():\n",
    "        \n",
    "        # ç¢ºä¿ç‰¹å¾µå­˜åœ¨æ–¼ DataFrame\n",
    "        valid_features = [f for f in feature_list if f in train_raw.columns]\n",
    "        \n",
    "        # ç°¡å–®æª¢æŸ¥\n",
    "        if not valid_features:\n",
    "            print(f\"   âš ï¸ Group: {group_name} - No valid features found. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"   ğŸ”¹ Group: {group_name} ({len(valid_features)} features)...\", end=\" \")\n",
    "\n",
    "        # åŸ·è¡Œ XGBoost\n",
    "        res = run_xgb_single(\n",
    "            train_raw, \n",
    "            test_raw, \n",
    "            feature_cols=valid_features, \n",
    "            dep_var=\"is_fraud\"\n",
    "        )\n",
    "\n",
    "        if res[\"status\"] == \"success\":\n",
    "            metrics = res[\"metrics\"]\n",
    "            print(f\"âœ… Done (Best Iter: {metrics['Best Iteration']})\")\n",
    "            print(f\"      Train AUC: {metrics['Train AUC']} | Test AUC: {metrics['Test AUC']}\")\n",
    "            print(f\"      Train PR : {metrics['Train PR-AUC']} | Test PR : {metrics['Test PR-AUC']}\")\n",
    "            \n",
    "            xgb_results[block_id][group_name] = metrics\n",
    "        else:\n",
    "            print(f\"âŒ Error: {res['message']}\")\n",
    "            xgb_results[block_id][group_name] = {\"error\": res['message']}\n",
    "\n",
    "print(\"\\nğŸ‰ All XGBoost models completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6-2 c) XGB result output\n",
    "\n",
    "6-2 c **è·‘å®ŒXGBå¾Œçš„çµæœ**æœƒè¼¸å‡ºåœ¨è³‡æ–™å¤¾åç‚º<font color=blue>â€œXGB_results_wide.csvâ€</font>çš„csvæª”æ¡ˆç•¶ä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBoost æ•´åˆçµæœç¸½è¡¨ ===\n",
      "Year                      2010                                        2011                                        2012                                        2013                                        2014                                        2015                                        2016                                        2018                                        2019                                  \n",
      "                     Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC\n",
      "Feature Group                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "X_all                   0.9682   0.9341       0.3252      0.1487    0.9596      NaN       0.0011         0.0    0.8868      NaN       0.0216         0.0    0.9643   0.9135       0.2558      0.1137    0.9406      NaN       0.0269         0.0    0.9591   0.9280       0.2277      0.1760    0.9548   0.9410       0.2194      0.1783    0.8286   0.6117       0.0226      0.0052    0.8784   0.6938       0.0575      0.0059\n",
      "X_all + X_dk            0.9962   0.9884       0.6799      0.3243    0.9666      NaN       0.0009         0.0    0.8989      NaN       0.0238         0.0    0.9755   0.9515       0.3247      0.1978    0.9641      NaN       0.0403         0.0    0.9682   0.9429       0.3398      0.2768    0.9751   0.9540       0.4016      0.2880    0.9994   0.9774       0.7525      0.5302    0.9997   0.9988       0.8926      0.5543\n",
      "X_all + X_rfm           0.9786   0.9539       0.4432      0.2732    0.9558      NaN       0.0010         0.0    0.8977      NaN       0.0285         0.0    0.9783   0.9360       0.4125      0.1827    0.9436      NaN       0.0377         0.0    0.9943   0.9426       0.6669      0.2585    0.9793   0.9607       0.3764      0.2380    0.9301   0.7007       0.1102      0.0079    0.9520   0.7606       0.1824      0.0144\n",
      "X_all + X_rfm + X_dk    0.9959   0.9923       0.6594      0.4954    0.9735      NaN       0.0010         0.0    0.9037      NaN       0.0269         0.0    0.9801   0.9617       0.3785      0.2650    0.9649      NaN       0.0468         0.0    0.9916   0.9557       0.6230      0.3652    0.9893   0.9682       0.6065      0.3536    1.0000   0.9758       0.9770      0.5419    0.9999   0.9990       0.9737      0.6080\n",
      "X_dk                    0.9749   0.9766       0.1461      0.1537    0.9608      NaN       0.0008         0.0    0.8692      NaN       0.0090         0.0    0.9301   0.9325       0.0617      0.0973    0.9334      NaN       0.0100         0.0    0.9217   0.9122       0.1048      0.1287    0.9106   0.9185       0.0597      0.0443    0.9987   0.9772       0.4695      0.4338    0.9986   0.9987       0.4775      0.4836\n",
      "X_rfm                   0.8944   0.8317       0.0907      0.0350    0.8901      NaN       0.0003         0.0    0.7340      NaN       0.0041         0.0    0.8778   0.8072       0.0321      0.0179    0.7887      NaN       0.0045         0.0    0.8997   0.8035       0.0684      0.0224    0.8580   0.8353       0.0446      0.0157    0.8576   0.7570       0.0401      0.0092    0.8661   0.7044       0.0287      0.0044\n",
      "X_rfm + X_dk            0.9925   0.9907       0.5279      0.4573    0.9613      NaN       0.0007         0.0    0.8987      NaN       0.0227         0.0    0.9794   0.9664       0.3400      0.2960    0.9323      NaN       0.0228         0.0    0.9823   0.9496       0.4383      0.3391    0.9761   0.9617       0.3899      0.2178    0.9997   0.9862       0.8497      0.5627    0.9999   0.9991       0.9406      0.6433\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. å°‡ XGBoost çµæœè½‰æ›ç‚º DataFrame\n",
    "# ==========================================\n",
    "xgb_data_list = []\n",
    "\n",
    "for block_id, groups in xgb_results.items():\n",
    "    # æ ¹æ“šä½ çš„ code é‚è¼¯ï¼šYear = 2010 + block_id\n",
    "    current_year = 2010 + block_id \n",
    "    \n",
    "    for group_name, metrics in groups.items():\n",
    "        # æ’é™¤ç™¼ç”ŸéŒ¯èª¤çš„çµ„åˆ¥\n",
    "        if \"error\" in metrics:\n",
    "            continue\n",
    "            \n",
    "        row = {\n",
    "            \"Year\": current_year,\n",
    "            \"Feature Group\": group_name,\n",
    "            \"Train AUC\": metrics.get(\"Train AUC\"),\n",
    "            \"Test AUC\": metrics.get(\"Test AUC\"),\n",
    "            \"Train PR-AUC\": metrics.get(\"Train PR-AUC\"),\n",
    "            \"Test PR-AUC\": metrics.get(\"Test PR-AUC\"),\n",
    "            \"Best Iteration\": metrics.get(\"Best Iteration\") # XGBoost ç‰¹æœ‰çš„è³‡è¨Š\n",
    "        }\n",
    "        xgb_data_list.append(row)\n",
    "\n",
    "df_xgb_raw = pd.DataFrame(xgb_data_list)\n",
    "\n",
    "# ==========================================\n",
    "# 5. è£½ä½œæ•´åˆå¤§è¡¨ (Hierarchical Columns)\n",
    "# ==========================================\n",
    "\n",
    "# è¨­å®šè¦å‘ˆç¾çš„æŒ‡æ¨™ (å¯ä»¥è‡ªç”±å¢æ¸›ï¼Œä¾‹å¦‚åŠ å…¥ Best Iteration)\n",
    "target_metrics = [\"Train AUC\", \"Test AUC\", \"Train PR-AUC\", \"Test PR-AUC\"]\n",
    "\n",
    "# 1. ä½¿ç”¨ pivot è½‰ç½®\n",
    "# index: åˆ— (Feature Group)\n",
    "# columns: æ¬„ (Year)\n",
    "# values: å€¼ (æ‰€æœ‰æŒ‡æ¨™)\n",
    "df_xgb_pivot = df_xgb_raw.pivot(index=\"Feature Group\", columns=\"Year\", values=target_metrics)\n",
    "\n",
    "# 2. äº¤æ›æ¬„ä½å±¤ç´šï¼šå°‡ã€Œå¹´ä»½ã€ç§»åˆ°æœ€ä¸Šå±¤ (Level 0)ï¼ŒæŒ‡æ¨™ç§»åˆ°ç¬¬äºŒå±¤ (Level 1)\n",
    "df_xgb_pivot.columns = df_xgb_pivot.columns.swaplevel(0, 1)\n",
    "\n",
    "# 3. é‡æ–°æ’åºæ¬„ä½\n",
    "# æˆ‘å€‘å¸Œæœ›å¹´ä»½å¾å°åˆ°å¤§ï¼Œä¸”æ¯å€‹å¹´ä»½å…§çš„æŒ‡æ¨™é †åºå›ºå®š (Train -> Test)\n",
    "unique_years = sorted(df_xgb_raw[\"Year\"].unique())\n",
    "ordered_columns = []\n",
    "\n",
    "for year in unique_years:\n",
    "    for metric in target_metrics:\n",
    "        ordered_columns.append((year, metric))\n",
    "\n",
    "# å¼·åˆ¶å¥—ç”¨æ’åº\n",
    "df_xgb_final = df_xgb_pivot.reindex(columns=ordered_columns)\n",
    "\n",
    "print(\"\\n=== XGBoost æ•´åˆçµæœç¸½è¡¨ ===\")\n",
    "# å¦‚æœä½ åœ¨ Jupyter/Colabï¼Œç›´æ¥è¼¸å…¥ df_xgb_final å³å¯\n",
    "# é€™è£¡ç”¨ to_string ç¢ºä¿ç´”æ–‡å­—ä»‹é¢ä¹Ÿèƒ½çœ‹æ¸…æ¥š\n",
    "print(df_xgb_final.to_string())\n",
    "\n",
    "# ==========================================\n",
    "# 6. (é¸ç”¨) è¦–è¦ºåŒ–æ¨£å¼ - é‡å° Jupyter Notebook\n",
    "# ==========================================\n",
    "def highlight_xgb(val):\n",
    "    if pd.isna(val): return ''\n",
    "    # æ ¹æ“šç¶“é©—ï¼ŒXGBoost çš„ Train AUC å¾ˆå®¹æ˜“æ¥è¿‘ 1ï¼Œæ‰€ä»¥æ¨™æº–å¯ä»¥è¨­é«˜ä¸€é»\n",
    "    if val > 0.95: return 'background-color: #d4edda; color: green; font-weight: bold' # æ¥µå¥½ (ç¶ )\n",
    "    if val < 0.70: return 'background-color: #f8d7da; color: red'   # è¡¨ç¾å·® (ç´…)\n",
    "    return ''\n",
    "\n",
    "# é¡¯ç¤ºå¸¶æœ‰é¡è‰²çš„è¡¨æ ¼\n",
    "# df_xgb_final.style.applymap(highlight_xgb).format(\"{:.4f}\")\n",
    "df_xgb_final.to_csv(\"XGB_results_wide.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6-2 d) XGB ä½¿ç”¨stepwise selctioné¸å–è®Šæ•¸é‡è·‘\n",
    "\n",
    "6-2 d ç”¨æ–¼è·‘å®Œstepwise features selection å¾Œï¼Œç›´æ¥è®€å–é¸å®Œçš„featuresä¾†é€²è¡ŒXGBï¼Œè‹¥è¦å–®ç¨é‹è¡Œæ­¤æ®µç¨‹å¼ï¼Œè¨˜å¾—å…ˆè¼‰å¥½6-2 açš„functionå³å¯ï¼ï¼\n",
    "**XGB é‹è¡Œstepwise selectionçš„çµæœ**æœƒè¼¸å‡ºåœ¨è³‡æ–™å¤¾åç‚º<font color=blue>â€œxgb_stepwise.csvâ€</font>çš„csvæª”æ¡ˆç•¶ä¸­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6-2 e) Optional--ç”¨ä¾†æª¢æŸ¥ features importanceè€Œå·²ï¼ˆæˆ‘åœ¨å¯«codeéç¨‹ä¸­é¿å…è³‡æ–™æ´©æ¼çš„æª¢æŸ¥ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done (Best Iter: 14)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… Done (Best Iter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[33m'\u001b[39m\u001b[33mBest Iteration\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m# =========== âš ï¸ ä¿®æ”¹é€™è£¡ï¼ ===========\u001b[39;00m\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# åŸæœ¬æ˜¯: xgb_results[block_id][group_name] = metrics\u001b[39;00m\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# æ”¹æˆä¸‹é¢é€™æ¨£ï¼ŒæŠŠ Model ä¹Ÿå­˜é€²å»ï¼š\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[43mxgb_results\u001b[49m\u001b[43m[\u001b[49m\u001b[43mblock_id\u001b[49m\u001b[43m]\u001b[49m[group_name] = {\n\u001b[32m     24\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: res[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m],  \u001b[38;5;66;03m# <--- é—œéµï¼æŠŠæ¨¡å‹å­˜ä¸‹ä¾†\u001b[39;00m\n\u001b[32m     25\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m\"\u001b[39m: metrics\n\u001b[32m     26\u001b[39m     }\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# ====================================\u001b[39;00m\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâŒ Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "# ... (å‰é¢çš„å®šç¾©éƒ½ä¸ç”¨è®Š) ...\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    \n",
    "    # ... (ä¸­é–“çš„ split å’Œ feature group è¿´åœˆéƒ½ä¸ç”¨è®Š) ...\n",
    "    # é€™è£¡çœç•¥ä¸­é–“ä»£ç¢¼ï¼Œè«‹ç›´æ¥æ‰¾åˆ°å„²å­˜çµæœçš„é‚£ä¸€è¡Œ\n",
    "    \n",
    "        # åŸ·è¡Œ XGBoost\n",
    "        res = run_xgb_single(\n",
    "            train_raw, \n",
    "            test_raw, \n",
    "            feature_cols=valid_features, \n",
    "            dep_var=\"is_fraud\"\n",
    "        )\n",
    "\n",
    "        if res[\"status\"] == \"success\":\n",
    "            metrics = res[\"metrics\"]\n",
    "            print(f\"âœ… Done (Best Iter: {metrics['Best Iteration']})\")\n",
    "            \n",
    "            # =========== âš ï¸ ä¿®æ”¹é€™è£¡ï¼ ===========\n",
    "            # åŸæœ¬æ˜¯: xgb_results[block_id][group_name] = metrics\n",
    "            # æ”¹æˆä¸‹é¢é€™æ¨£ï¼ŒæŠŠ Model ä¹Ÿå­˜é€²å»ï¼š\n",
    "            xgb_results[block_id][group_name] = {\n",
    "                \"model\": res[\"model\"],  # <--- é—œéµï¼æŠŠæ¨¡å‹å­˜ä¸‹ä¾†\n",
    "                \"metrics\": metrics\n",
    "            }\n",
    "            # ====================================\n",
    "            \n",
    "        else:\n",
    "            print(f\"âŒ Error: {res['message']}\")\n",
    "            xgb_results[block_id][group_name] = {\"error\": res['message']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨åˆ†æ Time Block 9 çš„ç‰¹å¾µé‡è¦æ€§...\n",
      "              Feature  Importance\n",
      "27    merchant_others  785.025024\n",
      "30     DifferentState  730.633667\n",
      "26        merchant_us   79.876274\n",
      "28   FirstTxnInRegion   58.406689\n",
      "25    merchant_online   29.331198\n",
      "19    RecencyInterval   18.838356\n",
      "6       yearly_income   14.562068\n",
      "23   TxnFrequency_90d   12.727712\n",
      "29        HighRiskMCC    9.765574\n",
      "5   per_capita_income    9.287236\n",
      "7          total_debt    8.760721\n",
      "15    card_brand_Amex    7.528596\n",
      "22   TxnFrequency_60d    7.457257\n",
      "20    TxnFrequency_7d    7.362292\n",
      "10        gender_Male    7.073587\n",
      "12       credit_limit    6.861813\n",
      "4      retirement_age    6.658230\n",
      "9    num_credit_cards    6.531449\n",
      "21   TxnFrequency_30d    6.416031\n",
      "3         current_age    6.162704\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. è‡ªå‹•æŠ“å–æœ€å¾Œä¸€å€‹ Time Block çš„ ID (é¿å… Key Error)\n",
    "last_block_id = max(xgb_results.keys())\n",
    "print(f\"æ­£åœ¨åˆ†æ Time Block {last_block_id} çš„ç‰¹å¾µé‡è¦æ€§...\")\n",
    "\n",
    "# 2. å–å‡ºæ¨¡å‹\n",
    "# ç¢ºä¿æ‚¨ä½¿ç”¨çš„ group_name è·Ÿè¨“ç·´æ™‚ä¸€è‡´ (ä¾‹å¦‚ 'X_all + X_rfm + X_dk')\n",
    "target_group = 'X_all + X_rfm + X_dk' \n",
    "\n",
    "if target_group in xgb_results[last_block_id]:\n",
    "    model = xgb_results[last_block_id][target_group]['model']\n",
    "    \n",
    "    # 3. å–å¾—ç‰¹å¾µé‡è¦æ€§ (Gain)\n",
    "    # Gain ä»£è¡¨è©²ç‰¹å¾µåœ¨æ¨¹çš„åˆ†è£‚ä¸­å¸¶ä¾†äº†å¤šå°‘è³‡è¨Šå¢ç›Šï¼ˆæœ€æº–ç¢ºçš„æŒ‡æ¨™ï¼‰\n",
    "    importance = model.get_booster().get_score(importance_type='gain')\n",
    "    \n",
    "    # è½‰æˆ DataFrame\n",
    "    fi_df = pd.DataFrame(list(importance.items()), columns=['Feature', 'Importance'])\n",
    "    \n",
    "    # æ’åºä¸¦å–å‰ 20 å\n",
    "    fi_df = fi_df.sort_values(by='Importance', ascending=False).head(20)\n",
    "    \n",
    "    print(fi_df)\n",
    "\n",
    "    # 4. ç•«åœ–\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(fi_df['Feature'][::-1], fi_df['Importance'][::-1], color='#1f77b4')\n",
    "    plt.xlabel('Average Gain (Feature Importance)')\n",
    "    plt.title(f'Top 20 Features Driving the Model (Block {last_block_id})')\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(f\"æ‰¾ä¸åˆ° {target_group} çš„çµæœï¼Œè«‹æª¢æŸ¥æ‚¨çš„ feature_groups åç¨±\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Merchant Others åˆ†æ ===\n",
      "äº¤æ˜“ç¸½ç­†æ•¸: 59515\n",
      "è©æ¬ºç­†æ•¸: 3319\n",
      "è©æ¬ºç‡ (Fraud Rate): 5.58%\n",
      "------------------------------\n",
      "å…¨é«”å¹³å‡è©æ¬ºç‡: 0.0014954633014180765\n"
     ]
    }
   ],
   "source": [
    "# æª¢æŸ¥ merchant_others è£¡é¢çš„ç‹€æ³\n",
    "print(\"=== Merchant Others åˆ†æ ===\")\n",
    "mask = df_sorted['merchant_others'] == 1\n",
    "total = mask.sum()\n",
    "frauds = df_sorted.loc[mask, 'is_fraud'].sum()\n",
    "\n",
    "print(f\"äº¤æ˜“ç¸½ç­†æ•¸: {total}\")\n",
    "print(f\"è©æ¬ºç­†æ•¸: {frauds}\")\n",
    "print(f\"è©æ¬ºç‡ (Fraud Rate): {frauds/total:.2%}\")\n",
    "print(\"-\" * 30)\n",
    "print(\"å…¨é«”å¹³å‡è©æ¬ºç‡:\", df_sorted['is_fraud'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 0 (Year: 2010)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 6 features)... âœ… Test AUC: 0.9342\n",
      "   ğŸ”¥ Group: X_rfm (Using 4 features)... âœ… Test AUC: 0.8148\n",
      "   ğŸ”¥ Group: X_dk (Using 4 features)... âœ… Test AUC: 0.969\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 10 features)... âœ… Test AUC: 0.9533\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 8 features)... âœ… Test AUC: 0.9703\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 7 features)... âœ… Test AUC: 0.9758\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 12 features)... âœ… Test AUC: 0.9903\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 1 (Year: 2011)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 2 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_rfm (Using 1 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_dk (Using 2 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 7 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 3 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 5 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 7 features)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 2 (Year: 2012)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 3 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_rfm (Using 4 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_dk (Using 1 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 6 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 3 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 4 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 6 features)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 3 (Year: 2013)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 8 features)... âœ… Test AUC: 0.9028\n",
      "   ğŸ”¥ Group: X_rfm (Using 5 features)... âœ… Test AUC: 0.8051\n",
      "   ğŸ”¥ Group: X_dk (Using 3 features)... âœ… Test AUC: 0.9256\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 13 features)... âœ… Test AUC: 0.9468\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 12 features)... âœ… Test AUC: 0.9444\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 8 features)... âœ… Test AUC: 0.9646\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 15 features)... âœ… Test AUC: 0.9663\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 4 (Year: 2014)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 12 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_rfm (Using 4 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_dk (Using 3 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 14 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 12 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 6 features)... âœ… Test AUC: nan\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 17 features)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 5 (Year: 2015)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 11 features)... âœ… Test AUC: 0.9261\n",
      "   ğŸ”¥ Group: X_rfm (Using 5 features)... âœ… Test AUC: 0.8021\n",
      "   ğŸ”¥ Group: X_dk (Using 2 features)... âœ… Test AUC: 0.8772\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 18 features)... âœ… Test AUC: 0.9442\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 13 features)... âœ… Test AUC: 0.9386\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 7 features)... âœ… Test AUC: 0.9466\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 17 features)... âœ… Test AUC: 0.9522\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 6 (Year: 2016)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 9 features)... âœ… Test AUC: 0.942\n",
      "   ğŸ”¥ Group: X_rfm (Using 4 features)... âœ… Test AUC: 0.8385\n",
      "   ğŸ”¥ Group: X_dk (Using 2 features)... âœ… Test AUC: 0.8878\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 11 features)... âœ… Test AUC: 0.9598\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 10 features)... âœ… Test AUC: 0.9499\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 6 features)... âœ… Test AUC: 0.9586\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 15 features)... âœ… Test AUC: 0.9653\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 7 (Year: 2017)\n",
      "============================================================\n",
      "   âš ï¸ Group: X_all - Skipped (No features selected by Stepwise)\n",
      "   âš ï¸ Group: X_rfm - Skipped (No features selected by Stepwise)\n",
      "   âš ï¸ Group: X_dk - Skipped (No features selected by Stepwise)\n",
      "   âš ï¸ Group: X_all + X_rfm - Skipped (No features selected by Stepwise)\n",
      "   âš ï¸ Group: X_all + X_dk - Skipped (No features selected by Stepwise)\n",
      "   âš ï¸ Group: X_rfm + X_dk - Skipped (No features selected by Stepwise)\n",
      "   âš ï¸ Group: X_all + X_rfm + X_dk - Skipped (No features selected by Stepwise)\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 8 (Year: 2018)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 5 features)... âœ… Test AUC: 0.6004\n",
      "   ğŸ”¥ Group: X_rfm (Using 5 features)... âœ… Test AUC: 0.7576\n",
      "   ğŸ”¥ Group: X_dk (Using 3 features)... âœ… Test AUC: 0.9376\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 11 features)... âœ… Test AUC: 0.7167\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 7 features)... âœ… Test AUC: 0.6949\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 7 features)... âœ… Test AUC: 0.8532\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 11 features)... âœ… Test AUC: 0.8398\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block 9 (Year: 2019)\n",
      "============================================================\n",
      "   ğŸ”¥ Group: X_all (Using 6 features)... âœ… Test AUC: 0.6984\n",
      "   ğŸ”¥ Group: X_rfm (Using 4 features)... âœ… Test AUC: 0.7001\n",
      "   ğŸ”¥ Group: X_dk (Using 2 features)... âœ… Test AUC: 0.7503\n",
      "   ğŸ”¥ Group: X_all + X_rfm (Using 10 features)... âœ… Test AUC: 0.7554\n",
      "   ğŸ”¥ Group: X_all + X_dk (Using 8 features)... âœ… Test AUC: 0.8077\n",
      "   ğŸ”¥ Group: X_rfm + X_dk (Using 7 features)... âœ… Test AUC: 0.8814\n",
      "   ğŸ”¥ Group: X_all + X_rfm + X_dk (Using 11 features)... âœ… Test AUC: 0.8729\n",
      "\n",
      "ğŸ‰ All XGBoost models completed!\n",
      "\n",
      "=== XGBoost Performance (Using Stepwise Selected Features) ===\n",
      "Year                      2010                                        2011                                        2012                                        2013                                        2014                                        2015                                        2016                                        2017                                        2018                                        2019                                  \n",
      "                     Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC\n",
      "Feature Group                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "X_all                   0.9626   0.9342       0.2689      0.1278    0.8415      NaN       0.0003         0.0    0.6665      NaN       0.0033         0.0    0.9668   0.9028       0.2202      0.1131    0.9402      NaN       0.0267         0.0    0.9723   0.9261       0.3035      0.1643    0.9552   0.9420       0.2145      0.1769       NaN      NaN          NaN         NaN    0.8028   0.6004       0.0144      0.0042    0.7626   0.6984       0.0078      0.0046\n",
      "X_all + X_dk            0.9856   0.9703       0.4201      0.2398    0.8480      NaN       0.0003         0.0    0.6665      NaN       0.0033         0.0    0.9862   0.9444       0.4226      0.1327    0.9626      NaN       0.0469         0.0    0.9739   0.9386       0.3441      0.2179    0.9595   0.9499       0.2537      0.2306       NaN      NaN          NaN         NaN    0.9006   0.6949       0.0526      0.0175    0.9197   0.8077       0.0718      0.0194\n",
      "X_all + X_rfm           0.9926   0.9533       0.6756      0.2391    0.8686      NaN       0.0003         0.0    0.8782      NaN       0.0159         0.0    0.9749   0.9468       0.2779      0.1597    0.9406      NaN       0.0383         0.0    0.9910   0.9442       0.5858      0.2680    0.9700   0.9598       0.2924      0.2160       NaN      NaN          NaN         NaN    0.9085   0.7167       0.0722      0.0081    0.9329   0.7554       0.1303      0.0085\n",
      "X_all + X_rfm + X_dk    0.9935   0.9903       0.5778      0.4512    0.9121      NaN       0.0004         0.0    0.8782      NaN       0.0159         0.0    0.9957   0.9663       0.7006      0.2836    0.9658      NaN       0.0446         0.0    0.9883   0.9522       0.5361      0.3179    0.9805   0.9653       0.4161      0.3242       NaN      NaN          NaN         NaN    0.9356   0.8398       0.0801      0.0301    0.9483   0.8729       0.1201      0.0399\n",
      "X_dk                    0.9660   0.9690       0.0720      0.0751    0.5920      NaN       0.0001         0.0    0.8200      NaN       0.0069         0.0    0.9223   0.9256       0.0132      0.0304    0.6333      NaN       0.0019         0.0    0.8805   0.8772       0.0103      0.0210    0.8775   0.8878       0.0149      0.0116       NaN      NaN          NaN         NaN    0.9435   0.9376       0.0473      0.0340    0.7623   0.7503       0.0114      0.0108\n",
      "X_rfm                   0.8717   0.8148       0.0606      0.0213    0.8802      NaN       0.0003         0.0    0.7550      NaN       0.0044         0.0    0.9136   0.8051       0.0657      0.0175    0.8031      NaN       0.0063         0.0    0.9080   0.8021       0.0785      0.0227    0.8537   0.8385       0.0392      0.0157       NaN      NaN          NaN         NaN    0.8553   0.7576       0.0356      0.0101    0.8527   0.7001       0.0241      0.0041\n",
      "X_rfm + X_dk            0.9864   0.9758       0.3975      0.3246    0.9298      NaN       0.0005         0.0    0.8883      NaN       0.0181         0.0    0.9792   0.9646       0.3000      0.2342    0.9229      NaN       0.0229         0.0    0.9770   0.9466       0.3313      0.2753    0.9699   0.9586       0.2942      0.1703       NaN      NaN          NaN         NaN    0.9205   0.8532       0.0769      0.0284    0.9238   0.8814       0.0615      0.0363\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# 4. è‡ªå‹•åŒ–åŸ·è¡Œï¼šStepwise Features -> XGBoost\n",
    "# ===========================================================\n",
    "\n",
    "# ç”¨ä¾†å­˜æœ€çµ‚ XGBoost çš„çµæœ\n",
    "xgb_stepwise_results = []\n",
    "\n",
    "# ç¢ºä¿ df_sorted å­˜åœ¨\n",
    "if 'df_sorted' not in locals():\n",
    "    raise ValueError(\"âš ï¸ Error: 'df_sorted' æœªå®šç¾©\")\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    \n",
    "    current_year = 2010 + block_id\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸš€ Running XGBoost (w/ Stepwise Feats) for Block {block_id} (Year: {current_year})\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # --- 1. è³‡æ–™åˆ‡åˆ† (å¿…é ˆèˆ‡ Stepwise éšæ®µå®Œå…¨ä¸€è‡´) ---\n",
    "    block_df = block_df.sort_values('date')\n",
    "    split_index = int(len(block_df) * 0.8)\n",
    "    \n",
    "    train_raw = block_df.iloc[:split_index].copy()\n",
    "    test_raw  = block_df.iloc[split_index:].copy()\n",
    "\n",
    "    # --- 2. ç‰¹å¾µå·¥ç¨‹ (Anti-Leakage) ---\n",
    "    try:\n",
    "        fraud_rate = train_raw.groupby('mcc_code')['is_fraud'].mean()\n",
    "        high_risk_mcc = fraud_rate[fraud_rate > 0.02].index\n",
    "        train_raw['HighRiskMCC'] = train_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "        test_raw['HighRiskMCC']  = test_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "    except:\n",
    "        pass # è‹¥è³‡æ–™ç‚ºç©ºï¼Œå¾Œé¢æœƒè¢«æª¢æŸ¥æ“‹ä¸‹\n",
    "\n",
    "    # --- 3. å–å‡ºè©²å¹´ä»½ Stepwise é¸å‡ºçš„ç‰¹å¾µå­—å…¸ ---\n",
    "    # å¦‚æœè©²å¹´ä»½å®Œå…¨æ²’è·‘ Stepwise (ä¾‹å¦‚å ±éŒ¯)ï¼Œçµ¦ä¸€å€‹ç©ºå­—å…¸\n",
    "    block_feats_dict = stepwise_feature_storage.get(block_id, {})\n",
    "\n",
    "    # --- 4. é‡å°æ¯å€‹ Group è·‘ XGBoost ---\n",
    "    for group_name in feature_groups.keys():\n",
    "        \n",
    "        # å¾å­—å…¸ä¸­å–å‡ºã€Œè©²å¹´ä»½ã€è©²ç¾¤çµ„ã€ç¯©é¸å¾Œçš„è®Šæ•¸åˆ—è¡¨\n",
    "        my_features = block_feats_dict.get(group_name, [])\n",
    "        \n",
    "        # æª¢æŸ¥ 1: æ˜¯å¦æœ‰è®Šæ•¸è¢«é¸å‡º\n",
    "        if not my_features:\n",
    "            print(f\"   âš ï¸ Group: {group_name} - Skipped (No features selected by Stepwise)\")\n",
    "            # å­˜å…¥ NaN ä»¥ä¾¿å ±è¡¨å°é½Š\n",
    "            xgb_stepwise_results.append({\n",
    "                \"Year\": current_year,\n",
    "                \"Feature Group\": group_name,\n",
    "                \"Train AUC\": np.nan, \"Test AUC\": np.nan,\n",
    "                \"Train PR-AUC\": np.nan, \"Test PR-AUC\": np.nan,\n",
    "                \"Num Features\": 0\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        print(f\"   ğŸ”¥ Group: {group_name} (Using {len(my_features)} features)...\", end=\" \")\n",
    "\n",
    "        # æª¢æŸ¥ 2: åŸ·è¡Œ XGBoost\n",
    "        # æ³¨æ„ï¼šé€™è£¡å‚³å…¥çš„æ˜¯ my_features (Stepwise ç¯©é¸å¾Œçš„çµæœ)\n",
    "        res = run_xgb_single(\n",
    "            train_raw, \n",
    "            test_raw, \n",
    "            feature_cols=my_features, # <--- é—œéµåœ¨é€™è£¡\n",
    "            dep_var=\"is_fraud\"\n",
    "        )\n",
    "\n",
    "        if res[\"status\"] == \"success\":\n",
    "            m = res[\"metrics\"]\n",
    "            print(f\"âœ… Test AUC: {m.get('Test AUC', np.nan)}\")\n",
    "            \n",
    "            xgb_stepwise_results.append({\n",
    "                \"Year\": current_year,\n",
    "                \"Feature Group\": group_name,\n",
    "                \"Train AUC\": m.get(\"Train AUC\"),\n",
    "                \"Test AUC\": m.get(\"Test AUC\"),\n",
    "                \"Train PR-AUC\": m.get(\"Train PR-AUC\"),\n",
    "                \"Test PR-AUC\": m.get(\"Test PR-AUC\"),\n",
    "                \"Num Features\": len(my_features)\n",
    "            })\n",
    "            \n",
    "        elif res[\"status\"] == \"skip\":\n",
    "            print(f\"âš ï¸ Skipped: {res['message']}\")\n",
    "            xgb_stepwise_results.append({\n",
    "                \"Year\": current_year, \"Feature Group\": group_name,\n",
    "                \"Train AUC\": np.nan, \"Test AUC\": np.nan,\n",
    "                \"Train PR-AUC\": np.nan, \"Test PR-AUC\": np.nan,\n",
    "                \"Num Features\": len(my_features)\n",
    "            })\n",
    "            \n",
    "        else:\n",
    "            print(f\"âŒ Error: {res['message']}\")\n",
    "            # è¦–æƒ…æ³æ±ºå®šæ˜¯å¦ç´€éŒ„ Error\n",
    "\n",
    "print(\"\\nğŸ‰ All XGBoost models completed!\")\n",
    "\n",
    "# ===========================================================\n",
    "# 5. ç”¢å‡º XGBoost (Stepwise Features) æœ€çµ‚å ±è¡¨\n",
    "# ===========================================================\n",
    "if xgb_stepwise_results:\n",
    "    df_xgb_raw = pd.DataFrame(xgb_stepwise_results)\n",
    "    \n",
    "    # è¨­å®šæŒ‡æ¨™\n",
    "    target_metrics = [\"Train AUC\", \"Test AUC\", \"Train PR-AUC\", \"Test PR-AUC\"]\n",
    "    \n",
    "    # è½‰ç½®è¡¨æ ¼ (Pivot)\n",
    "    df_xgb_pivot = df_xgb_raw.pivot(index=\"Feature Group\", columns=\"Year\", values=target_metrics)\n",
    "    \n",
    "    # èª¿æ•´æ¬„ä½å±¤ç´š (Year åœ¨ä¸Š)\n",
    "    df_xgb_pivot.columns = df_xgb_pivot.columns.swaplevel(0, 1)\n",
    "    \n",
    "    # æ’åºæ¬„ä½\n",
    "    unique_years = sorted(df_xgb_raw[\"Year\"].unique())\n",
    "    ordered_columns = [(y, m) for y in unique_years for m in target_metrics]\n",
    "    df_xgb_final = df_xgb_pivot.reindex(columns=ordered_columns)\n",
    "    \n",
    "    print(\"\\n=== XGBoost Performance (Using Stepwise Selected Features) ===\")\n",
    "    print(df_xgb_final.to_string())\n",
    "else:\n",
    "    print(\"No results to display.\")\n",
    "\n",
    "df_xgb_final.to_csv(\"xgb_stepwise.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06-3 Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6-3 a) LGBM functionå®šç¾©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM for Block 0 (Year: 2010)\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 131\u001b[39m\n\u001b[32m    128\u001b[39m block_df = block_df.sort_values(\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    129\u001b[39m split_index = \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(block_df) * \u001b[32m0.8\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m train_raw = \u001b[43mblock_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msplit_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m test_raw  = block_df.iloc[split_index:].copy()\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# --- é‡ç®— HighRiskMCC (Anti-Leakage) ---\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# é€™æ˜¯å‹•æ…‹ç”Ÿæˆçš„ç‰¹å¾µ\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/pandas/core/generic.py:6830\u001b[39m, in \u001b[36mNDFrame.copy\u001b[39m\u001b[34m(self, deep)\u001b[39m\n\u001b[32m   6681\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   6682\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mTrue\u001b[39;00m) -> Self:\n\u001b[32m   6683\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   6684\u001b[39m \u001b[33;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[32m   6685\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   6828\u001b[39m \u001b[33;03m    dtype: int64\u001b[39;00m\n\u001b[32m   6829\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6830\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6831\u001b[39m     \u001b[38;5;28mself\u001b[39m._clear_item_cache()\n\u001b[32m   6832\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(data, axes=data.axes).__finalize__(\n\u001b[32m   6833\u001b[39m         \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mcopy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6834\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/pandas/core/internals/managers.py:593\u001b[39m, in \u001b[36mBaseBlockManager.copy\u001b[39m\u001b[34m(self, deep)\u001b[39m\n\u001b[32m    590\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    591\u001b[39m         new_axes = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.axes)\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcopy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    594\u001b[39m res.axes = new_axes\n\u001b[32m    596\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m    597\u001b[39m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/pandas/core/internals/managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Project/2025_Fraud-Detection-project/virtual/lib/python3.13/site-packages/pandas/core/internals/blocks.py:822\u001b[39m, in \u001b[36mBlock.copy\u001b[39m\u001b[34m(self, deep)\u001b[39m\n\u001b[32m    820\u001b[39m refs: BlockValuesRefs | \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     values = \u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    823\u001b[39m     refs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# --- è¼”åŠ©æª¢æŸ¥å‡½æ•¸ (é˜²æ­¢å´©æ½°) ---\n",
    "def check_data_validity(y_data, stage=\"Train\"):\n",
    "    if len(y_data) == 0:\n",
    "        return False, f\"{stage} set is empty\"\n",
    "    if y_data.nunique() < 2:\n",
    "        val = y_data.iloc[0] if len(y_data) > 0 else \"None\"\n",
    "        return False, f\"{stage} set has only 1 class (value: {val})\"\n",
    "    return True, \"\"\n",
    "\n",
    "# ===========================================================\n",
    "# 1. ä¿®æ”¹å¾Œçš„ LightGBM è¨“ç·´å‡½æ•¸ (å«é˜²å‘†æ©Ÿåˆ¶)\n",
    "# ===========================================================\n",
    "def run_lgbm_single(train_df, test_df, feature_cols, dep_var=\"is_fraud\"):\n",
    "    \"\"\"\n",
    "    é‡å° Stepwise ç¯©é¸å¾Œçš„ç‰¹å¾µè¨“ç·´ LightGBMï¼Œä¸¦è™•ç†é‚Šç•Œæƒ…æ³ (Edge Cases)\n",
    "    \"\"\"\n",
    "    X_train = train_df[feature_cols]\n",
    "    y_train = train_df[dep_var]\n",
    "    X_test  = test_df[feature_cols]\n",
    "    y_test  = test_df[dep_var]\n",
    "\n",
    "    # --- 1. é˜²å´©æ½°æª¢æŸ¥ (é‡è¦ä¿®æ”¹) ---\n",
    "    # æª¢æŸ¥ Train: è‹¥ç„¡æ•ˆ (å¦‚å…¨ç‚º0)ï¼Œæ¨¡å‹ç„¡æ³•å­¸ç¿’ï¼Œç›´æ¥è·³é\n",
    "    is_valid_train, msg_train = check_data_validity(y_train, \"Train\")\n",
    "    if not is_valid_train:\n",
    "        return {\"status\": \"skip\", \"message\": msg_train}\n",
    "\n",
    "    # æª¢æŸ¥ Test: è‹¥ç„¡æ•ˆ (åªæœ‰ä¸€é¡)ï¼Œæ¨¡å‹ä»å¯è·‘ï¼Œä½† Test Metrics æœƒæ˜¯ NaN\n",
    "    is_valid_test, _ = check_data_validity(y_test, \"Test\")\n",
    "\n",
    "    # --- 2. è™•ç†é¡åˆ¥ä¸å¹³è¡¡ ---\n",
    "    pos = y_train.sum()\n",
    "    neg = len(y_train) - pos\n",
    "    # é˜²å‘†: é›–ç„¶å‰é¢å·²ç¶“æª¢æŸ¥é validityï¼Œä½†ç‚ºäº†ä¿éšªèµ·è¦‹\n",
    "    spw = neg / pos if pos > 0 else 1\n",
    "\n",
    "    # --- 3. åˆå§‹åŒ–æ¨¡å‹ ---\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.02,\n",
    "        max_bin=128,\n",
    "        scale_pos_weight=spw,\n",
    "        min_split_gain=1.0,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=5,\n",
    "        min_child_samples=20,\n",
    "        max_depth=4,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # --- 4. è¨“ç·´æ¨¡å‹ ---\n",
    "        # ç­–ç•¥ï¼šå¦‚æœæ¸¬è©¦é›†ç„¡æ•ˆï¼Œæˆ‘å€‘ç”¨è¨“ç·´é›†å……ç•¶ eval_set é˜²æ­¢å ±éŒ¯ï¼Œ\n",
    "        # ä½†é€™æ™‚ early_stopping çš„æ„ç¾©ä¸å¤§ï¼Œä¸éç‚ºäº†ä»£ç¢¼ä¸€è‡´æ€§æˆ‘å€‘ä¿ç•™ã€‚\n",
    "        \n",
    "        if is_valid_test:\n",
    "            eval_set = [(X_test, y_test)]\n",
    "        else:\n",
    "            eval_set = [(X_train, y_train)]\n",
    "\n",
    "        callbacks = [lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "        \n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=eval_set,\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        # --- 5. è¨ˆç®—æŒ‡æ¨™ ---\n",
    "        # Train éƒ¨åˆ† (é€šå¸¸ä¸æœƒæœ‰å•é¡Œ)\n",
    "        train_pred = model.predict_proba(X_train)[:, 1]\n",
    "        train_auc = roc_auc_score(y_train, train_pred)\n",
    "        train_pr  = average_precision_score(y_train, train_pred)\n",
    "\n",
    "        # Test éƒ¨åˆ† (é—œéµä¿®æ”¹ï¼šè™•ç† NaN)\n",
    "        test_auc = np.nan\n",
    "        test_pr = np.nan\n",
    "\n",
    "        if is_valid_test:\n",
    "            try:\n",
    "                test_pred = model.predict_proba(X_test)[:, 1]\n",
    "                test_auc = roc_auc_score(y_test, test_pred)\n",
    "                test_pr = average_precision_score(y_test, test_pred)\n",
    "            except ValueError:\n",
    "                # è¬ä¸€ç™¼ç”Ÿé æ¸¬å€¼å…¨ç‚ºåŒä¸€é¡åˆ¥ç­‰æ¥µç«¯æƒ…æ³\n",
    "                pass \n",
    "\n",
    "        best_iter = model.best_iteration_ if model.best_iteration_ else 500\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"metrics\": {\n",
    "                \"Train AUC\": round(train_auc, 4),\n",
    "                \"Test AUC\": round(test_auc, 4) if not np.isnan(test_auc) else np.nan,\n",
    "                \"Train PR-AUC\": round(train_pr, 4),\n",
    "                \"Test PR-AUC\": round(test_pr, 4) if not np.isnan(test_pr) else np.nan,\n",
    "                \"Best Iteration\": best_iter\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"message\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6-3 b) Run LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===========================================================\n",
    "# 2. ä¸»è¿´åœˆ (ä¿®æ­£ HighRiskMCC åŠ å…¥æ–¹å¼ & Skip è™•ç†)\n",
    "# ===========================================================\n",
    "\n",
    "# ... (å‰é¢çš„ feature_groups å®šç¾©éƒ½ä¸ç”¨å‹•) ...\n",
    "\n",
    "lgbm_results = {}\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸš€ Running LightGBM for Block {block_id} (Year: {2010 + block_id})\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # --- è³‡æ–™åˆ‡åˆ† ---\n",
    "    block_df = block_df.sort_values('date')\n",
    "    split_index = int(len(block_df) * 0.8)\n",
    "    \n",
    "    train_raw = block_df.iloc[:split_index].copy()\n",
    "    test_raw  = block_df.iloc[split_index:].copy()\n",
    "\n",
    "    # --- é‡ç®— HighRiskMCC (Anti-Leakage) ---\n",
    "    # é€™æ˜¯å‹•æ…‹ç”Ÿæˆçš„ç‰¹å¾µ\n",
    "    fraud_rate = train_raw.groupby('mcc_code')['is_fraud'].mean()\n",
    "    high_risk_mcc = fraud_rate[fraud_rate > 0.02].index\n",
    "    \n",
    "    train_raw['HighRiskMCC'] = train_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "    test_raw['HighRiskMCC']  = test_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "\n",
    "    lgbm_results[block_id] = {}\n",
    "\n",
    "    for group_name, feature_list in feature_groups.items():\n",
    "        \n",
    "        # 1. å…ˆéæ¿¾åŸæœ¬å­˜åœ¨çš„ç‰¹å¾µ\n",
    "        valid_features = [f for f in feature_list if f in train_raw.columns]\n",
    "        \n",
    "        # â˜…â˜…â˜… ä¿®æ­£é» 1: ç¢ºä¿å‹•æ…‹ç‰¹å¾µ HighRiskMCC è¢«åŠ å…¥ â˜…â˜…â˜…\n",
    "        # å¦‚æœä½ å¸Œæœ›æ¯å€‹æ¨¡å‹éƒ½åŒ…å«é€™å€‹å¼·ç‰¹å¾µï¼Œè«‹åœ¨é€™è£¡æ‰‹å‹• append\n",
    "        if 'HighRiskMCC' not in valid_features:\n",
    "            valid_features.append('HighRiskMCC')\n",
    "\n",
    "        if not valid_features:\n",
    "            continue\n",
    "            \n",
    "        print(f\"   ğŸ”¹ Group: {group_name} ({len(valid_features)} features)...\", end=\" \")\n",
    "\n",
    "        # åŸ·è¡Œ LightGBM\n",
    "        res = run_lgbm_single(\n",
    "            train_raw, \n",
    "            test_raw, \n",
    "            feature_cols=valid_features, \n",
    "            dep_var=\"is_fraud\"\n",
    "        )\n",
    "\n",
    "        # â˜…â˜…â˜… ä¿®æ­£é» 2: å„ªé›…åœ°è™•ç† Skip ç‹€æ…‹ â˜…â˜…â˜…\n",
    "        if res[\"status\"] == \"success\":\n",
    "            metrics = res[\"metrics\"]\n",
    "            print(f\"âœ… Done (Best Iter: {metrics['Best Iteration']})\")\n",
    "            lgbm_results[block_id][group_name] = metrics\n",
    "            \n",
    "        elif res[\"status\"] == \"skip\":\n",
    "            # é‡åˆ°è³‡æ–™ä¸è¶³ (ä¾‹å¦‚è©²å¹´ç„¡è©æ¬º)ï¼Œé¡¯ç¤ºé»ƒè‰²è­¦å‘Šä½†ä¸å ±éŒ¯\n",
    "            print(f\"âš ï¸ Skipped: {res['message']}\")\n",
    "            lgbm_results[block_id][group_name] = {\"skipped\": True, \"reason\": res['message']}\n",
    "            \n",
    "        else:\n",
    "            # çœŸæ­£çš„ç¨‹å¼éŒ¯èª¤æ‰é¡¯ç¤º Error\n",
    "            print(f\"âŒ Error: {res['message']}\")\n",
    "            lgbm_results[block_id][group_name] = {\"error\": res['message']}\n",
    "\n",
    "print(\"\\nğŸ‰ All LightGBM models completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6-3 c) LGBM result output\n",
    "\n",
    "6-3 c **è·‘å®ŒLGBMå¾Œçš„çµæœ**æœƒè¼¸å‡ºåœ¨è³‡æ–™å¤¾åç‚º<font color=blue>â€œlgbm_results_wide.csvâ€</font>çš„csvæª”æ¡ˆç•¶ä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LightGBM æ•´åˆçµæœç¸½è¡¨ ===\n",
      "Year                      2010                                        2011                                        2012                                        2013                                        2014                                        2015                                        2016                                        2017                                        2018                                        2019                                  \n",
      "                     Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC\n",
      "Feature Group                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "X_all                   0.9461   0.9243       0.0731      0.0643    0.9956      NaN       0.0058         NaN    0.9730      NaN       0.2116         NaN    0.9271   0.8950       0.0177      0.0414    0.9607      NaN       0.0168         NaN    0.9660   0.8764       0.1692      0.1295    0.8993   0.9016       0.0230      0.0171       NaN      NaN          NaN         NaN    0.7776   0.6269       0.0339      0.0147    0.7605   0.7197       0.0142      0.0174\n",
      "X_all + X_dk            0.9681   0.9682       0.0714      0.0632    0.9916      NaN       0.0031         NaN    0.9745      NaN       0.2163         NaN    0.9173   0.9017       0.0083      0.0191    0.9678      NaN       0.0178         NaN    0.9366   0.9082       0.0284      0.0491    0.9305   0.9347       0.0373      0.0308       NaN      NaN          NaN         NaN    0.9992   0.9180       0.6049      0.4627    0.9994   0.9987       0.7359      0.5735\n",
      "X_all + X_rfm           0.8184   0.8180       0.0258      0.0231    0.9968      NaN       0.0080         NaN    0.9809      NaN       0.1675         NaN    0.9624   0.8197       0.0679      0.0656    0.9765      NaN       0.0341         NaN    0.9711   0.9318       0.2023      0.2050    0.9284   0.9327       0.0370      0.0294       NaN      NaN          NaN         NaN    0.9217   0.6744       0.0988      0.0224    0.7787   0.7510       0.0144      0.0171\n",
      "X_all + X_rfm + X_dk    0.9694   0.9702       0.0537      0.0481    0.9979      NaN       0.0121         NaN    0.9826      NaN       0.1501         NaN    0.7408   0.6895       0.0265      0.0507    0.9654      NaN       0.0118         NaN    0.9369   0.9025       0.0301      0.0516    0.9305   0.9339       0.0378      0.0306       NaN      NaN          NaN         NaN    0.9995   0.9226       0.7049      0.4944    0.9993   0.9989       0.6409      0.5238\n",
      "X_dk                    0.9704   0.9728       0.0692      0.0771    0.9426      NaN       0.0005         NaN    0.8755      NaN       0.0416         NaN    0.9224   0.9240       0.0130      0.0295    0.9194      NaN       0.0062         NaN    0.9188   0.9095       0.0279      0.0522    0.9104   0.9184       0.0387      0.0301       NaN      NaN          NaN         NaN    0.9987   0.9793       0.4708      0.4389    0.9986   0.9987       0.4763      0.4861\n",
      "X_rfm                   0.7649   0.7586       0.0230      0.0203    0.9839      NaN       0.0016         NaN    0.8972      NaN       0.0339         NaN    0.8795   0.7833       0.0251      0.0331    0.9102      NaN       0.0063         NaN    0.7695   0.7359       0.0193      0.0341    0.7737   0.7749       0.0208      0.0166       NaN      NaN          NaN         NaN    0.7444   0.7176       0.0151      0.0142    0.7475   0.7105       0.0144      0.0173\n",
      "X_rfm + X_dk            0.9631   0.9661       0.0437      0.0422    0.9976      NaN       0.0105         NaN    0.9662      NaN       0.1079         NaN    0.9730   0.9150       0.1412      0.2163    0.9638      NaN       0.0153         NaN    0.9736   0.9324       0.2271      0.2964    0.9299   0.9354       0.0368      0.0294       NaN      NaN          NaN         NaN    0.9993   0.9353       0.6508      0.4970    0.9995   0.9990       0.7461      0.6204\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. è£½ä½œ LightGBM æ•´åˆå ±è¡¨\n",
    "# ==========================================\n",
    "lgbm_data_list = []\n",
    "\n",
    "for block_id, groups in lgbm_results.items():\n",
    "    current_year = 2010 + block_id \n",
    "    \n",
    "    for group_name, metrics in groups.items():\n",
    "        if \"error\" in metrics:\n",
    "            continue\n",
    "            \n",
    "        row = {\n",
    "            \"Year\": current_year,\n",
    "            \"Feature Group\": group_name,\n",
    "            \"Train AUC\": metrics.get(\"Train AUC\"),\n",
    "            \"Test AUC\": metrics.get(\"Test AUC\"),\n",
    "            \"Train PR-AUC\": metrics.get(\"Train PR-AUC\"),\n",
    "            \"Test PR-AUC\": metrics.get(\"Test PR-AUC\")\n",
    "        }\n",
    "        lgbm_data_list.append(row)\n",
    "\n",
    "df_lgbm_raw = pd.DataFrame(lgbm_data_list)\n",
    "\n",
    "# --- è½‰ç½®èˆ‡éšå±¤åŒ– ---\n",
    "target_metrics = [\"Train AUC\", \"Test AUC\", \"Train PR-AUC\", \"Test PR-AUC\"]\n",
    "\n",
    "# 1. Pivot: Index=Feature Group, Cols=Year\n",
    "df_lgbm_pivot = df_lgbm_raw.pivot(index=\"Feature Group\", columns=\"Year\", values=target_metrics)\n",
    "\n",
    "# 2. Swaplevel: è®“å¹´ä»½åœ¨æœ€ä¸Šå±¤\n",
    "df_lgbm_pivot.columns = df_lgbm_pivot.columns.swaplevel(0, 1)\n",
    "\n",
    "# 3. Reindex: å¼·åˆ¶æ’åº (å¹´ä»½å°->å¤§, æŒ‡æ¨™ Train->Test)\n",
    "unique_years = sorted(df_lgbm_raw[\"Year\"].unique())\n",
    "ordered_columns = []\n",
    "for year in unique_years:\n",
    "    for metric in target_metrics:\n",
    "        ordered_columns.append((year, metric))\n",
    "\n",
    "df_lgbm_final = df_lgbm_pivot.reindex(columns=ordered_columns)\n",
    "\n",
    "print(\"\\n=== LightGBM æ•´åˆçµæœç¸½è¡¨ ===\")\n",
    "print(df_lgbm_final.to_string())\n",
    "\n",
    "# å¦‚æœæ‚¨åœ¨ Jupyter Notebookï¼Œå¯ä»¥ç”¨é€™è¡Œé¡¯ç¤ºæ¼‚äº®çš„ HTML è¡¨æ ¼\n",
    "# df_lgbm_final.style.format(\"{:.4f}\").background_gradient(cmap='Blues', subset=pd.IndexSlice[:, (slice(None), 'Test AUC')])\n",
    "df_lgbm_final.to_csv(\"lgbm_results_wide.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6-3 d) LGBM ä½¿ç”¨stepwise ç‰ˆæœ¬\n",
    "\n",
    "6-3 d ç”¨æ–¼è·‘å®Œstepwise features selection å¾Œï¼Œç›´æ¥è®€å–é¸å®Œçš„featuresä¾†é€²è¡ŒLGBMï¼Œè‹¥è¦å–®ç¨é‹è¡Œæ­¤æ®µç¨‹å¼ï¼Œè¨˜å¾—å…ˆè¼‰å¥½6-3 açš„functionå³å¯ï¼ï¼\n",
    "**LGBM é‹è¡Œstepwise selectionçš„çµæœ**æœƒè¼¸å‡ºåœ¨è³‡æ–™å¤¾åç‚º<font color=blue>â€œlgbm_stepwise.csvâ€</font>çš„csvæª”æ¡ˆç•¶ä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 0 (Year: 2010)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 6 feats)... âœ… Test AUC: 0.8839\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 feats)... âœ… Test AUC: 0.735\n",
      "   ğŸ”¹ Group: X_dk (Using 4 feats)... âœ… Test AUC: 0.9515\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 10 feats)... âœ… Test AUC: 0.9181\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 8 feats)... âœ… Test AUC: 0.9576\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 7 feats)... âœ… Test AUC: 0.7709\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 12 feats)... âœ… Test AUC: 0.9282\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 1 (Year: 2011)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 2 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm (Using 1 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_dk (Using 2 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 7 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 3 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 5 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 7 feats)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 2 (Year: 2012)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 3 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_dk (Using 1 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 6 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 3 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 4 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 6 feats)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 3 (Year: 2013)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 8 feats)... âœ… Test AUC: 0.8776\n",
      "   ğŸ”¹ Group: X_rfm (Using 5 feats)... âœ… Test AUC: 0.7635\n",
      "   ğŸ”¹ Group: X_dk (Using 3 feats)... âœ… Test AUC: 0.8393\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 13 feats)... âœ… Test AUC: 0.8902\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 12 feats)... âœ… Test AUC: 0.9287\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 8 feats)... âœ… Test AUC: 0.7029\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 15 feats)... âœ… Test AUC: 0.9046\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 4 (Year: 2014)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 12 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_dk (Using 3 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 14 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 12 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 6 feats)... âœ… Test AUC: nan\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 17 feats)... âœ… Test AUC: nan\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 5 (Year: 2015)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 11 feats)... âœ… Test AUC: 0.9158\n",
      "   ğŸ”¹ Group: X_rfm (Using 5 feats)... âœ… Test AUC: 0.7344\n",
      "   ğŸ”¹ Group: X_dk (Using 2 feats)... âœ… Test AUC: 0.9018\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 18 feats)... âœ… Test AUC: 0.9277\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 13 feats)... âœ… Test AUC: 0.9145\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 7 feats)... âœ… Test AUC: 0.9344\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 17 feats)... âœ… Test AUC: 0.93\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 6 (Year: 2016)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 9 feats)... âœ… Test AUC: 0.9269\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 feats)... âœ… Test AUC: 0.7997\n",
      "   ğŸ”¹ Group: X_dk (Using 2 feats)... âœ… Test AUC: 0.9094\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 11 feats)... âœ… Test AUC: 0.9387\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 10 feats)... âœ… Test AUC: 0.9285\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 6 feats)... âœ… Test AUC: 0.9301\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 15 feats)... âœ… Test AUC: 0.9127\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 7 (Year: 2017)\n",
      "============================================================\n",
      "   âš ï¸ Group: X_all - Skipped (No features from Stepwise)\n",
      "   âš ï¸ Group: X_rfm - Skipped (No features from Stepwise)\n",
      "   âš ï¸ Group: X_dk - Skipped (No features from Stepwise)\n",
      "   âš ï¸ Group: X_all + X_rfm - Skipped (No features from Stepwise)\n",
      "   âš ï¸ Group: X_all + X_dk - Skipped (No features from Stepwise)\n",
      "   âš ï¸ Group: X_rfm + X_dk - Skipped (No features from Stepwise)\n",
      "   âš ï¸ Group: X_all + X_rfm + X_dk - Skipped (No features from Stepwise)\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 8 (Year: 2018)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 5 feats)... âœ… Test AUC: 0.5688\n",
      "   ğŸ”¹ Group: X_rfm (Using 5 feats)... âœ… Test AUC: 0.7391\n",
      "   ğŸ”¹ Group: X_dk (Using 3 feats)... âœ… Test AUC: 0.9186\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 11 feats)... âœ… Test AUC: 0.6876\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 7 feats)... âœ… Test AUC: 0.6626\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 7 feats)... âœ… Test AUC: 0.8275\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 11 feats)... âœ… Test AUC: 0.8216\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Running LightGBM (Stepwise Feats) for Block 9 (Year: 2019)\n",
      "============================================================\n",
      "   ğŸ”¹ Group: X_all (Using 6 feats)... âœ… Test AUC: 0.6501\n",
      "   ğŸ”¹ Group: X_rfm (Using 4 feats)... âœ… Test AUC: 0.6007\n",
      "   ğŸ”¹ Group: X_dk (Using 2 feats)... âœ… Test AUC: 0.7503\n",
      "   ğŸ”¹ Group: X_all + X_rfm (Using 10 feats)... âœ… Test AUC: 0.7311\n",
      "   ğŸ”¹ Group: X_all + X_dk (Using 8 feats)... âœ… Test AUC: 0.7654\n",
      "   ğŸ”¹ Group: X_rfm + X_dk (Using 7 feats)... âœ… Test AUC: 0.87\n",
      "   ğŸ”¹ Group: X_all + X_rfm + X_dk (Using 11 feats)... âœ… Test AUC: 0.8402\n",
      "\n",
      "ğŸ‰ All LightGBM models (Stepwise) completed!\n",
      "\n",
      "=== LightGBM Performance (Using Stepwise Selected Features) ===\n",
      "Year                      2010                                        2011                                        2012                                        2013                                        2014                                        2015                                        2016                                        2017                                        2018                                        2019                                  \n",
      "                     Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC Train AUC Test AUC Train PR-AUC Test PR-AUC\n",
      "Feature Group                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "X_all                   0.9054   0.8839       0.0246      0.0204    0.9060      NaN       0.0004         NaN    0.9287      NaN       0.0379         NaN    0.9327   0.8776       0.0183      0.0407    0.9379      NaN       0.0112         NaN    0.9588   0.9158       0.1428      0.1216    0.9276   0.9269       0.0365      0.0303       NaN      NaN          NaN         NaN    0.8176   0.5688       0.0159      0.0039    0.7112   0.6501       0.0039      0.0036\n",
      "X_all + X_dk            0.9620   0.9576       0.0498      0.0447    0.4990      NaN       0.0001         NaN    0.9287      NaN       0.0379         NaN    0.9551   0.9287       0.0426      0.0781    0.9906      NaN       0.0661         NaN    0.9682   0.9145       0.1940      0.1381    0.9249   0.9285       0.0361      0.0300       NaN      NaN          NaN         NaN    0.8700   0.6626       0.0337      0.0161    0.8869   0.7654       0.0314      0.0177\n",
      "X_all + X_rfm           0.9409   0.9181       0.0418      0.0378    0.9962      NaN       0.0067         NaN    0.9580      NaN       0.0723         NaN    0.9769   0.8902       0.0927      0.0939    0.9540      NaN       0.0121         NaN    0.9577   0.9277       0.0765      0.1119    0.9309   0.9387       0.0368      0.0300       NaN      NaN          NaN         NaN    0.7768   0.6876       0.0071      0.0048    0.8705   0.7311       0.0194      0.0053\n",
      "X_all + X_rfm + X_dk    0.9533   0.9282       0.0434      0.0392    0.9986      NaN       0.0178         NaN    0.9580      NaN       0.0723         NaN    0.9844   0.9046       0.1411      0.1475    0.9451      NaN       0.0149         NaN    0.9869   0.9300       0.3473      0.2484    0.9093   0.9127       0.0238      0.0200       NaN      NaN          NaN         NaN    0.9149   0.8216       0.0369      0.0203    0.9436   0.8402       0.0684      0.0257\n",
      "X_dk                    0.9530   0.9515       0.0439      0.0409    0.9187      NaN       0.0004         NaN    0.8200      NaN       0.0069         NaN    0.8306   0.8393       0.0043      0.0114    0.8016      NaN       0.0028         NaN    0.9107   0.9018       0.0188      0.0343    0.8984   0.9094       0.0227      0.0179       NaN      NaN          NaN         NaN    0.9360   0.9186       0.0127      0.0158    0.7623   0.7503       0.0114      0.0108\n",
      "X_rfm                   0.7421   0.7350       0.0081      0.0069    0.6495      NaN       0.0001         NaN    0.8594      NaN       0.0092         NaN    0.8959   0.7635       0.0150      0.0142    0.9113      NaN       0.0099         NaN    0.7871   0.7344       0.0067      0.0105    0.7711   0.7997       0.0088      0.0073       NaN      NaN          NaN         NaN    0.8461   0.7391       0.0131      0.0080    0.6958   0.6007       0.0038      0.0028\n",
      "X_rfm + X_dk            0.7703   0.7709       0.0103      0.0081    0.9922      NaN       0.0033         NaN    0.9366      NaN       0.0363         NaN    0.7598   0.7029       0.0246      0.0441    0.9517      NaN       0.0114         NaN    0.9731   0.9344       0.1600      0.1829    0.9246   0.9301       0.0284      0.0222       NaN      NaN          NaN         NaN    0.9173   0.8275       0.0420      0.0275    0.9190   0.8700       0.0470      0.0285\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# 2. è‡ªå‹•åŒ–åŸ·è¡Œï¼šStepwise Features -> LightGBM\n",
    "# ===========================================================\n",
    "\n",
    "lgbm_stepwise_results = []\n",
    "\n",
    "# æª¢æŸ¥å¿…è¦è®Šæ•¸\n",
    "if 'df_sorted' not in locals():\n",
    "    raise ValueError(\"âš ï¸ Error: 'df_sorted' æœªå®šç¾©\")\n",
    "if 'stepwise_feature_storage' not in locals():\n",
    "    raise ValueError(\"âš ï¸ Error: 'stepwise_feature_storage' æœªå®šç¾©ï¼Œè«‹å…ˆåŸ·è¡Œ Stepwise æ­¥é©Ÿã€‚\")\n",
    "\n",
    "# é€™è£¡æˆ‘å€‘ä»éœ€è¦ feature_groups çš„ key (ä¾‹å¦‚ \"X_all\", \"X_rfm\") ä¾†è·‘è¿´åœˆ\n",
    "group_names = feature_groups.keys()\n",
    "\n",
    "for block_id, block_df in df_sorted.groupby('time_block'):\n",
    "    \n",
    "    current_year = 2010 + block_id\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸš€ Running LightGBM (Stepwise Feats) for Block {block_id} (Year: {current_year})\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # --- 1. è³‡æ–™åˆ‡åˆ† (Split) - ä¿æŒä¸€è‡´ ---\n",
    "    block_df = block_df.sort_values('date')\n",
    "    split_index = int(len(block_df) * 0.8)\n",
    "    \n",
    "    train_raw = block_df.iloc[:split_index].copy()\n",
    "    test_raw  = block_df.iloc[split_index:].copy()\n",
    "\n",
    "    # --- 2. ç‰¹å¾µå·¥ç¨‹ (Anti-Leakage) ---\n",
    "    try:\n",
    "        fraud_rate = train_raw.groupby('mcc_code')['is_fraud'].mean()\n",
    "        high_risk_mcc = fraud_rate[fraud_rate > 0.02].index\n",
    "        train_raw['HighRiskMCC'] = train_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "        test_raw['HighRiskMCC']  = test_raw['mcc_code'].isin(high_risk_mcc).astype('uint8')\n",
    "    except:\n",
    "        pass # è‹¥è³‡æ–™ç‚ºç©ºï¼Œç¨å¾Œæœƒè¢« skip\n",
    "\n",
    "    # --- 3. è®€å–è©²å¹´ä»½çš„ Stepwise è®Šæ•¸å­—å…¸ ---\n",
    "    # å¦‚æœè©²å¹´ä»½å®Œå…¨æ²’è·‘å‡ºçµæœ (ä¾‹å¦‚è³‡æ–™å¤ªå°‘å ±éŒ¯)ï¼Œçµ¦ç©ºå­—å…¸\n",
    "    block_feats_dict = stepwise_feature_storage.get(block_id, {})\n",
    "\n",
    "    # --- 4. é‡å°æ¯å€‹ Group åŸ·è¡Œ ---\n",
    "    for group_name in group_names:\n",
    "        \n",
    "        # â˜… é—œéµï¼šå¾å­—å…¸å–å‡º Stepwise ç¯©é¸å¾Œçš„è®Šæ•¸\n",
    "        my_features = block_feats_dict.get(group_name, [])\n",
    "        \n",
    "        # æƒ…æ³ A: Stepwise æ²’é¸å‡ºä»»ä½•è®Šæ•¸ (æˆ–è©²çµ„è³‡æ–™æœ‰å•é¡Œ)\n",
    "        if not my_features:\n",
    "            print(f\"   âš ï¸ Group: {group_name} - Skipped (No features from Stepwise)\")\n",
    "            lgbm_stepwise_results.append({\n",
    "                \"Year\": current_year, \"Feature Group\": group_name,\n",
    "                \"Train AUC\": np.nan, \"Test AUC\": np.nan,\n",
    "                \"Train PR-AUC\": np.nan, \"Test PR-AUC\": np.nan,\n",
    "                \"Num Features\": 0\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        print(f\"   ğŸ”¹ Group: {group_name} (Using {len(my_features)} feats)...\", end=\" \")\n",
    "\n",
    "        # æƒ…æ³ B: åŸ·è¡Œ LightGBM\n",
    "        res = run_lgbm_single(\n",
    "            train_raw, \n",
    "            test_raw, \n",
    "            feature_cols=my_features, # ä½¿ç”¨ç¯©é¸å¾Œçš„è®Šæ•¸\n",
    "            dep_var=\"is_fraud\"\n",
    "        )\n",
    "\n",
    "        if res[\"status\"] == \"success\":\n",
    "            m = res[\"metrics\"]\n",
    "            print(f\"âœ… Test AUC: {m.get('Test AUC', np.nan)}\")\n",
    "            \n",
    "            lgbm_stepwise_results.append({\n",
    "                \"Year\": current_year,\n",
    "                \"Feature Group\": group_name,\n",
    "                \"Train AUC\": m.get(\"Train AUC\"),\n",
    "                \"Test AUC\": m.get(\"Test AUC\"),\n",
    "                \"Train PR-AUC\": m.get(\"Train PR-AUC\"),\n",
    "                \"Test PR-AUC\": m.get(\"Test PR-AUC\"),\n",
    "                \"Num Features\": len(my_features)\n",
    "            })\n",
    "            \n",
    "        elif res[\"status\"] == \"skip\":\n",
    "            print(f\"âš ï¸ Skipped: {res['message']}\")\n",
    "            lgbm_stepwise_results.append({\n",
    "                \"Year\": current_year, \"Feature Group\": group_name,\n",
    "                \"Train AUC\": np.nan, \"Test AUC\": np.nan,\n",
    "                \"Train PR-AUC\": np.nan, \"Test PR-AUC\": np.nan,\n",
    "                \"Num Features\": len(my_features)\n",
    "            })\n",
    "            \n",
    "        else:\n",
    "            print(f\"âŒ Error: {res['message']}\")\n",
    "            # è¦–éœ€æ±‚æ±ºå®šæ˜¯å¦ç´€éŒ„ Error\n",
    "\n",
    "print(\"\\nğŸ‰ All LightGBM models (Stepwise) completed!\")\n",
    "\n",
    "# ===========================================================\n",
    "# 3. ç”¢å‡ºå ±è¡¨\n",
    "# ===========================================================\n",
    "if lgbm_stepwise_results:\n",
    "    df_lgbm_raw = pd.DataFrame(lgbm_stepwise_results)\n",
    "    \n",
    "    # è½‰ç½®\n",
    "    target_metrics = [\"Train AUC\", \"Test AUC\", \"Train PR-AUC\", \"Test PR-AUC\"]\n",
    "    df_lgbm_pivot = df_lgbm_raw.pivot(index=\"Feature Group\", columns=\"Year\", values=target_metrics)\n",
    "    \n",
    "    # èª¿æ•´æ¬„ä½\n",
    "    df_lgbm_pivot.columns = df_lgbm_pivot.columns.swaplevel(0, 1)\n",
    "    unique_years = sorted(df_lgbm_raw[\"Year\"].unique())\n",
    "    ordered_columns = [(y, m) for y in unique_years for m in target_metrics]\n",
    "    \n",
    "    df_lgbm_final = df_lgbm_pivot.reindex(columns=ordered_columns)\n",
    "    \n",
    "    print(\"\\n=== LightGBM Performance (Using Stepwise Selected Features) ===\")\n",
    "    print(df_lgbm_final.to_string())\n",
    "else:\n",
    "    print(\"No results generated.\")\n",
    "\n",
    "\n",
    "df_lgbm_final.to_csv(\"lgbm_stepwise.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional code--å–®ç¨è®€å–stepwiseçµæœé€²å…¥code\n",
    "### (çœæ™‚é–“è®€stepwiseå¾Œçš„çµæœï¼Œç”¨ä¾†é‹è¡Œsession 6 å„d part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²è®€å–è®Šæ•¸è¨­å®š\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('stepwise_feature_storage.pkl', 'rb') as f:\n",
    "     stepwise_feature_storage = pickle.load(f)\n",
    "print(\"âœ… å·²è®€å–è®Šæ•¸è¨­å®š\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year_X_all  0  ['zip', 'longitude', 'use_chip_Swipe Transaction', 'merchant_id', 'amount', 'per_capita_income', 'credit_limit', 'errors_missing_flag', 'mcc_code', 'yearly_income', 'latitude']\n",
      "year_X_all  1  ['use_chip_Swipe Transaction', 'amount']\n",
      "year_X_all  2  ['use_chip_Swipe Transaction', 'merchant_id', 'mcc_code', 'credit_limit', 'num_credit_cards', 'errors_missing_flag']\n",
      "year_X_all  3  ['use_chip_Swipe Transaction', 'yearly_income', 'amount', 'card_type_Credit', 'card_type_Debit', 'merchant_id', 'gender_Male', 'errors_missing_flag', 'credit_score', 'card_brand_Visa']\n",
      "year_X_all  4  ['use_chip_Swipe Transaction', 'amount', 'credit_limit', 'num_credit_cards', 'retirement_age', 'errors_missing_flag', 'card_brand_Mastercard', 'num_cards_issued', 'current_age', 'longitude', 'per_capita_income', 'card_type_Credit', 'card_type_Debit', 'mcc_code']\n",
      "year_X_all  5  ['use_chip_Chip Transaction', 'use_chip_Swipe Transaction', 'amount', 'yearly_income', 'num_credit_cards', 'credit_limit', 'has_chip_YES', 'mcc_code', 'card_type_Credit', 'card_type_Debit', 'merchant_id', 'gender_Male', 'retirement_age', 'errors_missing_flag']\n",
      "year_X_all  6  ['use_chip_Chip Transaction', 'use_chip_Swipe Transaction', 'amount', 'per_capita_income', 'num_credit_cards', 'mcc_code', 'credit_limit', 'errors_missing_flag', 'merchant_id', 'yearly_income', 'card_type_Debit', 'has_chip_YES']\n",
      "year_X_all  7  []\n",
      "year_X_all  8  ['zip', 'longitude', 'use_chip_Chip Transaction', 'latitude', 'per_capita_income', 'mcc_code', 'merchant_id', 'errors_missing_flag', 'amount', 'retirement_age', 'credit_limit', 'num_credit_cards', 'card_type_Credit', 'num_cards_issued']\n",
      "year_X_all  9  ['zip', 'longitude', 'use_chip_Chip Transaction', 'latitude', 'mcc_code', 'yearly_income', 'merchant_id', 'retirement_age', 'credit_limit', 'num_credit_cards', 'amount', 'errors_missing_flag', 'card_type_Credit', 'per_capita_income', 'credit_score']\n",
      "year_X_all + X_dk  0  ['longitude', 'merchant_others', 'DifferentState', 'merchant_id', 'zip', 'amount', 'per_capita_income', 'mcc_code', 'credit_limit', 'errors_missing_flag', 'retirement_age', 'FirstTxnInRegion', 'total_debt']\n",
      "year_X_all + X_dk  1  ['use_chip_Swipe Transaction', 'DifferentState', 'amount']\n",
      "year_X_all + X_dk  2  ['use_chip_Swipe Transaction', 'merchant_id', 'mcc_code', 'credit_limit', 'num_credit_cards', 'DifferentState', 'errors_missing_flag']\n",
      "year_X_all + X_dk  3  ['use_chip_Swipe Transaction', 'yearly_income', 'amount', 'DifferentState', 'FirstTxnInRegion', 'merchant_id', 'card_brand_Visa', 'mcc_code', 'gender_Male', 'card_type_Credit', 'card_type_Debit', 'credit_score', 'current_age', 'num_credit_cards']\n",
      "year_X_all + X_dk  4  ['merchant_online', 'FirstTxnInRegion', 'DifferentState', 'amount', 'credit_limit', 'num_credit_cards', 'mcc_code', 'retirement_age', 'card_brand_Mastercard', 'num_cards_issued', 'current_age', 'longitude', 'per_capita_income', 'errors_missing_flag']\n",
      "year_X_all + X_dk  5  ['merchant_online', 'amount', 'DifferentState', 'yearly_income', 'num_credit_cards', 'use_chip_Chip Transaction', 'credit_limit', 'mcc_code', 'has_chip_YES', 'merchant_id', 'retirement_age', 'gender_Male', 'card_type_Credit', 'card_type_Debit']\n",
      "year_X_all + X_dk  6  ['merchant_us', 'amount', 'DifferentState', 'mcc_code', 'per_capita_income', 'num_credit_cards', 'credit_limit', 'merchant_id', 'has_chip_YES', 'yearly_income', 'card_type_Debit', 'merchant_online', 'errors_missing_flag', 'current_age', 'use_chip_Chip Transaction']\n",
      "year_X_all + X_dk  7  []\n",
      "year_X_all + X_dk  8  ['zip', 'longitude', 'DifferentState', 'use_chip_Chip Transaction', 'per_capita_income', 'latitude', 'merchant_id', 'mcc_code', 'errors_missing_flag', 'FirstTxnInRegion', 'card_type_Credit', 'num_credit_cards', 'credit_limit', 'retirement_age']\n",
      "year_X_all + X_dk  9  ['DifferentState', 'latitude', 'yearly_income', 'credit_limit', 'FirstTxnInRegion', 'zip', 'mcc_code', 'num_credit_cards', 'merchant_id', 'errors_missing_flag', 'use_chip_Chip Transaction', 'longitude', 'retirement_age', 'card_type_Credit', 'per_capita_income', 'credit_score', 'merchant_online']\n",
      "year_X_all + X_rfm  0  ['zip', 'longitude', 'use_chip_Swipe Transaction', 'merchant_id', 'RecencyInterval', 'amount', 'per_capita_income', 'TxnFrequency_7d', 'TxnFrequency_30d', 'credit_limit', 'AmtDelta', 'mcc_code', 'yearly_income', 'errors_missing_flag', 'latitude']\n",
      "year_X_all + X_rfm  1  ['use_chip_Swipe Transaction', 'amount', 'TxnFrequency_90d', 'TxnFrequency_7d', 'num_credit_cards', 'credit_score', 'RecencyInterval']\n",
      "year_X_all + X_rfm  2  ['use_chip_Swipe Transaction', 'TxnFrequency_90d', 'TxnFrequency_7d', 'RecencyInterval', 'merchant_id', 'num_credit_cards', 'mcc_code', 'credit_limit']\n",
      "year_X_all + X_rfm  3  ['use_chip_Swipe Transaction', 'TxnFrequency_90d', 'TxnFrequency_7d', 'yearly_income', 'RecencyInterval', 'amount', 'AmtDelta', 'num_credit_cards', 'card_type_Credit', 'card_brand_Amex', 'card_type_Debit', 'gender_Male', 'current_age', 'merchant_id']\n",
      "year_X_all + X_rfm  4  ['use_chip_Swipe Transaction', 'TxnFrequency_90d', 'TxnFrequency_7d', 'num_credit_cards', 'RecencyInterval', 'amount', 'AmtDelta', 'retirement_age', 'card_type_Credit', 'current_age', 'card_type_Debit', 'per_capita_income', 'longitude', 'card_brand_Mastercard', 'card_brand_Amex', 'num_cards_issued']\n",
      "year_X_all + X_rfm  5  ['use_chip_Chip Transaction', 'use_chip_Swipe Transaction', 'amount', 'RecencyInterval', 'TxnFrequency_90d', 'TxnFrequency_7d', 'num_credit_cards', 'credit_limit', 'TxnFrequency_30d', 'AmtDelta', 'has_chip_YES', 'yearly_income', 'gender_Male', 'card_type_Credit', 'card_type_Debit', 'card_brand_Amex', 'mcc_code', 'credit_score', 'retirement_age']\n",
      "year_X_all + X_rfm  6  ['use_chip_Chip Transaction', 'use_chip_Swipe Transaction', 'TxnFrequency_90d', 'RecencyInterval', 'amount', 'num_credit_cards', 'TxnFrequency_7d', 'credit_limit', 'AmtDelta', 'merchant_id', 'card_type_Debit', 'mcc_code', 'has_chip_YES', 'errors_missing_flag']\n",
      "year_X_all + X_rfm  7  []\n",
      "year_X_all + X_rfm  8  ['zip', 'longitude', 'use_chip_Chip Transaction', 'latitude', 'TxnFrequency_90d', 'TxnFrequency_7d', 'mcc_code', 'merchant_id', 'yearly_income', 'errors_missing_flag', 'card_type_Credit', 'RecencyInterval', 'num_credit_cards', 'credit_limit', 'TxnFrequency_30d', 'amount', 'num_cards_issued', 'retirement_age']\n",
      "year_X_all + X_rfm  9  ['zip', 'longitude', 'use_chip_Chip Transaction', 'latitude', 'mcc_code', 'yearly_income', 'merchant_id', 'retirement_age', 'TxnFrequency_90d', 'TxnFrequency_7d', 'AmtDelta', 'num_credit_cards', 'credit_limit', 'errors_missing_flag', 'card_type_Credit', 'RecencyInterval', 'per_capita_income', 'TxnFrequency_30d']\n",
      "year_X_all + X_rfm + X_dk  0  ['longitude', 'DifferentState', 'merchant_id', 'amount', 'RecencyInterval', 'per_capita_income', 'AmtDelta', 'TxnFrequency_7d', 'credit_limit', 'TxnFrequency_30d', 'FirstTxnInRegion', 'latitude', 'zip', 'yearly_income', 'merchant_online', 'merchant_us']\n",
      "year_X_all + X_rfm + X_dk  1  ['use_chip_Swipe Transaction', 'DifferentState', 'amount', 'TxnFrequency_90d', 'TxnFrequency_7d', 'num_credit_cards', 'credit_score']\n",
      "year_X_all + X_rfm + X_dk  2  ['use_chip_Swipe Transaction', 'TxnFrequency_90d', 'TxnFrequency_7d', 'RecencyInterval', 'merchant_id', 'num_credit_cards', 'mcc_code', 'credit_limit', 'DifferentState', 'longitude', 'zip', 'yearly_income', 'per_capita_income', 'current_age']\n",
      "year_X_all + X_rfm + X_dk  3  ['use_chip_Swipe Transaction', 'TxnFrequency_90d', 'TxnFrequency_7d', 'DifferentState', 'yearly_income', 'amount', 'RecencyInterval', 'FirstTxnInRegion', 'AmtDelta', 'num_credit_cards', 'card_type_Credit', 'card_brand_Amex', 'card_type_Debit', 'gender_Male', 'merchant_id', 'current_age']\n",
      "year_X_all + X_rfm + X_dk  4  ['merchant_online', 'FirstTxnInRegion', 'TxnFrequency_90d', 'TxnFrequency_7d', 'DifferentState', 'num_credit_cards', 'RecencyInterval', 'amount', 'retirement_age', 'AmtDelta', 'card_brand_Mastercard', 'current_age', 'longitude', 'num_cards_issued', 'card_type_Credit', 'card_type_Debit', 'per_capita_income', 'card_brand_Amex']\n",
      "year_X_all + X_rfm + X_dk  5  ['merchant_online', 'amount', 'DifferentState', 'TxnFrequency_90d', 'TxnFrequency_7d', 'RecencyInterval', 'num_credit_cards', 'credit_limit', 'use_chip_Chip Transaction', 'TxnFrequency_30d', 'has_chip_YES', 'AmtDelta', 'yearly_income', 'mcc_code', 'gender_Male', 'longitude', 'total_debt', 'card_type_Credit', 'card_type_Debit', 'card_brand_Amex', 'credit_score', 'retirement_age', 'merchant_others']\n",
      "year_X_all + X_rfm + X_dk  6  ['use_chip_Chip Transaction', 'TxnFrequency_90d', 'RecencyInterval', 'amount', 'DifferentState', 'TxnFrequency_7d', 'credit_limit', 'use_chip_Swipe Transaction', 'num_credit_cards', 'mcc_code', 'merchant_id', 'card_type_Debit', 'AmtDelta', 'has_chip_YES']\n",
      "year_X_all + X_rfm + X_dk  7  []\n",
      "year_X_all + X_rfm + X_dk  8  ['DifferentState', 'use_chip_Chip Transaction', 'TxnFrequency_90d', 'TxnFrequency_7d', 'latitude', 'yearly_income', 'merchant_id', 'mcc_code', 'RecencyInterval', 'errors_missing_flag', 'FirstTxnInRegion', 'card_type_Credit', 'zip', 'merchant_others']\n",
      "year_X_all + X_rfm + X_dk  9  ['DifferentState', 'latitude', 'yearly_income', 'RecencyInterval', 'TxnFrequency_90d', 'TxnFrequency_7d', 'zip', 'use_chip_Chip Transaction', 'longitude', 'mcc_code', 'merchant_id', 'num_credit_cards', 'retirement_age', 'AmtDelta', 'errors_missing_flag', 'credit_limit', 'FirstTxnInRegion', 'card_type_Credit', 'per_capita_income', 'TxnFrequency_30d', 'credit_score']\n",
      "year_X_dk  0  ['merchant_online', 'DifferentState', 'FirstTxnInRegion', 'merchant_others']\n",
      "year_X_dk  1  ['merchant_online', 'DifferentState']\n",
      "year_X_dk  2  ['merchant_online']\n",
      "year_X_dk  3  ['merchant_online', 'DifferentState', 'FirstTxnInRegion']\n",
      "year_X_dk  4  ['merchant_online', 'FirstTxnInRegion', 'DifferentState']\n",
      "year_X_dk  5  ['merchant_online', 'DifferentState']\n",
      "year_X_dk  6  ['merchant_online', 'DifferentState']\n",
      "year_X_dk  7  []\n",
      "year_X_dk  8  ['FirstTxnInRegion', 'DifferentState', 'merchant_us']\n",
      "year_X_dk  9  ['FirstTxnInRegion', 'DifferentState']\n",
      "year_X_rfm  0  ['RecencyInterval', 'TxnFrequency_7d', 'AmtDelta', 'TxnFrequency_30d']\n",
      "year_X_rfm  1  ['AmtDelta']\n",
      "year_X_rfm  2  ['RecencyInterval', 'TxnFrequency_90d', 'TxnFrequency_7d', 'AmtDelta']\n",
      "year_X_rfm  3  ['RecencyInterval', 'TxnFrequency_90d', 'TxnFrequency_7d', 'AmtDelta', 'TxnFrequency_30d']\n",
      "year_X_rfm  4  ['RecencyInterval', 'TxnFrequency_90d', 'TxnFrequency_7d', 'AmtDelta']\n",
      "year_X_rfm  5  ['RecencyInterval', 'TxnFrequency_90d', 'TxnFrequency_7d', 'AmtDelta', 'TxnFrequency_30d']\n",
      "year_X_rfm  6  ['TxnFrequency_90d', 'RecencyInterval', 'AmtDelta', 'TxnFrequency_7d']\n",
      "year_X_rfm  7  []\n",
      "year_X_rfm  8  ['TxnFrequency_90d', 'TxnFrequency_7d', 'AmtDelta', 'RecencyInterval', 'TxnFrequency_30d']\n",
      "year_X_rfm  9  ['TxnFrequency_90d', 'TxnFrequency_7d', 'AmtDelta', 'RecencyInterval']\n",
      "year_X_rfm + X_dk  0  ['merchant_online', 'DifferentState', 'FirstTxnInRegion', 'RecencyInterval', 'TxnFrequency_7d', 'TxnFrequency_30d', 'AmtDelta']\n",
      "year_X_rfm + X_dk  1  ['merchant_online', 'DifferentState', 'TxnFrequency_90d', 'TxnFrequency_7d', 'AmtDelta']\n",
      "year_X_rfm + X_dk  2  ['merchant_online', 'TxnFrequency_90d', 'TxnFrequency_7d', 'RecencyInterval']\n",
      "year_X_rfm + X_dk  3  ['merchant_online', 'TxnFrequency_90d', 'TxnFrequency_7d', 'DifferentState', 'RecencyInterval', 'FirstTxnInRegion', 'TxnFrequency_30d', 'AmtDelta']\n",
      "year_X_rfm + X_dk  4  ['merchant_online', 'FirstTxnInRegion', 'TxnFrequency_90d', 'TxnFrequency_7d', 'DifferentState', 'RecencyInterval']\n",
      "year_X_rfm + X_dk  5  ['merchant_online', 'TxnFrequency_90d', 'TxnFrequency_7d', 'RecencyInterval', 'DifferentState', 'TxnFrequency_30d', 'AmtDelta']\n",
      "year_X_rfm + X_dk  6  ['merchant_online', 'TxnFrequency_90d', 'RecencyInterval', 'DifferentState', 'TxnFrequency_7d', 'AmtDelta']\n",
      "year_X_rfm + X_dk  7  []\n",
      "year_X_rfm + X_dk  8  ['FirstTxnInRegion', 'DifferentState', 'TxnFrequency_90d', 'TxnFrequency_7d', 'RecencyInterval', 'TxnFrequency_30d', 'AmtDelta']\n",
      "year_X_rfm + X_dk  9  ['FirstTxnInRegion', 'DifferentState', 'TxnFrequency_90d', 'TxnFrequency_7d', 'RecencyInterval', 'AmtDelta', 'merchant_online']\n",
      "\n",
      "âœ… æœ€çµ‚ä¿®æ­£ç‰ˆ CSV å·²å­˜æª”ï¼šstepwise_features_final.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. ç¢ºä¿å®ƒæ˜¯ DataFrameã€‚å¦‚æœæ˜¯å­—å…¸è½‰éä¾†çš„ï¼Œé€™æ­¥æœƒè™•ç†å¥½ã€‚\n",
    "df = pd.DataFrame(stepwise_feature_storage)\n",
    "\n",
    "# 2. ä½¿ç”¨ stack() å°‡æ¬„ä½ã€Œæ—‹è½‰ã€ä¸‹ä¾†\n",
    "# é€™æœƒç”¢ç”Ÿä¸€å€‹å¤šé‡ç´¢å¼• (Year_Index, Model_Type)\n",
    "stacked = df.stack()\n",
    "\n",
    "# 3. è½‰å› DataFrame ä¸¦é‡æ•´ç´¢å¼•\n",
    "df_final = stacked.reset_index()\n",
    "\n",
    "# 4. é‡æ–°å‘½åæ¬„ä½\n",
    "df_final.columns = ['Year', 'Model_Type', 'Features']\n",
    "\n",
    "# 5. å°‡ Year è½‰æ›æˆä½ æƒ³è¦çš„ \"year_0\" æ ¼å¼\n",
    "df_final['Year'] = df_final['Year'].apply(lambda x: f\"year_{x}\")\n",
    "\n",
    "# 6. ä¾ç…§å¹´ä»½æ’åº\n",
    "df_final = df_final.sort_values(by=['Year', 'Model_Type'])\n",
    "\n",
    "# --- è¼¸å‡ºçµæœæª¢æŸ¥ ---\n",
    "for _, row in df_final.iterrows():\n",
    "    print(f\"{row['Year']}  {row['Model_Type']}  {row['Features']}\")\n",
    "\n",
    "# --- å„²å­˜ CSV ---\n",
    "df_final.to_csv('stepwise_features_final.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"\\nâœ… æœ€çµ‚ä¿®æ­£ç‰ˆ CSV å·²å­˜æª”ï¼šstepwise_features_final.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
